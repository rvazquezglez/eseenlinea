\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage[spanish]{babel}
\usepackage[pdftex]{graphicx} % PDFLaTeX
\DeclareGraphicsExtensions{.png,.pdf,.jpg}
\usepackage{epsf}
\usepackage{graphicx}
\usepackage{mathrsfs}


\newtheorem{teorema}{Teorema}[section]
\newtheorem{lema}[teorema]{Lema}
\newtheorem{prop}[teorema]{Proposici\'on}
\newtheorem{definicion}[teorema]{Definici\'on}
\newtheorem{problema}{Problema}
\newtheorem{ejemplo}{Ejemplo}
\spanishdecimal{.}
\usepackage[latin1]{inputenc}

\begin{document}

\title{\'ALGEBRA LINEAL}
\author{\textbf{ESCUELA SUPERIOR DE ECONOMIA}}
\date{\large{M\'exico, D.F., 10 de marzo de 2010}}
\def\contentsname{Contenido}
\maketitle
\tableofcontents
\newpage

\setcounter{page}{1}
\section{\'Algebra lineal}

\textbf{Introducci\'on}
\medskip

En la presente unidad de aprendizaje introduciremos una serie de t\'ecnicas matem\'aticas encuadradas dentro de lo que se conoce como el \textbf{\'Algebra lineal}, que nos proporcionar\'an un lenguaje eficiente para el tratamiento de una gran cantidad de fen\'omenos econ\'omicos.

\subsection{Vectores}

\subsubsection{Definici\'on}
\begin{definicion}
Para cada entero positivo $n$, definimos el espacio Euclidiano
$n$-dimensional como:
\[
 \Bbb{R}^n = \{(x_1,...,x_n) \mid x_i \in \Bbb{R},\, i =1,2,...,n   \}
\]


Un elemento particular de $\Bbb{R}^n$, digamos $x = (x_1,...,x_n)$
tambi\'en pueden denotarse como vector columna
\[ x^T =
\left(
  \begin{matrix}
  x_1      \\
  x_2 \\
  \vdots \\
x_n
  \end{matrix}
  \right)
\]

se le llama \textbf{vector ( o vector columna)}. Las cantidades
$x_i$ se le llaman componentes (o elementos de x), a $n$ se le llama
el orden de $x$. Los vectores de orden 1 se les llaman \textbf{escalares}.
\end{definicion}

\subsubsection{Operaci\'ones de vectores}

La operaci\'on de suma entre dos vectores $x,y  \in \Bbb{R}^{n}$ se
define como:
\[ x + y =
\left(
  \begin{matrix}
  x_1      \\
  x_2 \\
  \vdots \\
x_n
  \end{matrix}
  \right)
+
\left(
  \begin{matrix}
  y_1      \\
  y_2 \\
  \vdots \\
y_n
  \end{matrix}
  \right)
=
  \left(
  \begin{matrix}
  x_1 + y_1      \\
  x_2  + y_2\\
  \vdots \\
x_n + y_n
  \end{matrix}
  \right)
\]

y el producto  de un escalar $\lambda$ por un vector $x \in
\Bbb{R}^n$ se define como:

\[ \lambda x  =
\left(
  \begin{matrix}
  \lambda  x_1      \\
  \lambda x_2 \\
  \vdots \\
   \lambda x_n
  \end{matrix}
  \right)
\]



\begin{ejemplo}
Sea
\[
 x = \left(
  \begin{matrix}
  1      \\
  2 \\
-3
  \end{matrix}
  \right)
 \quad
 \text{y}
\quad
y = \left(
  \begin{matrix}
  7      \\
  -1 \\
  2
  \end{matrix}
  \right)
\]

\vspace{.2cm}

Calcule $x+y, 3x, -y$, y $5x - 2y$.

\vspace{.2cm}

\textbf{Soluci\'on:}


\[
 x + y = \left(
  \begin{matrix}
  8      \\
  1\\
  -1
  \end{matrix}
  \right),
  \quad
  3x =
\left(
  \begin{matrix}
  3     \\
  6 \\
 -9
  \end{matrix}
  \right), \quad
-y =
\left(
  \begin{matrix}
  -7      \\
  1 \\
 -2
  \end{matrix}
  \right)
  \quad
  5x - 2y =
\left(
  \begin{matrix}
  -9      \\
  12 \\
  -19
  \end{matrix}
  \right)
\]
\end{ejemplo}

\subsubsection{Representaci\'on gr\'afica.}

La suma y multiplicaci\'on por escalar definidas anteriormente
tienen un significado geom\'etrico. La representaci\'on geom\'etrica en $\Bbb{R}^3$ de la
suma de vectores $x=(x_1,x_2,x_3)$ y $y =(y_1,y_2,y_3)$ se obtiene trasladando a uno de ellos al extremo
del otro, formando un paralelogramo, una de cuyas diagonales representa el vector resultante
$ x + y =(x_1 + y_1,x_2 + y_2,x_3 + y_3)$. A esta representaci\'on  de la suma de
vectores es a lo que se le llama \textbf{ la ley del paralelogramo}.

\vspace{.2cm}

El producto de un escalar por un vector se interpreta de la
siguiente manera: s\'{\i} el escalar $\lambda$ es positivo y diferente de uno, al multiplicar el escalar $\lambda$ por
el vector $ x = ( x_1,x_2 , x_3)$, el vector resultante es  $\lambda x =  (\lambda x_1,\lambda x_2 , \lambda x_3)$, el cual se obtiene del vector $x $ multiplicando su magnitud por $\lambda$; si el escalar es negativo y diferente
de menos uno, el vector cambia su magnitud y sentido ; si el escalar
es cero, el vector se hace cero.

\begin{figure}[h]
\begin{center}
\includegraphics[width= 0.9
\textwidth,height=0.3\textheight]{Alg1.pdf}
\end{center}
\caption{Paralelogramo}
\label{Figura13}
\end{figure}

\newpage
\subsection{Producto punto}

Una aplicaci\'on del Teorema de Pit\'agoras en el espacio permite
definir la distancia  del origen de coordenadas al punto que determina
un vector $\alpha $.

\begin{definicion}
Dados los vectores $x, y \in \Bbb{R}^n$, se define su
producto punto como:
\[
  x \cdot y  = \sum_{i = 1 }^n \, x_iy_i
\]
\end{definicion}


El producto punto  satisface las siguientes propiedades:

\begin{itemize}
  \item El producto interno de dos vectores en $\Bbb{R}^n$ es un escalar \'unico.
 \item $x \cdot y = y \cdot x$
 \item $\lambda x \cdot y = x \cdot \lambda y = \lambda(x \cdot y) $
 \item $ (x + y) \cdot z  = x \cdot z + x \cdot z$
 \item $x \cdot x > 0$ si $x \ne 0$. $x \cdot x = 0$ si $\alpha = 0.$
 \end{itemize}

\begin{ejemplo}
Si
\[ x=
\left(
  \begin{matrix}
  1      \\
  2 \\
 -3
  \end{matrix}
  \right)
  \quad
  y =
  \left(
  \begin{matrix}
 4      \\
  -5 \\
 1
 \end{matrix}
  \right)
\]
Calcular $x \cdot y $: \\

Soluci\'on:
\[
 x \cdot y = (1)(4) + (2)(-5) + (-3)(1) = -9.
\]
\end{ejemplo}

\subsubsection{Norma de un vector}

\begin{definicion}
Dado un vector $x \in \Bbb{R}^n$, se define su norma
o longitud como
\[
\left\| x \right\| = \sqrt{ x \cdot x }.
\]
\end{definicion}

\begin{ejemplo}
Calcule la norma del vector $
x =\left(
  \begin{matrix}
  3     \\
  4
  \end{matrix}
  \right) $

Soluci\'on:

\[
\left\| x \right\| = \sqrt{3^2 + 4^2} = \sqrt{ 9 + 16} = \sqrt{25} = 5 .
\]
\end{ejemplo}

La norma de cualesquirera  vectores $x,y \in \Bbb{R}^n$ tiene las siguientes propiedades:

\begin{itemize}
 \item  $\left\| x \right\| \geq 0$. $\left\| x \right\| = 0$ si y solo si $ x = 0$.
 \item $\left\| \lambda x  \right\| = \mid \lambda \mid   \left\| x \right\| .$
 \item $\left\| x + y \right\| \leq \left\| x  \right\| + \left\| y \right\|$.
\end{itemize}

\subsubsection{Ángulo entre vectores}

El \'angulo entre dos vectores $x$ y $y$ se puede obtener a
trav\'es de la ecuaci\'on:
\[
  \cos (\theta) = \frac{ x \cdot y }{\left\| x
  \right\| \left\| y \right\|}.
\]


Notemos que la ecuaci\'on anterior  estable que los vectores $x$
y $y$ son perpendiculares si y solo si $x \cdot y = 0$, pues para
$0 \leq \theta \leq \pi$, $\cos (\theta) = 0$ si y solo si
$\theta = \frac{\pi}{2}$.

\begin{ejemplo} Calcular el \'angulo entre los vectores:
\[
x =\left(
  \begin{matrix}
  5     \\
  -3 \\
  2
  \end{matrix}
  \right) \quad  \text{y} \quad
y =\left(
  \begin{matrix}
  -2     \\
  1 \\
  3
  \end{matrix}
  \right)
\]

\vspace{.2cm}
El producto escalar de los vectores es
\[
 x \cdot y = -10 -3 + 6 = -7
\]

\vspace{.2cm}

entonces como
\[
  \cos (\theta) = \frac{ x \cdot y }{\left\| x
  \right\| \left\| y \right\|} = \frac{-7}{22.7} =-0.31
\]
de lo cual se sigue que el \'angulo $\theta$ entre los vectores $x$ y $y$ es
\[
 \theta = 108.31^{o}
\]
\end{ejemplo}

\subsubsection{Vectores ortogonales}

\begin{definicion}
Dos vectores no nulos  $x$ y $y$ en $\Bbb{R}^n$
 son llamados ortogonales o perpendiculares si y solo si $x \cdot y = 0$, y se escribe
 $x \perp y$.
\end{definicion}

\begin{ejemplo}
Determine todos los vectores que son ortogonales a:
\[
x =\left(
  \begin{matrix}
  1     \\
  2
  \end{matrix}
  \right)
  \]

  Soluci\'on: \\
  \vspace{.2cm}
  Todos los vectores $y \in \Bbb{R}^2$  que son ortogonales a $x$ cumplen  $x \cdot y = 0$,
  es decir, si $y = (y_1,y_2)$, entonces
\[
  x \cdot y  = (1,2) \cdot (y_1,y_2) = y_1 + 2y_2 = 0,
\]
  de lo cual se sigue que
\[
y = \lambda \left(
  \begin{matrix}
  -2    \\
  1
  \end{matrix}
  \right)  \quad (\lambda \in \Bbb{R}).
\]
\end{ejemplo}

La norma $\left\| x \right\|$ tambi\'en se usa para definir  la
funci\'on distancia $d$ en $\Bbb{R}^n$ como sigue:


\begin{definicion}
   Para todo $\alpha, \beta \in \Bbb{R}^n$,
   \[
      d(x,y) = \left\| x -y \right\|.
   \]
\end{definicion}

La funci\'on distancia $d$ satisface las siguientes propiedades:
\begin{itemize}
  \item $d(x,y) \geq 0$. Adem\'as, $d(\alpha,\beta) = 0$ si y solo si $\alpha = \beta.$
  \item $d(x, y) = d(\beta,\alpha)$
  \item $d(x,y) \leq d(x,z) + d(z,y)$.
\end{itemize}

\begin{ejemplo}
Si
\[
x =\left(
  \begin{matrix}
  1    \\
  -3
  \end{matrix}
  \right) \quad \text{y} \quad
y =\left(
  \begin{matrix}
  7     \\
  3
  \end{matrix}
  \right)
\]


Calcule la distancia entre los vectores $x$ y $y$: \\

Soluci\'on:
\[
      d(x,y) = \left\| x - y \right\| = \sqrt{ (-6)^2 + (-6)^2}  = 8.48  .
\]
\end{ejemplo}

\subsection{Producto cruz}

\begin{definicion}
Para cualquier par de vectores:
\[
x =\left(
  \begin{matrix}
  x_1     \\
  x_2   \\
  x_3
  \end{matrix}
  \right)
  \quad
y =\left(
  \begin{matrix}
  y_1     \\
  y_2   \\
  y_3
  \end{matrix}
  \right)
\]

en $\Bbb{R}^3$, el \textbf{producto cruz} se define como:



\begin{equation*}
x \times  y =
\begin{vmatrix}
 \vec{i}   & \vec{j}  & \vec{ k} \\
 x_1   & x_2  & x_3 \\
 y_1 & y_2 & y_3
\end{vmatrix}
= (x_2y_3 - y_2x_3) \vec{i} - (x_1y_3- y_1x_3) \vec{j} + (x_1y_2 -y_1x_2)\vec{k},
\end{equation*}


en donde

\[
\vec{i} =\left(
  \begin{matrix}
  1     \\
  0 \\
  0
  \end{matrix}
  \right)
  \quad
  \vec{j} =\left(
  \begin{matrix}
  0     \\
  1  \\
  0
  \end{matrix}
  \right)
 \quad
  \vec{k} =\left(
  \begin{matrix}
  0     \\
  0 \\
  1
  \end{matrix}
  \right)
  \]
\end{definicion}



\begin{ejemplo}
Dados
\[
x =\left(
  \begin{matrix}
  1     \\
  2 \\
  0
  \end{matrix}
  \right)
  \quad
  y =\left(
  \begin{matrix}
  1     \\
  3  \\
  0
  \end{matrix}
  \right)
\]

 calcule $x \times  y$, \\

Soluci\'on:

\vspace{.2cm}


De acuerdo con la definici\'on del producto cruz tenemos:


\begin{equation*}
x \times  y=
\begin{vmatrix}
 \vec{i}   & \vec{j}  & \vec{ k} \\
 1    & 2  & 0 \\
 1 &  3 &  0
\end{vmatrix}
= (2 \cdot 0 - 3 \cdot 0) \vec{i} + (1 \cdot 0 - 1 \cdot 0) \vec{j} + (3 - 2)\vec{k} = \vec{k}.
\end{equation*}


Por tanto
\[
x \times y =
\left(
  \begin{matrix}
  0     \\
  0 \\
  1
  \end{matrix}
  \right)
  \]
\end{ejemplo}


Se puede demostrar que:

 \begin{equation*}
 \label{pcruz}
 \left\| x \times y \right\| =
 \left\| x \right\|\left\| y \right\| \sen (\theta)
 \end{equation*}


donde $\theta$ es el \'angulo formado  por $\vec{\alpha}$ y $\vec{\beta}$.

\vspace{.2cm}

La ecuaci\'on (\ref{pcruz}) proporciona una forma de calcular \textbf{el \'area del pa\-ra\-le\-lo\-gra\-mo} determinado por los vectores
$x$ y $y$. Tambi\'en proporciona una alternativa para calcular el \'angulo entre dos vectores.

\subsubsection{Propiedades del producto cruz}

Si $x,\, y$ y $z$ son vectores  y $\lambda$ es un escalar,

entonces:

\begin{itemize}
\item $x \times y = - (y \times x)$
\item $ \lambda ( x \times y) = (\lambda x) \times y = x \times  (\lambda y)$
\item $ x \times (y  +   z)  = x \times y + x \times z $
\end{itemize}

\subsubsection{Ecuaci\'on del plano}
La ecuaci\'on del plano que pasa por un punto $(x_0,y_0,z_0)$ y cuyo vector normal es
$(a,b,c)$ es :
\begin{equation}
\label{plano}
   a(x - x_0) + b(y - y_0) + c(z - z_0) = 0.
\end{equation}

\begin{ejemplo}
Determinar la ecuaci\'on del plano perpendicular al vector $(1,1,1)$ que contiene al punto
$(1,0,0)$.

\vspace{.2cm}
Soluci\'on:
De la ecuaci\'on (\ref{plano}), la ecuaci\'on del plano es
\[
 1 (x -1) + 1 (y - 0) + 1(z - 0) =  0;
\]
esto es,
\[
 x + y + z = 1.
\]
\vspace{.2cm}

\end{ejemplo}

\newpage
\setcounter{page}{1}
\hspace{5cm}  \textbf{TAREA 1: VECTORES}

\vspace{.2cm}

Trabajo individual.

\begin{enumerate}
\item Sean los vectores $v = (1,-3,2)$ y $w=(4,2,1)$ calcule:
\begin{enumerate}
  \item $v + w$
  \item $2 v$
  \item $v - w$
 \end{enumerate}
 \vspace{.1cm}
\item Encuente el producto escalar $x \cdot y$ donde:
\begin{enumerate}
  \item $x = (-1,3)$,\, $y = (-1,5)$
  \item $x = (-6,12)$, \,$y = (15, -10)$
 \end{enumerate}
 \vspace{.1cm}
\item Calcule la norma del vector $x = (4,2,1)$
 \vspace{.2cm}
\item Hallar el \'angulo que forman los vectores $x = (2,10,3)$ y $y = (10,8,12)$
 \vspace{.2cm}
\item Demuestre que los vectores $v = (1,-1,1)$ y $w = (2,3,1)$ son ortogonales.
 \vspace{.2cm}
\item Encuentre un vector ortogonal a:
 \begin{enumerate}
 \item $x = (1,2)$
 \item $y = (-3,-4)$
\end{enumerate}
 \vspace{.1cm}
\item Calcule la distancia entre los siguientes vectores:
 \begin{enumerate}
 \item $x = (2,3)$,\, $y = (4,7)$
 \item $x = (-1,1)$, \,$y = (4, 0)$
 \end{enumerate}
\item Calcule el \'area del paralelogramo determinado por los vectores:
\begin{enumerate}
\item $x = (1,-1,2)$,\, $y = (-2,0,3)$.
\item $x = (1, 0,-1)$, \,$y = (-3,-1, 2)$
\end{enumerate}
\item Calcule $x \times y$ dados
Dados
\[
x =\left(
  \begin{matrix}
  2     \\
  -1 \\
  3
  \end{matrix}
  \right)
  \quad
  y =\left(
  \begin{matrix}
  1     \\
  -2  \\
  -1
  \end{matrix}
  \right)
\]
\item Encontrar un plano $\pi$ que pasa por el punto $(2,5,1)$ y cuyo vector normal es $(1,-2,3)$
\end{enumerate}

\newpage
\setcounter{page}{1}
\section{Matrices y sistemas de ecuaciones}
\subsection{Matrices}
\textbf{Introducci\'on}
\medskip

En econometr\'{\i}a estamos preocupados con el modelado de los datos observados. En muchos casos el n\'umero de datos num\'ericos es grande (varios cientos o miles) de las observaciones de una serie de posibles variables de interés y todos los datos deben ser manejados de una manera organizada. Muchos conjuntos de datos se almacenan en una hoja de c\'alculo, donde cada columna es igual al número de observaciones de esa variable. Por ejemplo, los datos sobre las calificaciones de Cálculo, Inglés e Historia de cinco estudiantes se puede representar por la siguiente tabla.

\begin{center}
\begin{tabular}{|1|r|r|r|} \hline
Estudiantes & Cálculo & Inglés  & Historia \\  \hline
1 & 1.8 & 4 & 8 \\ \hline
2 & 2.4 & 6 & 9 \\ \hline
3 & 2.9 & 6 & 7 \\ \hline
4 & 3.0 & 7 & 6 \\ \hline
5 & 3.5 & 8 & 7 \\ \hline
\end{tabular}
\end{center}

\vspace{.2cm}

\textbf{Matriz de datos}

\vspace{.2cm}

La informaci\'on consiste en datos reales de las cinco puntuaciones en Cálculo, Inglés e Historia y podemos resumir estos datos en la siguiente matriz:
\[
\left(
\begin{matrix}
1.8 & 4 & 8 \\
2.4 & 6 & 9 \\
2.9 & 6 & 7 \\
3.0 & 7 & 6\\
3.5 & 8 & 7
\end{matrix}
\right)
\]

Este bloque rectangular de n\'umeros se llama matriz. La matriz anterior tiene cinco filas y tres columnas. En econometr\'{\i}a trabajamos con las matrices, y por supuesto siempre debemos recordarnos el significado de las columnas y filas (en el caso, la correspondencia entre columnas y variables y entre las filas y los estudiantes, por lo que el n\'umero 2.9 en la columna 1 y la fila 3 se sabe que corresponden a la calificación de Cálculo del tercer estudiante).

\subsubsection{Definici\'on}

\begin{definicion}
Sean $m,n$ n\'umeros naturales. Una matriz de orden m filas  por n
columnas con coeficientes o entradas en los n\'umeros reales, es un
arreglo rectangular:


\begin{equation*}
 \left[
  \begin{matrix}
     a_{11}   & a_{12}  & \cdots   & a_{1n} \\
     a_{21}   & a_{22}  & \cdots   & a_{2n} \\
    \vdots    & \vdots  & \vdots   & \vdots \\
      a_{m1}  & a_{m2}  & \cdots  & a_{mn}
  \end{matrix}
  \right]
\end{equation*}

por simplicidad a la matriz anterior simplemente se representa por:
$[a_{ij}]$.
\end{definicion}

\subsubsection{Tipos de matrices: Cuadrada, diagonal, identidad, sim\'etrica}

\begin{definicion}
Sea $[a_{ij}]$ una matriz m por n. Si $m = n$, al conjunto de matrices
de orden $n$ por $n$ se le llama \textbf{ matrices cuadradas de orden $n$}.
\begin{ejemplo}
La siguiente matriz es una matriz de orden 2 por 2:
\[
\left[
  \begin{matrix}
   1    &  2   \\
   3  &  4
  \end{matrix}
 \right]
\]

\end{ejemplo}

\begin{definicion}
La matriz cuadrada $[a_{ij}]$ de orden n, tal que $a_{ij} = 0$ si $i
\ne j$, es decir, a la matriz
\[
\begin{equation*}
\text{diag}(a_{11},a_{22}, ...,a_{nn}) =
 \left[
  \begin{matrix}
     a_{11}   & 0  &  0     &  \cdots   & 0 \\
     0   & a_{22}  &  0     &  \cdots   & 0 \\
    \vdots    & \vdots & \vdots  & \vdots   & \vdots \\
     0  & 0   &  0     &\cdots  & a_{nn}
  \end{matrix}
  \right]
\]
se le llama \textbf{matriz diagonal de orden n}. En particular
si adem\'as $a_{ii} = 1$ es decir,a la matriz
\[
\begin{equation*}
I_n =
 \left[
  \begin{matrix}
     1   & 0  &  0     &  \cdots   & 0 \\
     0   & 1  &  0     &  \cdots   & 0 \\
    \vdots    & \vdots & \vdots  & \vdots   & \vdots \\
     0  & 0   &  0     &\cdots  & 1
  \end{matrix}
  \right]
\end{equation*}
\]
se le llama la  \textbf{matriz identidad de orden n}.
\end{definicion}


\begin{definicion}
Si A es una matriz cuadrada puede ocurrir que $A^{T} = A$, en este
caso a la matriz $A$ se le llama \textbf{matriz sim\'etrica.}
\end{definicion}

\begin{ejemplo}
Si $A = \text{diag}(a_{11},a_{22},...,a_{nn})}$, entones $A = A^T$, es
 decir, A es una matriz sim\'etrica.
\end{ejemplo}

\begin{ejemplo}
Sea
\[ A =
 \left[
 \begin{matrix}
 4 & - 2 & 7 \\
 -2 & 1 & 5 \\
 7 & 5 & 3
 \end{matrix}
 \right]
 \]
 Entonces $A$ es una matriz sim\'etrica.
\end{ejemplo}


\subsubsection{Aritm\'etica de matrices}
\textbf{Propiedades de la suma y multiplicaci\'on}

Sean $A = [a_{ij}], B = [b_{ij}]$ matrices m por n. Se define la \textbf{ suma}
de $A$ con $B$ por:


\begin{equation*}
 \left[
  \begin{matrix}
     a_{11}   & a_{12}  & \cdots   & a_{1n} \\
     a_{21}   & a_{22}  & \cdots   & a_{2n} \\
    \vdots    & \vdots  & \ddots   & \vdots \\
      a_{m1}  & a_{m2}  & \cdots  & a_{mn}
  \end{matrix}
  \right] +
 \left[
  \begin{matrix}
     b_{11}   & b_{12}  & \cdots   & b_{1n} \\
     b_{21}   & b_{22}  & \cdots   & b_{2n} \\
    \vdots    & \vdots  & \ddots   & \vdots \\
      b_{m1}  & b_{m2}  & \cdots  & b_{mn}
  \end{matrix}
  \right] =
\end{equation*}

\begin{center}
\begin{equation*}
\left[
  \begin{matrix}
     a_{11} + b_{11}  & a_{12} + b_{12}  & \cdots   & a_{1n} + b_{1n} \\
     a_{21} + b_{21}   & a_{22} + b_{22}  & \cdots   & a_{2n} + b_{2n} \\
    \vdots    & \vdots  & \ddots   & \vdots \\
      a_{m1} + b_{m1}  & a_{m2} + b_{m2}  & \cdots  & a_{mn} + b_{mn}
  \end{matrix}
\right]
\end{equation*}
\end{center}
\vspace{.2cm }
la cual tambi\'en es una matriz m por n.

\begin{ejemplo}
La suma de las matrices $A$ y $B$ donde:
\begin{equation*}
A =
   \left[
  \begin{matrix}
   1    & 3      \\
   9  &  7
  \end{matrix}
  \right] \hspace{.2cm}
 \texct{  y  }
 \hspace{.2cm}  B =
 \left[
  \begin{matrix}
   4    & 1 \\
   8  &    2
  \end{matrix}
 \right]
\end{equation*}

es:
\[
   \left[
  \begin{matrix}
   1    & 3      \\
   9  &  7
  \end{matrix}
  \right] \hspace{.2cm}
  +
 \hspace{.2cm} \[
 \left[
  \begin{matrix}
   4    & 1 \\
   8  &    2
  \end{matrix}
 \right]
=
\left[
  \begin{matrix}
   5    & 4 \\
   17  &  9
  \end{matrix}
 \right]
\end{equation*}
\]
\end{ejemplo}

Sea $A$ una matrix $m$ por $n$, $A  = [a_{ij}]$ y B una matriz $n$ por $k$
con $B = [b_{jr}]$, se define el \textbf{ producto} de $A$ por $B$ como sigue:
$AB = [c_{ir}]$ es una matriz $m$ por $k$ donde para todo $1 \leq i
\leq m$, para todo $1 \leq r \leq k$:
\[
            c_{ir} = \sum_{j = 1}^{n}a_{ij}b_{jr}
\]

En el siguiente ejemplo usaremos la notaci\'on $A_{m,n}$ para
denotar la matriz $A$ de orden $m \times n$.

\begin{ejemplo}
Calcular $C_{2,2} = A_{2,2} \cdot B_{2,2}$ donde
\begin{equation*}
A_{2,2} =
   \left[
  \begin{matrix}
   2    & 1      \\
   0  &  8
  \end{matrix}
  \right] \hspace{.2cm}
 \texct{  y  }
 \hspace{.2cm}  B_{2,2} =
 \left[
  \begin{matrix}
   5    & 1 \\
   7  &   4
  \end{matrix}
 \right]
\end{equation*}
Calculando el producto

\[ A_{2,2} \cdot B_{2,2} =
   \left[
  \begin{matrix}
   2    & 1      \\
   0  &  8
  \end{matrix}
  \right]
 \left[
  \begin{matrix}
   5    & 1 \\
   7  &    4
  \end{matrix}
 \right]
=
\left[
  \begin{matrix}
   17    & 6 \\
   56  &  32
  \end{matrix}
 \right]
\end{equation*}
\]
por tanto
\[C_{2,2} =
\left[
  \begin{matrix}
   17    & 6 \\
   56  &  32
  \end{matrix}
 \right]
 \]
\end{ejemplo}

\begin{ejemplo}
Calcular $C_{3,3} = A_{3,2} \cdot B_{2,3}$ donde
\begin{equation*}
A_{3,2} =
   \left[
  \begin{matrix}
   1    & 2      \\
   4  &  3 \\
   1 & 6
  \end{matrix}
  \right] \hspace{.2cm}
 \texct{  y  }
 \hspace{.2cm}  B_{2,3} =
 \left[
  \begin{matrix}
   5    & 1  & 1 \\
   2  &   4  & 1
  \end{matrix}
 \right]
\end{equation*}
Calculando el producto

\[ A_{3,2} \cdot B_{2,3} =
   \left[
  \begin{matrix}
   1    & 2      \\
   4  &  3 \\
   1 & 6
  \end{matrix}
  \right]
\left[
  \begin{matrix}
   5    & 1  & 1 \\
   2  &   4  & 1
  \end{matrix}
 \right]
 = \left[
  \begin{matrix}
   5    & 10 & 3 \\
   10  &  20 & 7 \\
   13 &  26 & 7
  \end{matrix}
 \right]
\end{equation*}
\]
por tanto
\[C_{3,3} =
\left[
  \begin{matrix}
   9    & 10 & 3 \\
   10  &  20 & 7 \\
   13 &  26 & 7
  \end{matrix}
 \right]
 \]
\end{ejemplo}

En \'algebra matricial  se dice que dos matrices son iguales si
todos los elementos correspondientes son iguales. Si $A$ es
cualquier matriz, una matriz $B$ ser\'a una matriz identidad para la
suma si:

\[
        A + B = A \hspace{1cm} \text{y} \hspace{1cm} B + A = A
\]

Se puede verificar f\'acilmente que la matriz identidad para la suma
es una matriz en la cual cada elemento es igual a cero.

\vspace{.2cm}


De manera similar, Si $A$ es cualquier matriz, la matriz identidad para
la multiplicaci\'on es la matriz identidad $I_n$ que satisface la relaci\'on:
\[
        AI = A \hspace{1cm} \text{y} \hspace{1cm} IA = A
\]

\begin{ejemplo}
\textbf{El beneficio de una Firma}

\vspace{.2cm}

Suponer que una firma produce tres tipos de productos, usando dos tipos de insumos, las cantidades de cada producto est\'an dadas por los vectores columna $q$:
\[q=
\left[
\begin{matrix}
15,000 \\
27,000  \\
13,000
\end{matrix}
\right]
\]

y los precios unitarios est\'an dadas por el vector de precios
$
\left[
\begin{matrix}
10 & 12 & 5
\end{matrix}
\right].
$

\vspace{.2cm}

Las cantidades de insumos empleados  en la producci\'on  est\'an dadas por el vector columna $z$:

\[ z=
\left[
\begin{matrix}
11,000 \\
30,000
\end{matrix}
\right]
\]

Y los precios  de esos insumos  por el vector $w = \left[
\begin{matrix}
20 & 8
\end{matrix}
\right]$. El beneficio de la empresa se
encuentra dada por:
\begin{align*}
\prod &= pq- wz \\
      &= \left[
\begin{matrix}
10 & 12 & 5
\end{matrix}
\right]
\left[
\begin{matrix}
15,000 \\
27,000  \\
13,000
\end{matrix}
\right] -
\left[
\begin{matrix}
20 & 8
\end{matrix}
\right]
\left[
\begin{matrix}
11,000 \\
30,000
\end{matrix}
\right]  \\
&=(150,000 + 324,000 + 65,000)- (220,000 + 240,000) = 79,000
\end{align*}
\end{ejemplo}
\newpage

\textbf{Potencia de matrices y matriz idempotente}

\begin{definicion}
Si $A$ es una matriz cuadrada y $n$ es un entero positivo, entonces \textbf{ la n-\'esima
potencia de $A$}, la cual se escribe como $A^n$, es el producto de $n$ factores de $A$:
\[
 A^n = \underbrace{A \cdot A \cdots A}_{n}
 \]
Si $A$ es una matriz de orden $n$, se define $A^0 = I_n$.
\end{definicion}

\begin{ejemplo}
Si  $A =\left(
  \begin{matrix}
   1    &  -1  \\
   0  &  1
  \end{matrix}
 \right)$
 entonces:

 \begin{align*}
 A^2 &= A A = \left(
  \begin{matrix}
   1    &  -1   \\
   0  &  1
  \end{matrix}
 \right)
 \left(
  \begin{matrix}
   1    &  -1   \\
   0  &  1
  \end{matrix}
 \right) =
 \left(
  \begin{matrix}
   1    &  -2   \\
   0  &  1
  \end{matrix}
 \right) \\
 A^3 &= A^2 A =
  \left(
  \begin{matrix}
   1    &  -2   \\
   0  &  1
  \end{matrix}
 \right)
 \left(
  \begin{matrix}
   1    &  -1   \\
   0  &  1
  \end{matrix}
 \right) =
 \left(
  \begin{matrix}
   1    &  -3   \\
   0  &  1
  \end{matrix}
 \right).
 \end{align*}
\end{ejemplo}

Es f\'acil demostrar por  inducci\'on que
\[
  A^n =
\left(
  \begin{matrix}
   1    &  -n   \\
   0  &  1
  \end{matrix}
 \right)
\]

\begin{definicion}
Una matriz $A$ tal que $A^2 = A$ se le llama \textbf{matriz idempotente}.
\end{definicion}

\begin{ejemplo}
La matriz $A =\left[
  \begin{matrix}
   1    &  0   \\
   -1  &  0
  \end{matrix}
 \right]$ es idempotente.
\end{ejemplo}

\subsubsection{Transpuesta y sus propiedades}

\begin{definicion}
Dada una matriz $A = [a_{ij}]$, se define la matriz
$A^{T} = [b_{ij}]$ donde $b_{ij} = a_{ji}$. A la matriz $A^T$ se le
llama la \textbf{ matriz traspuesta de $A$}.
\end{definicion}

\begin{ejemplo}
La traspuesta de la matriz:
\begin{equation*}
A =
   \left[
  \begin{matrix}
   5    & -2       \\
   -1  &  7
  \end{matrix}
  \right]
\end{equation}

es dada por:

\[
A^{T} =
   \left[
  \begin{matrix}
   5    & -1       \\
   -2  &  7
  \end{matrix}
  \right]
\end{equation}
\]
\end{ejemplo}

Propiedades de la matriz traspuesta:

\begin{itemize}
\item $A= (A^T)^T$
\item $(A + B)^T = A^T + B^T$
\item $(AB)^T = B^T A^T$
\end{itemize}

\begin{ejemplo}
Si
\[
A =
   \left[
  \begin{matrix}
   2    & 1 & 3       \\
   3  &  1  & 4
  \end{matrix}
  \right]
\]

entonces
\[
A^T =
   \left[
  \begin{matrix}
   2    & 3       \\
   1  & 1  \\
   3  & 4
  \end{matrix}
  \right]
\]

as\'{\i}

\[
(A^T)^T =
   \left[
  \begin{matrix}
   2    & 1 & 3       \\
   3  &  1  & 4
  \end{matrix}
  \right] =  A
 \]
\end{ejemplo}

\begin{ejemplo}
Sean
\[
A =
   \left[
  \begin{matrix}
   1    & 2        \\
   3  &  0
  \end{matrix}
  \right], \quad
B =
   \left[
  \begin{matrix}
   3    & 1        \\
   -1  &  1
  \end{matrix}
  \right]
 \]

entonces

\[
A^T =
   \left[
  \begin{matrix}
   1    & 3        \\
   2  &  0
  \end{matrix}
  \right], \quad
B^T =
   \left[
  \begin{matrix}
   3    & -1        \\
   1  &  1
  \end{matrix}
  \right]
 \]

Para la suma tenemos que

\begin{align*}
A + B &=
\left[
  \begin{matrix}
   1    & 2       \\
   3  &  0
  \end{matrix}
  \right]
+
   \left[
  \begin{matrix}
   3    & 1       \\
   -1  &  1
  \end{matrix}
  \right] \\
 &= \left[
  \begin{matrix}
   4    & 3       \\
   2  &  1
  \end{matrix}
  \right]
\end{align*}

entonces
\[
(A + B)^T =
   \left[
  \begin{matrix}
   4    & 2        \\
   3  &  1
  \end{matrix}
  \right] = A^T + B^T
 \]


ya que


\begin{align*}
A^T + B^T &=
\left[
  \begin{matrix}
   1    & 3       \\
   2  &  0
  \end{matrix}
  \right]
+
   \left[
  \begin{matrix}
   3    & -1       \\
   1  &  1
  \end{matrix}
  \right] \\
 &= \left[
  \begin{matrix}
   4    & 2       \\
   3  &  1
  \end{matrix}
  \right].
\end{align*}


Ahora, para la multiplicaci\'on tenemos

\begin{align*}
A B &=
\left[
  \begin{matrix}
   1    & 2       \\
   3  &  0
  \end{matrix}
  \right]
   \left[
  \begin{matrix}
   3    & 1       \\
   -1  &  1
  \end{matrix}
  \right] \\
 &= \left[
  \begin{matrix}
   1    & 3       \\
   9  &  3
  \end{matrix}
  \right]
\end{align*}

entonces
\[
(AB)^T =
   \left[
  \begin{matrix}
   1   & 9        \\
   3  &  3
  \end{matrix}
  \right] = B^T A^T
 \]

ya que

\begin{align*}
B^T A^T &=
\left[
  \begin{matrix}
   3    & -1       \\
   1  &  1
  \end{matrix}
  \right]
   \left[
  \begin{matrix}
   1    & 3       \\
   2  &  0
  \end{matrix}
  \right] \\
 &= \left[
  \begin{matrix}
   1    & 9       \\
   3  &  3
  \end{matrix}
  \right].
\end{align*}

\end{ejemplo}


\textbf{Traza y sus propiedades}
\medskip

La traza de una matriz es una operaci\'on definida s\'olo para
matrices cuadradas.

\begin{definicion}
Si $\textbf{A}$ es una matriz $n \times n$, la \textbf{traza de la
  matriz $A$}, denotada como $tr(A)$, se define como
\[
   tr(A) =  \sum_{i = 1}^{n} \ a_{ii}.
\]

\begin{itemize}
\item  $ tr(I_n) = n$
\item  $tr(A^T) = tr(A)$
\item  $tr(A + B) = tr(A) + tr(B)$
\item  $tr(\alpha A) = \alpha tr(A)$, para todo escalar $\alpha$
\item  $tr(AB) = tr(BA)$, donde $A$ es una matriz $m \times n$ y $B$
  es una matriz $n \times m$.
\end{itemize}

\begin{ejemplo}
 Si
\[
 A = \left[
  \begin{matrix}
   2    & 7       \\
   3  &  4
  \end{matrix}
  \right]
 \]

entonces
\[
tr(A)= 2 + 4  =  6
\]

\end{ejemplo}
\end{definicion}

\subsection{Determinantes}
En esta secci\'on introducimos una
funci\'on, la funci\'on determinante. Si $A$ es una matriz cuadrada,
entonces la funci\'on determinante asocia a $A$ exactamente un
n\'umero real llamado el determinante de $A$, el determinante de $A$
el cual se le denota por $\mid A \mid$.

\subsubsection{Definici\'on}
\begin{definicion}
Si $A =[a_{ij}]$  es una matriz cuadrada de orden 1, entonces $\mid A \mid = a_{11}.$
\end{definicion}

\begin{definicion}
Si $A =
   \left[
  \begin{matrix}
   a_{11}    & a_{12}      \\
   a_{21}  &  a_{22}
  \end{matrix}
  \right]
$
es una matriz cuadrada de orden 2, entonces $\mid A \mid = a_{11}a_{22}- a_{21}a_{12}.$
\end{definicion}

\begin{ejemplo}

\[
\left[
  \begin{matrix}
   4    & 1      \\
   3  &  2
  \end{matrix}
  \right] = 4 \cdot 2 - 3 \cdot 1 = 8 - 3 = 5
\]
\end{ejemplo}

\begin{definicion} Determinante  de $3 \times 3$\\

\vspace{.2cm}

 Sea  $ A = \left(
 \begin{matrix}
 a_{11} & a_{12} & a_{13} \\
 a_{21} & a_{22} & a_{23} \\
 a_{31} & a_{32} & a_{33}
 \end{matrix}
 \right) $. Entonces
\vspace{.2cm}
\[
\det A = | A | = a_{11} \left|
 \begin{matrix}
 a_{22} & a_{23} \\
 a_{32} &  a_{33}
 \end{matrix}
 \right| - a_{12} \left| \begin{matrix}
 a_{21} & a_{23} \\
 a_{31} &  a_{33}
 \end{matrix}
 \right| + a_{13} \left|
 \begin{matrix}
 a_{21} & a_{22} \\
 a_{31} &  a_{32}
 \end{matrix}
 \right|
\]

\end{definicion}


\begin{ejemplo}
C\'alculo de un determinante $3\times 3$\\

\vspace{.2cm}


Sea $ A = \left(
 \begin{matrix}
 3   & 5 & 2 \\
 4 & 2 & 3 \\
 -1 &  2 & 4
 \end{matrix}
 \right) $. Calcule $|A|$.

\[
| A | = \left|
 \begin{matrix}
 3   & 5 & 2 \\
 4 & 2 & 3 \\
 -1 &  2 & 4
 \end{matrix}
 \right|
= 3 \left|
 \begin{matrix}
 2 & 3 \\
 2 &  4
 \end{matrix}
 \right| - 5 \left| \begin{matrix}
 4 & 3 \\
 -1 &  4
 \end{matrix}
 \right| + 2 \left|
 \begin{matrix}
 4 & 2 \\
 -1 &  2
 \end{matrix}
 \right| =
 3 \cdot 2 - 5 \cdot 19 + 2 \cdot 10 = -69
\]

\end{ejemplo}


\begin{definicion}
(\textbf{Menor}) Sea $A$ una matriz de $n \times n $ y sea $M_{ij}$
la matriz de $(n - 1) \times (n - 1)$ que se obtiene de $A$
eliminando el rengl\'on $i$ y la columna $j$. $M_{ij}$ se llama el
\textbf{menor ij} de $A$.
 \end{definicion}

\begin{ejemplo}
C\'alculo de dos menores de una matriz $3 \times 3$\\

 Sea A = \left(
 \begin{matrix}
 2   & -1 & 4 \\
 0 & 1 & 5 \\
 6 &  3 & -4
 \end{matrix}
 \right). $ Encuentre $M_{13}$ y $M_{32}$.

\vspace{.2cm}

\textbf{Soluci\'on:} Eliminando el primer rengl\'on y la tercer
columna de $A$ se obtiene $M_{13} = \left( \begin{matrix}
 0 & 1 \\
 6 &  3
 \end{matrix}
 \right).$

\vspace{.2cm}

 De manera similar, si se elimina el tercer rengl\'on y la segunda
 columna se obtiene
 $M_{32} = \left( \begin{matrix}
 2 & 4 \\
 0 &  5
 \end{matrix}
 \right).$
\end{ejemplo}


\begin{definicion}
Sea $A$ una matriz de $n \times n$. El  $\textbf{cofactor ij}$ de
$A$, denotado por $A_{ij}$, est\'a dado por
\begin{equation}
\label{cofactor}
 A_{ij} = (-1)^{i + j} |M_{ij}|
\end{equation}

Estos es, el cofactor $ij$ de $A$ se obtiene tomando el determinante
del menor $ij$  y multiplic\'andolo por $(-1)^{i+j}$. Observe que

\[
(-1)^{i+j} = \left{
\begin{cases}
 1 & \text{si $i+j$ es  par} \\ -1 & \text{si $i+j$ es impar}
\end{cases}
\]

\end{definicion}

\begin{ejemplo}
 Si $ A = \left(
 \begin{matrix}
 2   & -1 & 4 \\
 0 & 1 & 5 \\
 6 &  3 & -4
 \end{matrix}
 \right). $\\
\vspace{.2cm}

Del ejemplo anterior tenemos que
 $M_{13} = \left(
\begin{matrix}
 0 & 1 \\
 6 &  3
 \end{matrix}
 \right)$ y $M_{32} = \left( \begin{matrix}
 2 & 4 \\
 0 &  5
 \end{matrix}
 \right)$. Entonces los cofactores $A_{13}$ y $A_{32}$ de la matriz
 $A$ se obtienen usando formula $\ref{cofactor}$ como sigue
\begin{align*}
A_{13} &= (-1)^{1+ 3}|M_{13} | = (-1)^4  (0 \cdot 3 - 1 \cdot 6) =-6
\\
A_{32} &= (-1)^{3+ 2}|M_{32} | = (-1)^5  (2 \cdot 5 - 0 \cdot 4)
=-10
\end{align*}
\end{ejemplo}

\begin{definicion}
(\textbf{Determinante $n \times n$}) Sea $A$ una matriz $n \times
n$. Entonces el determinante de $A$, denotado por $\det A$ o $|A|$,
est\'a dado por
\begin{equation}
\label{determinante}
\begin{align*}
\det A &= |A| = a_{11} A_{11} + a_{12}A_{12} + \cdots + a_{1n}A_{1n
} \\
&= \limits\sum_{k = 1}^{n} a_{1k}A_{1k}
\end{align*}
\end{equation}
La expresi\'on al lado derecho de $(\ref{determinante})$ se llama
\textbf{expansi\'on por cofactores. }
\end{definicion}

\begin{definicion}
(\textbf{La adjunta}). Sea $A$ una matriz de $n \times n$, y sea
$B$, dada por
\[
 B =\left[
  \begin{matrix}
     A_{11}   & A_{12}  & \cdots   & A_{1n} \\
     A_{21}   & A_{22}  & \cdots   & A_{2n} \\
    \vdots    & \vdots  &          & \vdots \\
      A_{n1}  & A_{n2}  & \cdots  & A_{nn}
  \end{matrix}
  \right]
  \]
es decir, la matriz de sus cofactores. Entonces la \textbf{ adjunta}
de $A$, escrito adj $A$, es la transpuesta de la matriz $B$ de $n
\times n$; es decir

\[
 \text{adj A} = B^T =\left[
  \begin{matrix}
     A_{11}   & A_{21}  & \cdots   & A_{n1} \\
     A_{12}   & A_{22}  & \cdots   & A_{n2} \\
    \vdots    & \vdots  &          & \vdots \\
      A_{1n}  & A_{2n}  & \cdots  & A_{nn}
  \end{matrix}
  \right]
  \]

\begin{ejemplo}
 Sea $ A = \left(
 \begin{matrix}
 2   & 4 & 3 \\
 0 & 1 & -1 \\
 3 &  5 & 7
 \end{matrix}
 \right). $ Calcule adj $A$.

\vspace{.2cm}

\textbf{Soluci\'on:}\\
\vspace{.2cm}

Se tiene $A_{11} = \left|
\begin{matrix}
1  & -1 \\
 5 &  7
 \end{matrix}
 \right| = 12$, $A_{12} = -\left| \begin{matrix}
 0 & -1\\
 3 &  7
 \end{matrix}
 \right| = -3$, $A_{13} = -3$, $A_{21} = -13$, $A_{22} = 5$, $A_{23} =
 2$, $A_{31}= -7$, $A_{32} = 2$ y $A_{33} = 2.$ As\'{\i},

\vspace{.4cm}

$
  B =\left(
  \begin{matrix}
  12   & -3  & -3 \\
     -13  & 5  & 2 \\
  -7   & 2  &      2
  \end{matrix}
  \right)$  y \hspace{.3cm} $ \text{adj A} = B^T = \left(
 \begin{matrix}
 12   & -13 & -7 \\
 -3 & 5 & 2 \\
 -3 &  2 & 2
 \end{matrix}
 \right). $
\end{ejemplo}
\end{definicion}

\textbf{Regla de Sarrus}
\medskip

Hay una forma alternativa de calcular determinantes de orden 3. Se
a\~{n}aden a la derecha sus dos primeras columnas de una matriz $A$ dada, donde

\[
 A = \left(
 \begin{matrix}
 a_{11}   & a_{12} & a_{13} \\
 a_{21} & a_{22} & a_{23} \\
 a_{31} &  a_{32} & a_{33}
 \end{matrix}
 \right)
\]

Primero se multiplican las tres l\'{\i}neas que van de arriba a la izquireda a abajo a la derecha, poniendo el signo $+$ a los productos.
\begin{equation}
\label{s1}
 a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32}
\end{equation}
Luego se multiplican las tres l\'{\i}neas que van de abajo a la
izquierda a arriba a la derecha, poniendo el signo $-$ a a los
productos.
\begin{equation}
\label{s2}
 -a_{31}a_{22}a_{13} - a_{32}a_{23}a_{11}  - a_{33}a_{21}a_{12}
\end{equation}
La suma de los t\'erminos de (\ref{s1}) y (\ref{s2}) es igual a $A$.
\medskip

Sea
\[ A =
\left(
\begin{matrix}
1 &  2 & 3  \\
-4 & 5 & 1 \\
-2 & 1 & -3
\end{matrix}
\right)
\]
Entonces para calcular el determinante de la matriz $A$ consideremos el
si\-gui\-en\-te arreglo

\[
\begin{matrix}
1  &  2  &  3  & 1   & 2 \\
-4 &  5  &  1  & -4  & 5   \\
-2 &  1  & -3  & -2  & 1
\end{matrix}
\]
Aplicando la regla de Sarrus tenemos que
\begin{align*}
 \mid A \mid &=  1 \cdot 5 \cdot (-3) + 2 \cdot 1 \cdot (-2) + 3 \cdot
 (-4) \cdot 1 - (-2) \cdot 5 \cdot 3 - 1  \cdot 1 \cdot 1 - (-3) \cdot
 (-4) \cdot 2 \\
&= -15 - 4  -12 +30 -1 -24 \\
&= - 26
\end{align*}
Por tanto $\mid A \mid = - 26$


\subsubsection{Propiedades de los determinantes}

El c\'alculo de los determinantes se simplifica utilizando varias propiedades. En lo siguiente $A$ denota una matriz cuadrada.

\vspace{.2cm}

\textbf{Propiedades de los determinantes}:

\begin{enumerate}
  \item Si cada una de las entradas de un rengl\'on (o columna) de $A$ es 0, entonces $\mid A \mid = 0$.
  \item Si dos renglones (o columnas) de $A$ son id\'enticos, $\mid A\mid = 0.$
  \item Si $A$ es triangular superior (o inferior), entonces $\mid A \mid$ es igual al producto de las entradas de la diagonal principal.
  \item Si $B$ es la matriz que se obtiene sumando un m\'ultiplo de un rengl\'on (o columna) de  $A$ a otro rengl\'on (columna), entonces $\mid A\mid =  \mid B\mid$.
  \item Si $B$ es la matriz que se obtiene multiplicando cada entrada de un rengl\'on (o columna) de $A$ por el mismo n\'umero $k$, entonces \\ $\mid B \mid = k \mid A \mid .$
\end{enumerate}

\subsection{Matriz inversa}
\subsubsection{Definici\'on}
\begin{definicion}
Sea $A$ una matriz $n$ por $n$, una matriz $B$ $n$ por $n$ que tiene
la propiedad de que $AB = BA = I_n$ se le llama la \textbf{matriz
inversa} de $A$ y se le denota por $B = A^{-1}$. M\'as a\'un, se
dice que $A$ es \textbf{ matriz invertible} en este caso.
\end{definicion}

\begin{teorema}
Una matriz cuadrada tiene inversa \Longleftrightarrow
 \mid A \mid \ne 0.
\end{teorema}

\begin{definicion}
Una matriz $A$ se llama \textbf{matriz singular} si $\mid A \mid  =
0$ y  \textbf{matriz no singular} si $\mid A \mid \ne 0$. Entonces
una matriz tiene inversa si y s\'olo si es no singular.
\end{definicion}

Sea
\[
A =
   \left(
  \begin{matrix}
   a  & b       \\
   c  & d
  \end{matrix}
  \right).
\]
Si $\mid A \mid = ad - bc \ne 0$, entonces
\[
A^{-1} = \frac{1}{ad - bc}
   \left(
  \begin{matrix}
   d    & -b       \\
   -c  &  a
  \end{matrix}
  \right).
\]


\begin{ejemplo}
La matriz inversa de la matriz:
\begin{equation*}
A =
   \left[
  \begin{matrix}
   1    & 2      \\
   3  &  4
  \end{matrix}
  \right]
\end{equation}
\]
es dada por:
\begin{align*}
A^{-1} &= \frac{1}{4-6}
\left[
  \begin{matrix}
   4    & -2      \\
   -3  &  1
  \end{matrix}
  \right] \\
\hspace{.3cm}
 &=
\left[
  \begin{matrix}
   \frac{4}{-2}    & \frac{-2}{-2}       \\
   \frac{-3}{-2}  &  -\frac{1}{2}
  \end{matrix}
  \right] \\
\hspace{.3cm}
&=
   \left[
  \begin{matrix}
   -2    & 1       \\
   \frac{3}{2}  &  -\frac{1}{2}
  \end{matrix}
  \right]
\end{align*}

Puesto que

\begin{align*}
AA^{-1} & =\left[
  \begin{matrix}
   1    & 2      \\
   3  &  4
  \end{matrix}
  \right]
   \left[
  \begin{matrix}
   -2
    & 1       \\
   \frac{3}{2}  &  -\frac{1}{2}
  \end{matrix}
  \right]=
   \left[
  \begin{matrix}
   1    & 0       \\
   0  &  1
  \end{matrix}
  \right] = I_2 \\
\hspace{.3cm}
A^{-1}A & =
   \left[
  \begin{matrix}
   -2    & 1       \\
   \frac{3}{2}  &  -\frac{1}{2}
  \end{matrix}
  \right]
  \left[
  \begin{matrix}
   1    & 2      \\
   3  &  4
  \end{matrix}
  \right]=
   \left[
  \begin{matrix}
   1    & 0       \\
   0  &  1
  \end{matrix}
  \right] = I_2
\end{align*}
\end{ejemplo}

\vspace{.2cm}

\subsubsection{Propiedades}

\vspace{.2cm}


Propiedades de la matriz inversa: Sea $A$ y $B$ matrices invertibles
$n \times n$. Entonces:

\begin{itemize}
\item $(A^{-1})^{-1} = A$.
\item $(AB)^{-1} =B^{-1} A^{-1}$
\item La traspuesta de $A$ es invertible y $(A^T)^{-1} = (A^{-1})^T.$
\item $(\lambda A)^{-1} = c^{-1} A^{-1}$, si $\lambda \in \Bbb{R}, \lambda \ne 0.$
\end{itemize}

En una matriz $A$ $m$ por $n$  se tienen tres operaciones elementales
de filas:
\begin{enumerate}
   \item[1.] Multiplicaci\'on de una fila de A por un n\'umero $c$
    distinto de cero.
   \item[2.] Remplazo de la r-\'esima fila de A por la fila $r$ m\'as $c$
   veces la fila $s$, donde $c$ es cualquier n\'umero y $r$ es
   distinto de $s$.
   \item[3.] Intercambio de dos filas de $A$.
\end{enumerate}

\hspace{.2cm}

Si $A$ y $B$ son dos matrices $m$ por $n$ sobre los n\'umeros reales,
se dice que $B$ es equivalente por filas a $A$ si $B$ se obtiene de A
por una sucesi\'on finita de operaciones elementales de filas.

\vspace{.2cm}

Se puede ver que si A es inversible, entonces A es equivalente por filas
a la matriz identidad $I_n$. Mas a\'un, al reducir la matriz A a la matriz
identidad $I_n$ por medio de una sucesi\'on de operaciones elementales
de filas, la inversa de A se obtiene al aplicar la misma sucesi\'on
de operaciones a la matriz identidad.

\newpage
\setcounter{page}{1}
\hspace{5cm}  \textbf{TAREA 1: MATRICES}

\vspace{.2cm}

Trabajo en equipo. \\

\begin{enumerate}
\item Sea $A=\left[
  \begin{matrix}
   1  & 2      \\
   3  & 4
  \end{matrix}
  \right]$,
   $B=\left[
  \begin{matrix}
   0   & 1 \\
   -1  & 2
  \end{matrix}
 \right]$
y $\alpha=3$, $\beta=4$ calcular:\\
\begin{enumerate}
\item $\alpha A+\beta B$
\item $\alpha (B)$
\item $(\alpha-\beta)(A-B)$
\end{enumerate}
\item Obtener las matrices A + B, A - B y AB si:
\[
  A = \left[
  \begin{matrix}
   3    & 5     \\
   -7  &  2
  \end{matrix}
  \right],
\quad B =
 \left[
  \begin{matrix}
   -3    & 1 \\
   4  &    6
  \end{matrix}
 \right]
\]
\item Sean las siguientes matrices\\
\[
A=\left[
\begin{matrix}
1& -1\\
1&  0
\end{matrix}
  \right]
\qquad
B=
\left[
\begin{matrix}
-1& 0\\
1& 2
\end{matrix}
\right]
\]
\[
C=
\left[
\begin{matrix}
1& 2& 3\\
4& 5& 6
\end{matrix}
  \right]
\qquad
D=
\left[
\begin{matrix}
1& 2\\
3& 4\\
5& 6
\end{matrix}
\right]
\]

Calcular $ AB $, $\: BA $, $\:CD $, $ \:DA $, $\: C'B $
\vspace{.4cm}
\item
Cierto o falso: $ (AB)^2=A^2B^2 $, demuestra tu respuesta.
\item  Verificar que las matrices $A$ y $B$ satisfaces $(AB)^T = B^T
  A^T$, si:
\[
A =
   \left[
  \begin{matrix}
   1    & 0 & 0       \\
   0  &  0 & 1
  \end{matrix}
  \right]
, B =
 \left[
  \begin{matrix}
   4    & 3 \\
   1  &  1 \\
   0 & 2
  \end{matrix}
 \right]
\]
\item Sea $A=\left[
  \begin{matrix}
   1  & 3      \\
   0  & -2     \\
   -2 & -1
  \end{matrix}
  \right]$,
   $B=\left[
  \begin{matrix}
   1  & 2 \\
   0  & -1
  \end{matrix}
 \right]$ realizar:\\
\begin{enumerate}
\item $A \cdot A^{T}$
\item $B(I+B)$
\item $B^{2}$
\end{enumerate}
\item Dar los valores de $x$ y $y$ si:
\[
   \left[
  \begin{matrix}
   1    & 2      \\
   x - y  &  2
  \end{matrix}
  \right]
=
 \left[
  \begin{matrix}
   1    & y \\
   0  &    2
  \end{matrix}
 \right]
\]
\item Calcule el determinante de las siguientes matrices:
\begin{enumerate}
\item
\[
A =
\left[
  \begin{matrix}
   3    & 0  & 4\\
   2  &  3  & 2 \\
   0 & 5 & -1
  \end{matrix}
 \right]
\]
\item
\[
B =
\left[
  \begin{matrix}
   4    &  3 & 0  \\
   6  &  5 & 2  \\
  9 & 7 & 3
  \end{matrix}
 \right]
\]
\end{enumerate}
\item Calcule $\mid A^3 \mid $, donde:
\[
A =
\left[
  \begin{matrix}
   1    & 0  & 1 \\
   1  &  1 & 2 \\
   1 & 2 & 1
  \end{matrix}
 \right]
\]
\item Obtener la inversa de las siguientes matrices:
\begin{enumerate}
\item
\[
A= \left[
  \begin{matrix}
   3    & 2 \\
   -1  &  1
  \end{matrix}
 \right]
\]
 \item
\[
B =
\left[
  \begin{matrix}
   1  & 1  & 2 \\
   2  & -2 & 0 \\
   3  & 0  & 4
  \end{matrix}
 \right]
\]
\end{enumerate}
\end{enumerate}

\newpage
\setcounter{page}{1}
\begin{center}
\textbf{TAREA 2: MATRICES EN C\'OMPUTO}
\end{center}

\vspace{.5cm}

Trabajo en equipo. \\

Realicen en excel o en mathematica las siguientes operaciones matriciales.

\begin{enumerate}
\item Considerar las siguientes matrices
\[
A=
\left[
\begin{matrix}
2& 0& -3\\
4& 1& 5\\
\end{matrix}
\right]
 \qquad
B=
\left[
\begin{matrix}
7& -1& 4& 7\\
2& 5& 0& -4\\
-3& 1& 2& 3
\end{matrix}
\right]
\]
\[
C=
\left[
\begin{matrix}
1& 3\\
2& 5\\
-1& 2
  \end{matrix}
  \right]
\qquad
D=
\left[
\begin{matrix}
-2& 0\\
1& 4\\
-7& 5
  \end{matrix}
  \right]
\qquad
E=
\left[
\begin{matrix}
-1& 1\\
4& 6\\
-7& 3
  \end{matrix}
  \right]
\]
calcular las operaciones matriciales,
\begin{enumerate}
\item
AB
\item
3C
\item
C+D
\item
E-C
\item
-7C+3D
\item
2C-3D+4E
\end{enumerate}
\item Sea la siguiente matriz
\vspace{.3cm}
\[
X=
\left[
\begin{matrix}
1& 2\\
0& 1\\
1& 0\\
\end{matrix}
\right]
\]
\begin{enumerate}
\item Encontrar la matriz $P=X(X'X)^{-1}X'$
\vspace{.2cm}
\item
Encontrar $P'$ y calcular $ P'X $
\vspace{.2cm}
\item
Calcular $ PP $, $ P^3 $, $ P^4$
\vspace{.2cm}
\item
Obtener $ M=I-P $
\vspace{.2cm}
\item
Calcular $MM$, $ M^2 $, $ M^3$
\vspace{.2cm}
\item
Calcular $ MX $
\end{enumerate}
\item Encontrar en cada caso el determinante
\[
A=
\left[
\begin{matrix}
1& 2& -2& 0\\
2& 3& -4& 1\\
-1& -2& 0& 2\\
0& 2& 5& 3
\end{matrix}
\right]
\qquad
B=
\left[
\begin{matrix}
0& 0& 0& 1\\
0& 0& 1& 0\\
0& 1& 0& 0\\
1& 0& 0& 0
\end{matrix}
\right]
\]
\item Calcular la inversa de las siguientes matrices
\[
A=
\left[
\begin{matrix}
2& 1& 2\\
0& 3& -1\\
4& 1& 1
\end{matrix}
  \right]
\qquad
B=
\left[
\begin{matrix}
2& -1& 0\\
-1& 2& -1\\
0& -1& 2
\end{matrix}
\right]
\]
\item Sean las siguientes matrices
\[
A=
\left[
\begin{matrix}
1& -1\\
1& 0
\end{matrix}
  \right]
\qquad
B=
\left[
\begin{matrix}
-1& 0\\
1& 2\\
\end{matrix}
\right]
\]
\begin{enumerate}
\item Calcular $ AB $ y obtener su inversa, $ (AB)^{-1} $
\vspace{.1cm}
\item Verificar que $ (AB)^{-1}=(A)^{-1}(B)^{-1} $
\end{enumerate}
\end{enumerate}

\newpage
\setcounter{page}{1}
\subsection{Soluci\'on de sistemas de ecuaciones lineales}
\textbf{Introducci\'on}
\medskip

Cuando una situaci\'on debe describirse matem\'aticamente, no es raro que surja un conjunto de
ecuaciones. Por ejemplo, suponga que el administrador de una
f\'abrica establece un plan de producci\'on para dos modelos de un
producto nuevo. El modelo $A$ requiere de 4 piezas del tipo $I$ y 9
piezas de tipo $II$. El modelo $B$ requiere de 5 piezas del tipo $I$
y 14 piezas del tipo $II$. De sus proveedores, la f\'abrica obtiene
335 piezas del tipo $I$ y 850 piezas del tipo $II$ cada d\'{\i}a. \textquestiondown
Cu\'antos productos de cada modelo debe producir cada d\'{\i}a, de
modo que todas las piezas del tipo $I$ y piezas del tipo $II$ sean
utilizadas?
\medskip

Suponga que hacemos que $x$ igual al n\'umero de art\'{\i}culos del modelo $A$ fabricados cada
d\'{\i}a, y igual al n\'umero de art\'{\i}culos del modelo $B$. Entonces \'estos requieren de
$4x + 5y$ piezas del tipo $I$ y $9x + 14y$ piezas del tipo $II$. Como est\'an disponibles 335
y 850 piezas del tipo $I$ y $II$, respectivamente tenemos:
\begin{align*}
4x + 5y = 335 \\
9x + 14y = 850
\end{align*}
A este conjunto de ecuaciones le llamamos \textbf{sistema} de dos ecuaciones lineales en las
variables (o inc\'ognitas) $x$ y $y$. El problema es encontrar valores de $x$ y $y$ para los cuales
ambas ecuaciones sean verdaderas de manera simult\'anea. Estos valores se llaman soluciones del
sistema.
\medskip

Como las ecuaciones  son lineales, sus gr\'aficas son l\'{\i}neas rectas; lla\-me\-mos\-las
$L_1$ y $L_2$. Ahora, las coordenadas de cualquier punto sobre una l\'{\i}nea satisfacen
las ecuaciones de esa l\'{\i}nea; esto es, hacen la ecuaci\'on verdadera, Por tanto, las coordendas
de cualquier punto de intersecci\'on de $L_1$ y $L_2$ satisfacen ambas ecuaciones. Estos significa
que un punto de intersecci\'on da una soluci\'on del sistema.
\medskip

Si $L_1$ y $L_2$ se dibujan en el mismo plano, existen tres posibles situaciones:
\begin{enumerate}
   \item[1.] $L_1$ y $L_2$ pueden intersecarse en exactamente un punto, digamos $(x_0,y_0)$. Por tanto,
   el sistema tiene soluci\'on $x= x_0$ y $y = y_0$.
\begin{ejemplo}
El sistema de ecuaciones tiene solución unica
\begin{align*}
 x - y &= 1 \\
 x + y &= 5
\end{align*}
\end{ejemplo}
   \begin{center}
   \centering
\includegraphics[width= 0.4\textwidth,height=0.3
\textheight]{Sistem1.pdf}
\end{center}
   \item[2.] $L_1$ y $L_2$ pueden ser parelelas y no tener puntos en com\'un. En este caso no existe
   soluci\'on.
\begin{ejemplo}
Sistema de ecuaciones sin solución
\begin{align*}
 x + y &= 7 \\
2x +2y &= 13
\end{align*}
\end{ejemplo}
   \begin{center}
   \centering
\includegraphics[width= 0.4\textwidth,height=0.3
\textheight]{Sistem2.pdf}
\end{center}
   \item[3.] $L_1$ y $L_2$ pueden ser la misma recta. Por tanto las coordenadas de cualquier punto
   sobre la recta son una soluci\'on del sistema. En consecuencia, existe un n\'umero infinito de
   soluciones.
\begin{ejemplo}
Sistema de ecuaciones con un número infinito de soluciones
\begin{align*}
 x + y &= 7 \\
2x +2y &= 14
\end{align*}
\end{ejemplo}
   \begin{center}
   \centering
\includegraphics[width= 0.4\textwidth,height=0.3
\textheight]{Sistem3.pdf}
\end{center}
\end{enumerate}

M\'etodos algebraicos para resolver un sistema de ecuaciones en dos va\-ria\-bles:

\begin{enumerate}
 \item M\'etodo de eliminaci\'on por adici\'on.
 \item M\'etodo de eliminaci\'on por sustituci\'on.
 \item M\'etodo de eliminaci\'on por igualaci\'on.
\end{enumerate}

\begin{ejemplo}
Encontrar el punto de equilibio si las ecuaciones de oferta  y demanda de un producto son $ p =  \frac{1}{300}q + 8$ y  $p =
-\frac{1}{180}q + 12$ respectivamente.

\vspace{.2cm}

\textbf{Soluci\'on:}

Sustituyendo $p$  por $\frac{1}{300} q  + 8 $ en la ecuaci\'on de
demanda, obtenemos

\begin{align*}
\frac{1}{300} q  + 8 &= -\frac{1}{180} q + 12, \\
\left( \frac{1}{300} + \frac{1}{180}   \right) q  &= 4, \\
 q &= 450.
\end{align*}

\vspace{.2cm}

Por tanto,

\begin{align*}
 p &= \frac{1}{300} (450) + 8 \\
  &=9.50
\end{align*}

y el punto de equilibrio es $(450, 9.50)$.
\end{ejemplo}

\begin{center}
\centering
\includegraphics[width= 0.5\textwidth,height=0.3
\textheight]{Sistem4.pdf}
\end{center}

\subsubsection{Representaci\'on matricial de un sistema de ecuaciones
li\-nea\-les}

\begin{definicion}
Una ecuaci\'on lineal en las variables $x_1,x_2,...,x_n$ es una ecuaci\'on de la forma:
\[
  a_1x_1 + a_2x_2 + \cdots + a_n x_n = b
\]
\end{definicion}

\begin{definicion}
Un sistema de ecuaciones de $m$  ecuaciones lineales en las incognitas $x_1,...,x_n$ es un
colecci\'on de ecuaciones de la forma:

\begin{equation*}
  \begin{matrix}
     a_{11}x_1 \, +  & \cdots   & + \, a_{1n} x_n & = b_1\\
    \vdots    &          & \vdots            & \vdots     \\
      a_{m1} x_1 \,  + & \cdots        & + \, a_{mn} x_n & =
       b_n
  \end{matrix}
\end{equation*}
\end{definicion}


Dado el sistema, este se puede representar en forma matricial


\[
\begin{equation*}
\left[
  \begin{matrix}
     a_{11}   & \cdots   & a_{1n} \\
    \vdots    &          & \vdots \\
      a_{m1}  & \cdots        & a_{mn}
  \end{matrix}
  \right]
   \left[
  \begin{matrix}
   x_1 \\
   \vdots \\
   x_n
\end{matrix}
  \right]
   =
 \left[
  \begin{matrix}
     b_1 \\
     \vdots \\
     b_n
  \end{matrix}
 \right]
\]
\end{definicion}

\begin{ejemplo}
El sistema de ecuaciones

\begin{align*}
4x + 5y &=  335 \\
9x + 14y &= 850
\end{align*}

se representa matricialmente por

\[
\begin{equation*}
\left[
  \begin{matrix}
     4  &  5 \\
     9  &  14
  \end{matrix}
  \right]
   \left[
  \begin{matrix}
   x \\
   y
\end{matrix}
  \right]
   =
 \left[
  \begin{matrix}
     335 \\
  850
  \end{matrix}
 \right]
\]
\end{ejemplo}

\begin{definicion}
Una soluci\'on del sistema es una n-ada $(c_1,...,c_n)$ tal que $ a_{i1}c_1 + a_{i2}c_2 + \cdots
+ a_{in} c_n = b$ para cada $i = 1, ...,n$. Cuando el sistema tiene soluci\'on se dice consistente, de otra forma es
inconsistente.
\end{definicion}

\vspace{.2cm}

\subsubsection{M\'etodos de soluci\'on: Forma escalonada, el m\'etodo de Gauss-Jordan, inversa de una matriz, regla de Cramer.}

\vspace{.2cm}


\textbf{Forma escalonada y el m\'etodo de Gauss-Jordan }

\vspace{.2cm}

Una t\'ecnica adecuada para resolver  sistema de ecuaciones lineales
de gran tama\~{n}o es el \textbf{m\'etodo de eliminaci\'on} de
Gauss-Jordan. Este m\'etodo comprende una serie de operaciones sobre
un sistema de ecuaciones lineales para obtener en cada paso un
\textbf{sistema equivalente}. La reducci\'on concluye cuando el
sistema original ha sido transformado de modo que aparezca  en
cierta forma can\'onica de la pueda leerse la soluci\'on con
facilidad.

\begin{definicion}
Una matriz se le llama \textbf{reducida por renglones}, si:
\begin{enumerate}
  \item Cada rengl\'on compuesto  completamente de ceros se encuentra bajo los renglones con alg\'un valor distinto de cero.
  \item El primer valor distinto de cero en cada rengl\'on es 1 (llamado el 1 principal)
  \item En cualesquiera dos renglones sucesivos (distintos de cero), el 1 principal en el rengl\'on inferior se encuentra a la derecha  en el rengl\'on superior.
  \item Si una columna contiene un 1 principal, entonces los dem\'as valores en esas columnas son ceros.
\end{enumerate}
\end{definicion}

\vspace{.2cm}

\begin{definicion} Un sistema de ecuaciones de $m$  ecuaciones
lineales en las incognitas $x_1,...,x_n$

\begin{equation*}
  \begin{matrix}
     a_{11}x_1 \, +  & \cdots   & + \, a_{1n} x_n & = b_1\\
    \vdots    &          & \vdots            & \vdots     \\
      a_{m1} x_1 \,  + & \cdots        & + \, a_{mn} x_n & =
       b_n
  \end{matrix}
\end{equation*}

se puede representar mediante la matriz:

\begin{equation*}
\left[
  \begin{matrix}
     a_{11} \,   & \cdots   &  \, a_{1n}  &  b_1\\
    \vdots    &          & \vdots            & \vdots     \\
      a_{m1}  \,   & \cdots        &  \, a_{mn}  & b_n
  \end{matrix}
  \right]
\end{equation*}

\vspace{.2cm}

A la representaci\'on matricial anterior se le llama \textbf{matriz aumentada del sistema de ecuaciones.}
\end{definicion}

\vspace{.2cm}

\textbf{El m\'etodo de eliminaci\'on de Gauss-Jordan}

\begin{enumerate}
  \item Se escribe la matriz aumentada correspondiente al sistema lineal.
  \item En caso necesario, se intercambian renglones para obtener una matriz aumentada donde el primer valor en el primer rengl\'on sea distinto de cero. Luego se pivotea la matriz con respecto a este valor.
  \item En caso necesario, se intercambia el segundo rengl\'on con otro para obtener una matriz aumentada donde el segundo valor del segundo rengl\'on sea distinto de cero. Luego se pivotea con respecto de este valor.
  \item Se contin\'ua hasta que la \'ultima matriz tenga una forma reducida por renglones.
\end{enumerate}

El siguiente teorema nos permite determinar si un sistema homog\'eneo tiene una soluci\'on \'unica (la soluci\'on trivial) o un n\'umero infinito de soluciones.

\begin{teorema}
Sea $A$ la matriz reducida de un sistema homog\'eneo de $m$ ecuaciones lineales con $n$ inc\'ognitas. Si $A$ tiene exactamente $k$ renglones diferentes de cero, entonces $k \leq n$. Adem\'as:
\begin{enumerate}
 \item Si $k \leq n$, el sistema tiene un n\'umero infinito de soluciones.
 \item Si $k = n$, el sistema tiene una \'unica soluci\'on (la soluci\'on trivial).
\end{enumerate}
\end{teorema}

\vspace{.2cm}

\textbf{Inversa de una matriz}

\vspace{.2cm}

Si $A$ es inversible, el sistema de ecuaciones:
\[
           AX =B
\]
donde:
\[
\begin{equation*}
A =   \left[
  \begin{matrix}
     a_{11}   & \cdots   & a_{1n} \\
    \vdots    &          & \vdots \\
      a_{m1}  & \cdots        & a_{mn}
  \end{matrix}
  \right]
\end{equation*}
\begin{equation*}
X =
   \left[
  \begin{matrix}
   x_1 \\
   \vdots \\
   x_n
\end{matrix}
  \right] \hspace{.2cm}
 \texct{  y  }
 \hspace{.2cm}  B =
 \left[
  \begin{matrix}
     b_1 \\
     \vdots \\
     b_n
  \end{matrix}
 \right]
\end{equation*}
\]
tiene como \'unica soluci\'on
\begin{equation}
\label{sistema}
X = A^{-1}B
\end{equation}

\begin{ejemplo}
Por ($\ref{sistema}$) se tiene que la soluci\'on del sistema de ecuaciones:
\[
\begin{aligned}
 3x_1 + 2x_2 & = 1 \\
 4x_1 + 3x_2 & = 5
\end{aligned}
\]
es:
\[
X = A^{-1}B =
\begin{equation*}
   \left[
  \begin{matrix}
   3    & -2       \\
   -4  &  3
  \end{matrix}
  \right]
  \left[
  \begin{matrix}
   1  \\
   5
  \end{matrix}
  \right] =
  \left[
  \begin{matrix}
   -7  \\
    11
  \end{matrix}
  \right]
\end{equation}
\]
Por tanto, la soluci\'on es:
\[
X =
\begin{equation*}
\left[
 \begin{matrix}
   x_1  \\
   x_2
  \end{matrix}
  \right]
=
\left[
 \begin{matrix}
   -7  \\
    11
  \end{matrix}
  \right]
\end{equation}
\]
es decir, $x_1 = -7$ y $x_2 = 11$.
\end{ejemplo}

\begin{ejemplo}
\textbf{Equilibrio entre oferta y demanda}}
\medskip

El equilibrio del mercado de bienes (el equilibrio del mercado) se produce cuando la cantidad demandada por los consumidores ($Q_d$) y la cantidad ofrecida $(Q_s)$ por los productores de los bienes de servicio son iguales. De manera equivalente, el equilibrio del mercado se produce cuando el precio que un consumidor est\'a dispuesto a pagar $(P_d)$ es igual al precio que un productor est\'a dispuesto a aceptar $(P_s)$. La condici\'on de equilibrio, por lo tanto, se expresa como
\[
  Q_d = Q_s = Q  \quad  \text{ y } \quad  P_d = P_s  = P
\]

Las funciones de demanda y la oferta de un producto son  dadas por:
 \begin{align*}
 \text{Funci\'on de demanda: }  \quad   P &= 100 - \frac{1}{2} Q \\
  \text{Funci\'on de oferta:} \quad   P &= 10 + \frac{1}{2} Q
 \end{align*}

Calcular el precio de equilibrio y la cantidad algebraicamente y gr\'aficamente.

\vspace{.2cm}

\textbf{Soluci\'on:}

\vspace{.2cm}
De las funciones de demanda y oferta obtenemos el sistema de ecuaciones:
\begin{align*}
P + \frac{1}{2} Q &= 100 \\
P - \frac{1}{2} Q &= 10
\end{align*}

Este sistema escrit\'o con matrices:
\[
A =
  \left[
  \begin{matrix}
   1    & \frac{1}{2}      \\
   1 &  -\frac{1}{2}
  \end{matrix}
  \right]
\left[
  \begin{matrix}
   P      \\
   Q
  \end{matrix}
  \right] = \left[
  \begin{matrix}
   100 \\
   10
  \end{matrix}
  \right]
\]

Como la matriz inversa de
 \[ A =
  \left[
  \begin{matrix}
   1    & \frac{1}{2}      \\
   1 &  -\frac{1}{2}
  \end{matrix}
  \right]
 \]
es la matriz

\[ A^{-1} =
  \left[
  \begin{matrix}
   \frac{1}{2}    & \frac{1}{2}      \\
   1 &  -1
  \end{matrix}
  \right]
  \]

Entonces

\[
 \left[
 \begin{matrix}
   P  \\
   Q
  \end{matrix}
  \right] =
\[
  \left[
  \begin{matrix}
   \frac{1}{2}    & \frac{1}{2}      \\
   1 &  -1
  \end{matrix}
  \right]
 \left[
 \begin{matrix}
   100  \\
    10
  \end{matrix}
  \right]
  =
    \left[
 \begin{matrix}
   55  \\
    90
  \end{matrix}
  \right]
\]

\vspace{.2cm}

Por lo tanto, el precio de equilibrio es $P = 55$ y la cantidad de equilibrio es $Q = 90$.
\end{ejemplo}
\medskip

La siguiente figura ilustra el  equilibrio del mercado, en el punto cuando la cantidad es 90, y precio de equilibrio \$55. El consumidor paga \$55 por la mercancía que es tambi\'en el precio que recibe el productor por las mercanc\'{\i}as.
\end{ejemplo}

\begin{figure}[h]
\begin{center}
\includegraphics[width= 0.6
\textwidth,height=0.3
\textheight]{O-D.pdf}
\end{center}
\caption{Equilibrio de mercado}
\label{Figura13}
\end{figure}

\begin{ejemplo}
(\textbf{Equilibrio en el mercado de trabajo})
El equilibrio del mercado de trabajo se produce cuando la mano de obra demandada por las empresas $(L_d)$ es igual a la de la mano de obra ofrecida por los trabajadores $(L_s) $ o, equivalentemente, cuando el salario que las empresas est\'a dispuesto a ofrecer $(w_s)$ es igual al salario que los trabajadores están dispuestos a aceptar $(w_d)$. El Equilibrio del mercado de trabajo, por lo tanto, se expresa como
\[
  L_d = L_s = L  \quad  \text{ y } \quad  w_d = w_s  = w
\]
de nuevo, en la soluci\'on para el equilibrio del mercado de trabajo, $L$ y $w$ se refieren al n\'umero de unidades de trabajo y el salario de equilibrio, respectivamente.
\medskip

La funci\'on de demanda de trabajo y la funciones de oferta se dan como
 \begin{align*}
 \text{Funci\'on de demanda: }  \quad   w &= 9 - .6 L \\
  \text{Funci\'on de oferta:} \quad   w &= 2 + .4 L
 \end{align*}


\vspace{.2cm}

\textbf{Soluci\'on:}

\vspace{.2cm}
De las funciones de demanda y oferta obtenemos el sistema de ecuaciones:
\begin{align*}
w +  0.6 L &= 9 \\
w - 0.4 L &= 2
\end{align*}


Este sistema escrit\'o con matrices:

\[
  \left[
  \begin{matrix}
   1    & 0.6      \\
   1 &  0.4
  \end{matrix}
  \right]
\left[
  \begin{matrix}
   w      \\
   L
  \end{matrix}
  \right] = \left[
  \begin{matrix}
   9 \\
   2
  \end{matrix}
  \right]
\]

Como la matriz inversa de
 \[ A =
  \left[
  \begin{matrix}
   1    & 0.6      \\
   1 &  0.4
  \end{matrix}
  \right]
  \]
es la matriz

\[ A^{-1} =
  \left[
  \begin{matrix}
   3    & -2      \\
  -12  &  12
  \end{matrix}
  \right]
  \]

Entonces

\[
 \left[
 \begin{matrix}
   w  \\
   L
  \end{matrix}
  \right] =
\[
  \left[
  \begin{matrix}
   3    & -2      \\
  -12 &  12
  \end{matrix}
  \right]
 \left[
 \begin{matrix}
   9  \\
   2
  \end{matrix}
  \right]
  =
    \left[
 \begin{matrix}
   4.8 \\
    7
  \end{matrix}
  \right]
\]

La siguiente figura ilustra el punto de equilibrio del mercado laboral,
con n\'umero de equilibrio de trabajadores, 7 y \$4.80
el salario de equilibrio. Cada trabajador recibe \$4.80  por hora
de sus servicios laborados que tambi\'en el salario que la empresa est\'a dispuesta a pagar.
\end{ejemplo}

\begin{figure}[h]
\begin{center}
\includegraphics[width= 0.6
\textwidth,height=0.3
\textheight]{w-l.pdf}
\end{center}
\caption{Equilibrio en el mercado de trabajo}
\label{Figura13}
\end{figure}

\begin{ejemplo}
Una econom\'{\i}a cerrada es descrita por el sistema de ecuaciones que da el equilibrio entre el mercado de bienes y el mercado de dinero, la relaci\'on entre  la $IS$ y la $LM$. El mercado de bienes (la parte $IS$ del modelo) es  descrito por:
\begin{align*}
      Y &= C + I + G \\
      C &= 15 + 0.8 (Y-T) \\
      T &= -25 + 0.25 Y \\
      I &= 65 - R \\
      G &= 94
\end{align*}
donde $C$ es el gasto de consumo, $T$ es el  impuesto sobre los ingresos , $Y$ es la producci\'on total, $I$ es el gasto de inversi\'on, $R$ es la tasa de interes y $G$ es el gasto del gobierno.
\begin{align*}
 L &= 5Y -50 R \\
 M &= 1,500
\end{align*}
donde $L$ es la demanda de dinero y $M$ es la oferta de dinero fija. Encontrar el nivel de equilibrio de  $Y$ y $R$. \\

\textbf{Soluci\'on:}

\vspace{.2cm}

Expresamos el sistema de ecuaciones anterior en la forma
\[
    AX = B
\]

donde $A$ es una matriz $2 \times 2$ de coeficientes, \textbf{X} es
el vector de variables $2 \times 1$ con entradas $Y$ y $R$, y
\textbf{B} es el vector de constantes $2 \times 1$. Primero
resolveremos el equilibrio en  el mercado de bienes y dinero,
obteniendo las funciones $IS$ y $LM$  y luego ponemos las dos juntas.
La funci\'on $IS$ se obtiene de $Y = C + I + G$, como sigue:
\begin{align*}
   Y &= 15 + 0.8 Y + -0.8(-25 + 0.25 Y) + 65 - R -94 \\
   Y(1-0.8 + 0.2) &= 15 + 20 + 65 + 94- R \\
   Y &= 485 - 2.5 R
\end{align*}

La funci\'on $LM$  es entonces dada de $M = L$:
\[
    1,500 = 5Y - 50 R \quad  \text{o} \quad Y = 300 + 10 R
\]
buscando entre las relaciones $IS$ y $LM$ como sistema de ecuaciones tenemos:
\begin{align*}
     Y + 2.5R &= 485  \\
     Y - 10R &= 300
\end{align*}
El cual se representa matricialmente por:
 \[
 \left[
  \begin{matrix}
   1    &  2.5        \\
   1  &  -10
  \end{matrix}
  \right] \cdot
  \left[
  \begin{matrix}
   Y  \\
   R
  \end{matrix}
  \right] =
  \left[
  \begin{matrix}
   485 \\
   300
  \end{matrix}
  \right]
\end{equation}
\]
Resolviendo para $Y$ y $R$ tenemos:
\begin{align*}
 \left[
  \begin{matrix}
   Y  \\
   R
  \end{matrix}
  \right] &=
  \left[
  \begin{matrix}
   1    &  2.5        \\
   1  &  -10
  \end{matrix}
  \right]^{-1}
  \left[
  \begin{matrix}
   485 \\
   300
  \end{matrix}
  \right] \\
 &= \left[
  \begin{matrix}
   0.8    &  0.2        \\
   0.08  &  -0.08
  \end{matrix}
  \right]
  \left[
  \begin{matrix}
   485 \\
   300
  \end{matrix}
  \right] \\
  &=\left[
  \begin{matrix}
   448 \\
   14.8
  \end{matrix}
  \right]
 \end{align*}
El nivel de equilibrio  de producci\'on de esta economi\'{\i}a es 448 y la tasa de interes 14.8 \%. Notemos que como el nivel de ingresos, impuesto sobre los ingresos es $T = -25 + 0.25 (448) = 87$, mientras que el gasto p\'ublico es $G = 94$. El d\'eficit p\'ublico corriente es por lo tanto $T - G = -7.$
\end{ejemplo}

\begin{figure}[h]
\begin{center}
\includegraphics[width= 0.55
\textwidth,height=0.27
\textheight]{IS-LM.pdf}
\end{center}
\caption{Modelo IS-LM de una economía cerrada}
\label{Figura13}
\end{figure}

\vspace{.2cm}

\textbf{Regla de Cramer}

\vspace{.2cm}

Una de las aplicaciones m\'as importantes de los determinantes es
resolver ciertos tipos de sistemas de ecuaciones lineales.

\vspace{.2cm}

Se va a estudiar el siguiente m\'etodo, conocido como la \textbf{regla de Cramer} para resolver sistemas de ecuaciones lineales.

\vspace{.2cm}


Sea un sistema de $n$ ecuaciones lineales con $n$ inc\'ognitas dado por:


\begin{equation*}
  \begin{matrix}
     a_{11}x_1 \, +  & \cdots   & + \, a_{1n} x_n =c_1\\
    \vdots    &          & \vdots \\
      a_{n1} x_1 \,  + & \cdots        & + \, a_{nn} x_n =c_n
  \end{matrix}
\end{equation*}

Si el determinante $\Delta$ de la matriz de los coeficientes $A$ es diferente de cero, entonces el sistema tiene una \'unica soluci\'on. Adem\'as, la soluci\'on esta dada por:
\[
 x_1  = \frac{\Delta_1}{\Delta}, \, ..., \, x_n = \frac{\Delta_n}{\Delta},
\]

donde $\Delta_k$, es el determinante de la matriz obtenida al remplazar la k-\'esima columna de $A$ por la columna de constantes.

\begin{ejemplo}
Usar la regla de Cramer para resolver el sistema de ecuaciones
\begin{align*}
 2x_1 - x_2 &= 1 \\
4x_1 + 4x_2 &= 20
\end{align*}

\vspace{.2cm}

\textbf{Soluci\'on:}

\vspace{.2cm}

La matriz de coeficientes y el vector columna son:
\[A =
\left[
\begin{matrix}
2 & -1 \\
4 & 4
\end{matrix}
\right]
\quad \text{y} \quad
 b= \left[
\begin{matrix}
1 \\
20
\end{matrix}
\right],
\]
as\'{\i} que
\[
\det A = 8 -(-4) =12\]

por tanto
\[
 x_1 = \frac{ \left|
\begin{matrix}
1  & -1 \\
20 &  4
\end{matrix}
\right]}
{
\left|
\begin{matrix}
2 & -1 \\
4 & 4
\end{matrix}
\right|
} = \frac{24}{12} = 2
\quad \text{y} \quad
 x_2 = \frac{ \left|
\begin{matrix}
2 & 1 \\
4 & 20
\end{matrix}
\right]}
{
\left|
\begin{matrix}
2 & -1 \\
4 & 4
\end{matrix}
\right|
} = \frac{36}{12} = 3
\]
\end{ejemplo}

\begin{ejemplo}
En el modelo Keynesiano $IS-LM$
\begin{align*}
 Y &= C + I  \\
 C &= 100 + 0.8 Y \\
 I &= 1000 - 20i \\
 M^{s} &= M^{d} \\
 M^{s} &= 2350 \\
 M^{d} &= 0.5 Y - 30 i
\end{align*}

A partir de las ecuaciones anteriores obtener los valores de equilibrio del ingreso($Y$) y la tasa de interes ($i$).
\medskip

\textbf{Solución:}
\medskip

Dadas las condiciones de equilibrio obtenemos:
\begin{align*}
Y= 100 +& 0.8 Y + 1000 -20i  \\
0.5 Y - 30i &= 2350 \\
0.2Y + 20i  &= 1100 \\
0.5 Y - 30i  &= 2350
\end{align*}

Escribiendo en forma matricial
\[
\left[
\begin{matrix}
0.2 & 20 \\
0.5 & -30
\end{matrix}
\right] \left[
\begin{matrix}
\bar{Y} \\
\bar{i}
\end{matrix}
\right] = \left[
\begin{matrix}
1100 \\
2350
\end{matrix}
\right]
\]
\[
|A| = -6 - 10 = -16.
\]
Usando la Regla de Cramer,

\[
\bar{Y} = \frac{\left|
\begin{matrix}
1100 & 20 \\
2350 & -30
\end{matrix}
\right|}{-16} = \frac{-33000 - 47 000}{-16} = 5000
\]
\[\bar{i} = \frac{\left|
\begin{matrix}
0.2 & 1100 \\
0.5 & 2350
\end{matrix}
\right|}{-16} =  \frac{470- 550}{-16} = 5 \%
\]
\end{ejemplo}

\textbf{Estatica comparativa}
\medskip

Para ilustrar el uso de las derivadas parciales, se recurre al
modelo keynesiano simple de ingreso nacional $Y,$ el nivel de
consumo $C,$ el nivel de inversión $I_0$  y el gasto del gobierno
está dado por $G_0$. Por otra parte, la notación detrás de las dos
últimas variables muestra que la inversión y el gasto público
son variables exógenas. En el contexto de los modelos económicos,
esto significa que  dependen de factores externos al modelo y por lo
tanto sus valores no pueden ser influenciados en el modelo y se
deben tomar por sentados, es decir, ya estan dadas. Al mismo tiempo, las otras variables se
suponen que son endógenas y, por tanto, dependen de factores internos
del modelo. De hecho, las variables endógenas en el modelo depende
de las exógenas, así como en los parámetros. Aquí $ C_{0} $ es el
nivel de consumo autónomo. El parámetro $c$ es conocido como la propensión marginal a consumir.
Queremos resolver el modelo a partir de las variables endógenas $\bar{Y} $ y $\bar{C}$ en equilibrio:
\begin{align*}
Y &=  C + I_0 + G_0 \\
C &= C_{0}+ c Y  && C_{0} > 0 \quad c \in (0,1)
\end{align*}
Así formuladas, las ecuaciones dadas forman la así llamada forma
estructural del modelo. Cuando se resuelve por $\bar{Y} $ o $ \bar{C} $,
se obtiene la forma reducida del modelo. Tenemos la solución
en forma reducida cuando la variable endógena se expresa en términos
de las variables exógenas o parámetros en el modelo. Reescribiendo
las ecuaciones,
\begin{align*}
Y- C &= I_0 + G_0 \\
-c Y + C &= C_{0}
\end{align*}
\[
\left[
\begin{matrix}
1 & -1 \\
-c & 1
\end{matrix}
\right] \left[
\begin{matrix}
\bar{Y} \\
\bar{C}
\end{matrix}
\right] = \left[
\begin{matrix}
I_0 + G_0 \\
C_{0}
\end{matrix}
\right]
\]
\medskip

$|A| = 1- c > 0$
\medskip

El determinante es claramente positivo, ya que la propensión
marginal a consumir es menor que 1, calculando el valor de $ \bar{Y}$
\[
\bar{Y} = \frac{\left[
\begin{matrix}
I_0 + G_0 & -1 \\
C_{0} & 1
\end{matrix}
\right] }{1- c} = \frac{I_0 + G_0 + C_{0} }{1- c}
\]
A partir de este modelo de ingreso, vemos que el
equilibrio en el ingreso es positivo y se relaciona
positivamente con la variable exógena inversión, el gasto
gubernamental, y el consumo autónomo. Por otro lado, se
relaciona positivamente con la propensión marginal a consumir.
\medskip

La estática comparativa nos ayuda a estudiar la forma en que el ingreso
$ \bar {Y} $ responde ante cambios de las variables exógenas o de cualquier otro parámetro. Por ejemplo, podemos ver que el ingreso aumenta cuando la inversión aumenta en la economía simplemente diferenciando
el ingreso con respecto a la inversión:
\[
\frac{\partial \bar{Y}}{\partial I_0} = \frac{1}{1 - c}
> 0
\]
Igualmente el efecto del gasto del gobierno en el ingreso.
Este efecto se muestra por el multiplicador del gasto del gobierno,
expresado por la derivada parcial
\[
\frac{\partial \bar{Y}}{\partial G_0} = \frac{1}{1 - c}
> 0
\]
Vemos que el valor del multiplicador del gasto gubernamental es el
mismo que el multiplicador de la inversión. Para el consumo
tenemos
\[
\bar{C} = \frac{\left[
\begin{matrix}
1 & I_0 + G_0  \\
-c & C_{0}
\end{matrix}
\right] }{1- c} = \frac{ C_{0} + c (I_0 + G_0) }{1- c}
= \frac{C_{0} + c (I_0 + G_0 )}{1 - c} > 0
\]
El equilibrio de consumo también es positivo. Podemos ver que el consumo se
relaciona positivamente con el ingreso,  el nivel de inversión y el gasto público.
\medskip

Al igual que el ingreso el consumo aumenta con el
nivel de inversión en la economía simplemente diferenciando el
consumo con respecto a la inversión:
\[
\frac{\partial \bar{C}}{\partial I_0} = \frac{c}{1- c}> 0
\]
Nuevamente el efecto del gasto del gobierno aumenta  el consumo.
Este efecto se muestra por el multiplicador del gasto del gobierno,
expresada por la derivada parcial
\[
\frac{\partial \bar{C}}{\partial G_0} = \frac{c}{1- c}
> 0
\]
Observemos que en en el caso del consumo, también el valor del
multiplicador del gasto gubernamental es el mismo que el del
multiplicador de la inversión.

\begin{problema}
En un modelo b\'asico macroeconómico keynesiano se supone que $Y = C
+ I_{0} + G_{0}$, donde $C =50+0.75 Y$,  $I = 100$ y $G_{0} = 50$  ¿calcule el efecto
de un incremento de 20 unidades en la inversión?.
\medskip

\textbf{Soluci\'on}
\begin{align*}
Y- C &= 100 + 50 \\
-0.75 Y + C &= 50
\end{align*}
\[
\left[
\begin{matrix}
1 & -1 \\
-0.75 & 1
\end{matrix}
\right] \left[
\begin{matrix}
\bar{Y} \\
\bar{C}
\end{matrix}
\right] = \left[
\begin{matrix}
150 \\
50
\end{matrix}
\right]
\]
\medskip

$|A| = 1- 0.75 = 0.25 $
\medskip

El determinante es positivo, calculando el valor de $ \bar{Y}$
\[
\bar{Y} = \frac{\left[
\begin{matrix}
150 & -1 \\
50 & 1
\end{matrix}
\right] }{0.25} = 1000
\]
Calculando el valor de $ \bar{C}$
\[
\bar{C} = \frac{\left[
\begin{matrix}
1 & 150  \\
-0.75 & 50
\end{matrix}
\right] }{0.25} = 1000
\]
Ahora vamos obtener el multiplicador de la inversión
\[
\frac{\partial \bar{Y}}{\partial I_0} = \frac{1}{1 - 0.75} = 4
\]
Este multiplicador indica que por cada unidad que aumenta la inversión el ingreso se incrementará en 4 unidades. Luego, si la inversión aumenta en 20, entonces el ingreso aumentará en 80.
\begin{align*}
\partial \bar{Y} & = 4 * {\partial I_0} \\
                 & = 4 * 20 \\
\partial \bar{Y} & = 80
\end{align*}
\end{problema}

\begin{ejemplo}
El mercado de bienes es descrito por:
\begin{align*}
 Y &= C + I + G \\
 C &= C_0 + c(1-t) Y \\
 I &= I_0 - bR \\
 G &= \bar{G}
\end{align*}

El mercado de dinero es descrito por:
\begin{align*}
L &= kY - h R \\
M  &= \bar{M}
\end{align*}
 La econom\'{\i}a en equilibrio es entonces caracterizada por:
\begin{align*}
  Y &= C + I + \bar{G} \\
  C &= C_0 + c(1-t)Y \\
  I &= I_0 - bR \\
  \bar{M} &= k Y - h R
\end{align*}

Estas son cuatro variables end\'ogenas en el sistema $Y, C, I$ y $R$
y cuatro variables exogenas, $\bar{G}, C_0, I_0,$ y $\bar{M}$. El
sistema se puede escribir en la forma:
\[
   A \textbf{x} = \texttbf{B}
\]
donde $A$ es una matriz $4 \times 4$ de par\'ametros, $x$ es el
vector de variables endogenas, y \textbf{B} es un vector de
constantes  y variables ex\'ogenas.

\vspace{.2cm}

Supongamos que nos interesa determinar $R$. Lo haremos por la regla de Cramer. El sistema es dado por:

\[
   \left[
  \begin{matrix}
   1    & -1   &-1   & 0   \\
   -c(1-t) & 1 & 0 & 0     \\
   0 & 0 & 1 & b  \\
   k &0 &0 & -h
  \end{matrix}
  \right] \cdot
  \left[
  \begin{matrix}
   Y  \\
   C   \\
    I    \\
     R
  \end{matrix}
  \right] =
  \left[
  \begin{matrix}
   \bar{G} \\
   C_0 \\
   I_0 \\
    \bar{M}
  \end{matrix}
  \right]
\end{equation}
\]

Obtenemos $\mid  A \mid $ desarrollandolo a lo largo de la tercer fila de $A$:
\begin{align*}
\mid A \mid & = 1
\left|
  \begin{matrix}
   1       & -1   & 0   \\
   -c(1-t) & 1    & 0   \\
   k       & 0    & -h
  \end{matrix}
  \right|
- b
\left|
  \begin{matrix}
   1       & -1   &-1     \\
   -c(1-t) & 1    & 0      \\
   k       & 0    & 0
  \end{matrix}
  \right| \\
  &= -h
  \left|
  \begin{matrix}
   1       & -1   \\
   -c(1-t) & 1
  \end{matrix}
  \right|
  -b \left( -1
  \left|
  \begin{matrix}
   -c(1-t) & 1    \\
     k     & 0
  \end{matrix}
  \right|
  \right) \\
  &= -h[1- b(1-t)] -bk
\end{align*}

Resolviendo para  $R = \mid A_4 \mid  /   \mid  A \mid$, donde $\mid A_4 \mid$
se obtiene remplazando la cuarta columna de $A$ por $\textbf{B}:$
\[
A_4 =
\left|
  \begin{matrix}
   1    & -1   &-1   & \bar{G}   \\
   -c(1-t) & 1 & 0 & C_0     \\
   0 & 0 & 1 & I_0  \\
   k & 0  & 0 & \tilde{M}
  \end{matrix}
  \right|
\]

Entonces $\mid A_4 \mid$ se obtiene expandiendo a lo largo de la tercer fila de $A_4$:

\begin{align*}
\mid A_4 \mid & = 1
\left|
  \begin{matrix}
   1       & -1   & \tilde{G}   \\
   -c(1-t) & 1    & C_0         \\
   k       & 0    & \tilde{M}
  \end{matrix}
  \right|
- I_0
\left|
  \begin{matrix}
   1       & -1  &-1     \\
   -c(1-t) & 1   & 0      \\
   k       & 0   & 0
  \end{matrix}
  \right| \\
  &= k
  \left|
  \begin{matrix}
   -1    & \tilde{G}  \\
   1     & C_0
  \end{matrix}
  \right|
  +\tilde{M}
  \left|
  \begin{matrix}
   1       & -1    \\
   -c(1-t) & 1
  \end{matrix}
  \right|
  -I_0 \left( k
  \left|
  \begin{matrix}
   -1 & -1    \\
    1 & 0
  \end{matrix}
  \right|
  \right) \\
  &= -k(C_0 + \tilde{G}) + \tilde{M} \left[ 1- c(1-t) \right] -I_0k.
\end{align*}

Por tanto $R$ es dado por:

\[
   R = \frac{k(C_0 + I_0 + \tilde{G}) - \tilde{M} \left[ 1- c(1-t) \right] }{h \left[ 1- c(1-t) \right] + bk}.
\]
\end{ejemplo}

\newpage
\setcounter{page}{1}
\hspace{3cm}  \textbf{TAREA 3: SISTEMAS DE ECUACIONES}

\vspace{.2cm}

Trabajo en equipo. \\
\begin{enumerate}
\item  Resolver las siguientes pares de ecuaciones por el método de igualación:

\begin{enumerate}
 \item
\begin{align*}
 y &= 22 - x \\
2y &= 4 + 8x
\end{align*}
\item
\begin{align*}
 q &= 25-p \\
 q &= 4+2p
\end{align*}
\end{enumerate}
\item Cuales de los siguientes sistemas son consistentes
  y cuales son inconsistentes:
\begin{enumerate}
\item
\begin{align*}
 5x - 8y &= 4 \\
 -x + 2y &= 2
\end{align*}
\item
\begin{align*}
  x - 4y &= 3 \\
-3x +12y &= -14
\end{align*}
\item
\begin{align*}
  x - 4y &= 3 \\
-3x +12y &= -9
\end{align*}
\item
\begin{align*}
   2x + y - z &= 10 \\
  4y + 2z &= 4  \\
   x &= 0
\end{align*}
\end{enumerate}
\item Resuelva los siguientes sistemas de ecuaciones lineales mediante el m\'etodo de eliminaci\'on de Gauss-Jordan.
\begin{enumerate}
\item
\begin{align*}
3x + y &= 1 \\
-7x - 2y &= -1
\end{align*}
\item
\begin{alignat*}{3}
    4x_1     &+  x_2  && + 2x_3   &&=  0      \\
     x_1     &  - x_2      && + 4x_3  && = 1      \\
    2x_1   & +  x_2 && -  x_3 &&= 2
\end{alignat*}
\end{enumerate}

\item Usar la regla de Cramer para calcular las soluciones del sistema de
  ecuaciones:
\begin{enumerate}
\item
\begin{align*}
 2x - 6y &= 8 \\
-3x +14y &= 8
\end{align*}
\item
\begin{alignat*}{3}
    2x_1     &+  x_2  && + x_3   &&=  3      \\
    -x_1     &        && + 2x_3  && = 10      \\
     3 x_1   & +  x_2 && +  3x_3 &&= -3
\end{alignat*}
\end{enumerate}

\item Las funci\'ones  de demanda y oferta para un producto
  (pantalones) son dadas por:
\begin{align*}
\text{Funci\'on de demanda:} \quad  P &= 50 - 3 Q \\
\text{Funci\'on de oferta: } \quad    P &= 14 + 1.5 Q
\end{align*}

donde $P$ es el precio de un par de pantalones; $Q$ es el n\'umero de
pares de pantalones. Calcular a través de la matriz inversa el precio y la cantidad de equilibrio.

\item Las funci\'ones  de demanda y oferta para el trabajo son dadas por:
\begin{align*}
\text{Funci\'on de demanda de trabajo:} \quad  w &= 70 - 4 L \\
\text{Funci\'on de oferta de trabajo: } \quad   w &= 10 + 2 L
\end{align*}

Calcular con el método de Cramer el n\'umero de trabajadores empleados y el
salario de equilibrio por hora.

\item Considere la siguiente econom\'{\i}a cerrada:
\begin{align*}
   C &= 15 + 0.8(Y-T) \\
   T &= 25 + 0.25 Y \\
   I &= 65- R \\
   G &= 80 \\
   L &= 5Y-50R \\
   M &=1,500
\end{align*}

Resolver para el nivel de equilibrio de la renta y de la tasa de ínteres por cualquier método visto anteriormente.
\medskip

\item El modelo de ingreso nacional es
\begin{align*}
Y &=  C + I_0 + G_0 \\
C &= C_{0} + c(Y - T)  && C_{0} > 0 \quad c \in (0,1) \\
T  &= T_{0} + \beta Y   && T_{0} > 0 \quad \beta \in (0,1)
\end{align*}

Encontrar las derivadas parciales $\frac{\partial Y}{\partial G_0}$ y $\frac{\partial C}{\partial G_0}$. Determinar sus signos e interpretar su significado económico.
\end{enumerate}

\newpage
\setcounter{page}{1}
\hspace{1cm}  \textbf{TAREA 4: SISTEMAS DE ECUACIONES EN C\'OMPUTO}

\vspace{.2cm}

Trabajo en equipo\\

\vspace{.2cm}

De la siguiente informaci\'on acerca de las ecuaciones
estructurales de una econom\'{\i}a cerrada, derivar las curvas $IS \
(Y = C+ I)$ y $LM \ (M / P = L)$, donde supondremos que $P =
1$. Resolver la renta de equilibrio y la tasa de inter\'es a trav\'es
de matrices con excel o mathematica.

\vspace{.1cm}

Ejercicio 1.

\begin{align*}
 C  &= 50 + 0.8 Y \\
 I &= 20 - 5R \\
 L & = 100- R + 0.5 Y \\
M &= 200
\end{align*}

Ejercicio 2
\begin{align*}
 C  &= 15 + 3/4 Y \\
 I &= 10 - 1.5R \\
 L & = 0.25 Y - 0.5 R \\
M &= 8
\end{align*}


Ejercicio 3
\begin{align*}
 C  &= 20 + 0.8 Y \\
 I &= 20 - 2R \\
 L & = 10 + 0.25 Y - 0.5 R \\
M &= 55
\end{align*}

\newpage

\setcounter{page}{1}
\section{Espacios vectoriales}
\subsection{Espacio y subespacio  vectorial}

\begin{definicion}
Sea $K$ un campo. Un espacio vectorial sobre $K,$ o tambi\'en
llamado un $K$- espacio vectorial, consta de lo siguiente:
\begin{enumerate}
\item[1.] Un conjunto $V,$ cuyos elementos se llaman vectores.
\item[2.] Una operaci\'on binaria en $V,$ llamada suma de vectores, denotada por $+$, y que cumple lo
siguiente:
\begin{enumerate}
\item[a)] Para todos $x, y \in V,$ se cumple que $x + y = y + x$ (conmutatividad).
\item[b)] Para todos $x,y$ y $z \in V,$ se cumple que $(x + y) + z =x + (y + z)$ (asociatividad).
\item[c)] Existe un elemento en $V$ llamado cero y denotado por  0 tal que $0 + x = x$, pata todo $x \in V$ (existencia del neutro aditivo).
\item[d)] Para todo $x \in V$ existe un elemento $-x$ tal que $x + (-x) = 0$ (existencia de elementos inversos).
\end{enumerate}
\item[3.] Una operaci\'on binaria en $V,$  llamada producto de vectores, denotada por $\cdot$, y que cumple lo
siguiente:
\begin{enumerate}
 \item[a)] Para todo $x \in V$, se tiene que $1 \, x = x$, con $1 \in K.$
 \item[b)] Para todo $x \in V$ y para todo $\lambda$ y $\mu \in k$, se tiene que $\lambda(\mu x) = (\lambda\mu) x$.
 \item[c)] El producto por escalar es distributivo, es decir,
 \begin{align*}
(\lambda + \mu) x &=\lambda x + \mu x, \\
\lambda(x + y) &= \lambda x + \lambda y,
\end{align*}
para todos $\lambda,\mu \in K$ y para todos $x, y \in
V$
\end{enumerate}
\end{enumerate}

\begin{definicion}
Al conjunto $V$ con la suma y el producto por escalar se le llama \textbf{ espacio vectorial sobre $K$}.
\end{definicion}

\begin{ejemplo}
La operaci\'on de suma y producto por escalar en $\Bbb{R}^{3}$ se formulan como:

\begin{enumerate}
  \item Dados $(x_1,x_2,x_3)$, $(y_1,y_2,y_3) \in \Bbb{R}^3$, se define:
  \[
     (x_1,x_2,x_3) + (y_1,y_2,y_3) = (x_1 + y_1,x_2 + y_2, x_3+y_3)
   \]
   \item Dados $(x_1,x_2,x_3) \in \Bbb{R}^3$ y $c \in \Bbb{R}$, se define:
   \[
    c\,\,  (x_1,x_2,x_3) = (cx_1,cx_2,cx_3)
   \]
\end{enumerate}

Entonces $\Bbb{R}^3$ con la suma y producto definidos anteriormente
es un espacio vectorial. Para esto verifiquemos que $\Bbb{R}^3$ con
la operaci\'on $+$ cumple las siguientes propiedades
\begin{enumerate}
\item[a)] Para todos $x, y \in \Bbb{R}^3$, se cumple que $x + y = y + x$ (conmutatividad).
 Sean $x=(x_1,x_2,x_3)$ y $y =(y_1,y_2,y_3)$, entonces
 \[
 x+y = (x_1 +y_1,x_2+ y_2, x_3 + y_3)= (y_1+x_1, y_2+x_2, y_3 + x_3)= y + x
 \]
\item[b)] Para todos $x,y,z \in \Bbb{R}^3$, se cumple que $(x + y) + z =x + (y + z)$ (asociatividad).
Sean $x=(x_1,x_2,x_3),$  $y=(y_1,y_2,y_3),$ y $z=(z_1,z_2,z_3)$, entonces
\begin{align*}
(x + y) + z &=((x_1,x_2,x_3) + (y_1,y_2,y_3))+ (z_1,z_2,z_3) \\
&=(x_1 +y_1,x_2+y_2,x_3 + y_3) +(z_1,z_2,z_3) \\ &=((x_1 +y_1) +
z_1,(x_2+y_2) + z_2,(x_3 + y_3) + z_3)  \\ & = (x_1 + (y_1 +
z_1),x_2+ (y_2 + z_2),x_3 + (y_3 + z_3)) \\ &= (x_1,x_2,x_3) +
((y_1,y_2,y_3)+ (z_1,z_2,z_3)) \\ &= x + (y + z)
\end{align*}
\item[c)] Existe un elemento en $\Bbb{R}^3$ llamado cero y denotado por  0 tal que $0 + x = x$, pata todo $x \in \Bbb{R}^3$ (existencia del neutro aditivo).
Sea $0 =(0,0,0)$ entonces si $x = (x_1,x_2,x_3)$ tenemos
\[0 + x =(0,0,0) + (x_1,x_2,x_3) = (0 + x_1, 0 + x_2, 0 + x_3) =
(x_1,x_2,x_3) =x
\]
\item[d)] Para todo $x \in \Bbb{R}^3$ existe un elemento $-x$ tal que $x + (-x) = 0$ (existencia de elementos inversos).
Sea $x \in \Bbb{R}^3$, con $x =(x_1,x_2,x_3)$, definimos el inverso
de $x$ por $-x=(-x_1,-x_2,-x_3)$, entonces tenemos
\begin{align*}
 x + (-x) &= (x_1,x_2,x_3) + (-x_1,-x_2,-x_3)\\
  & = (x_1 + (-x_1), x_2 + (-x_2), x_3 +
 (-x_3)) \\   &= (x_1 -x_1, x_2 -x_2, x_3-x_3) = (0,0,0) = 0
\end{align*}
\end{enumerate}
Ahora veamos que $\Bbb{R}^3$ con la operaci\'on producto $\cdot$
cumple
\begin{enumerate}
 \item[a)] Para todo $x \in \Bbb{R}^3$, se tiene que $1 \, x = x$, con $1 \in \Bbb{R}.$
Si $x \in \Bbb{R}^3$,
\[
 1 \cdot x = 1 \cdot (x_1,x_2,x_3) = (1 \cdot x_1, 1 \cdot x_2, 1 \cdot
 x_3) = (x_1,x_2,x_3) = x
\]

 \item[b)] Para todo $x \in \Bbb{R}^3$ y para todo $\lambda$ y $\mu \in \Bbb{R}$, se tiene que $\lambda(\mu x) = (\lambda\mu) x$.
 Sea $x \in \Bbb{R}^3$, con $x = (x_1,x_2,x_3)$, tenemos
 \begin{align*}
 \lambda(\mu x) &=\lambda(\mu (x_1,x_2,x_3)) = \lambda (\mu x_1,\mu
x_2,\mu x_3)   = (\lambda(\mu x_1),\lambda (\mu x_2),\lambda (\mu
x_3)) \\ & = ((\lambda\mu) x_1,(\lambda \mu) x_2,(\lambda \mu) x_3)
 = (\lambda\mu) x
 \end{align*}
 \item[c)] El producto por escalar es distributivo, es decir,
 \begin{align*}
(\lambda + \mu) x &=\lambda x + \mu x, \\
\lambda(x + y) &= \lambda x + \lambda y,
 \end{align*}
para todos $\lambda,\mu \in K$ y para todos $x, y \in V$.

\vspace{.2cm}

Sea $x \in \Bbb{R}^3$, con $x = (x_1,x_2,x_3)$, tenemos
\begin{align*}
 (\lambda + \mu) \cdot x & = (\lambda +\mu)\cdot (x_1,x_2,x_3) = ((\lambda +\mu) x_1,
(\lambda +\mu) x_2,(\lambda +\mu) x_3)  \\
&= (\lambda x_1 + \mu
x_1,\lambda x_2 + \mu x_2,\lambda  x_3 + \mu x_3) \\
& = (\lambda
x_1,\lambda x_2,\lambda x_3) + (\mu x_1,\mu x_2,\mu x_3) =
 \\ &= \lambda x + \mu x.
 \end{align*}
\begin{align*}
 \lambda  \cdot ( x + y) &= \lambda \cdot ((x_1,x_2,x_3)+ (y_1,y_2,y_3)) = \lambda \cdot
 (x_1 + y_1, x_2 + y_2, x_3 + y_3)  \\ &= (\lambda (x_1 + y_1),\lambda (x_2 +  y_2),\lambda (x_3 + y_3)) \\
 & = (\lambda x_1,\lambda x_2,\lambda x_3) + (\lambda
y_1,\lambda y_2,\lambda y_3) =
 \\ &= \lambda x + \lambda y.
 \end{align*}

para todos $\lambda,\mu \in K$ y para todos $x, y \in V$
\end{enumerate}
\end{ejemplo}


\begin{definicion}
Sea $W$ un subconjunto no vac\'{\i}o de $V,$ se dice que $W$
es un\textbf{ subespacio vectorial} de $V,$ si satisface las
siguientes propiedades:

\begin{enumerate}
 \item Para todos $x$ y $y \in W,$ se tiene que $x+y \in W,$ es decir, $W$ es cerrado bajo la suma.
 \item Para todo $x \in W$ y para todo $\lambda \in \Bbb{R}$, $\lambda
  x \in W,$ es decir $W$ es cerrado bajo producto por escalar.
\end{enumerate}
\end{definicion}

\begin{ejemplo}
Sea
\[
  W = \{(x_1,x_2,x_3) \in \Bbb{R}^3 \mid x_3 = 0  \}
\]
es decir, $x \in W$, entonces $x =(x_1,x_2, 0)$. Entonces $W$ es un
subespacio vectorial de $\Bbb{R}^3.$ Para esto verifiquemos que si
$x, y \in W,$ entonces $x + y \in W$. Como $x,y \in W,$ $x=(x_1,x_2, 0)$ y $y =(y_1,y_2, 0 )$, luego $x + y = (x_1+y_1,x_2 +
y_2, 0) \in W $. Ahora veamos que si $x \in W$ y $\lambda \in
\Bbb{R}$, $\lambda x \in W$, lo cual se sigue de que si $x =
(x_1,x_2, 0)$, entonces $\lambda x = \lambda(x_1,x_2, 0) =
(\lambda x_1,\lambda x_2, 0) \in W$.
\end{ejemplo}

\begin{ejemplo}
Sea $A$ una matriz 3 por 2. Entonces
\begin{enumerate}
\item[a)] el espacio columna de $A$, el cual es el conjunto de todas las combinaciones lineales de las
columnas de $A$ y se le denota por $C(A)$ es un subespacio de
$\Bbb{R}^3$
\item[b)] el espacio nulo de $A$, que consta de todos los vectores $x$ tales que $Ax= 0$
y  se le denota por $N(A)$ es un subespacio de $\Bbb{R}^2$
\item[c)] el espacio rengl\'on de $A$, generado por los renglones de
$A$, el cual es el espacio columna de $A^T$ y se le denota por
$C(A^T)$ es un subespacio de $\Bbb{R}^2$
\item[d)] el espacio nulo izquierdo de $A$ el cual es espacio nulo
de $A^T$,  denotado por $N(A^T)$, es un subespacio de $\Bbb{R}^3$.
\end{enumerate}
\end{ejemplo}


\newpage
\setcounter{page}{1}
\textbf{TAREA 1: ESPACIOS Y SUBESPACIOS VECTORIALES}\\
\vspace{.2cm}

Trabajo individual.\\

\begin{enumerate}
\item Demostrar que el conjunto $V$ de matrices $3 \times 3$, es un espacio
vectorial sobre  $\Bbb{R}$ con las operaciones suma  y producto por
escalar usuales, es decir:

Si $A = [a_{ij}], B = [b_{ij}]$ matrices 3 por 3. La operación
\textbf{ suma} de $A$ con $B$ es:


\begin{equation*}
 \left[
  \begin{matrix}


     a_{11}   & a_{12}   & a_{13} \\
     a_{21}   & a_{22}  & a_{23} \\
      a_{31}  & a_{32}  & a_{33}
  \end{matrix}
  \right] +
 \left[
  \begin{matrix}
     b_{11}   & b_{12}   & b_{13} \\
     b_{21}   & b_{22}  & b_{23} \\
      b_{31}  & b_{32}  & b_{33}
  \end{matrix}
  \right] =
  \left[
  \begin{matrix}
     a_{11} + b_{11}  & a_{12} + b_{12}  & a_{13} + b_{13} \\
     a_{21} + b_{21}   & a_{22} + b_{22}  & a_{23} + b_{23} \\
      a_{31} + b_{31}  & a_{32} + b_{32}  & a_{33} + b_{33}
  \end{matrix}
\right]
\end{equation*}

y producto de una matriz por un escalar:
\[ \lambda  \cdot A = \lambda
 \left[
  \begin{matrix}
     a_{11}   & a_{12}   & a_{13} \\
     a_{21}   & a_{22}  & a_{23} \\
      a_{31}  & a_{32}  & a_{33}
  \end{matrix}
  \right]
  =
\left[
  \begin{matrix}
    \lambda a_{11}   &\lambda  a_{12}   & \lambda a_{13} \\
     \lambda a_{21}   &\lambda a_{22}  & \lambda a_{23} \\
    \lambda  a_{31}  &\lambda a_{32}  &\lambda a_{33}
  \end{matrix}
  \right]
\]

\item Una matriz (cuadrada) 3 \times 3 \  $\left[a_{ij} \right]$ sobre $\Bbb{R}$  es sim\'etrica si
$a_{ij} = a_{ji}$ para todo $i,j$. Demostrar que las matrices sim\'etricas forman un subespacio del espacio de las
matrices $3 \times 3$.

\item Sea $V$ el conjunto de todas las matrices $2 \times 2$ sobre $\Bbb{R}$. Demostrar que $V$ es un espacio vectorial sobre $\Bbb{R}$ con las operaciones usuales de suma y producto por escalar usuales. Sea $W$ el subconjunto de $V$ que consta de las matrices de la forma
\[
\left[
  \begin{matrix}
   a_1    & a_2 \\
   a_3  &  0
  \end{matrix}
 \right]
 \]
con $a_1,a_2,a_3 \in \Bbb{R}$. Demostrar que $W$  es un subespacio
vectorial de $V$.
\item  Demostrar que los siguientes conjuntos de vectores $\alpha = (x_1,x_2,x_3) \in \Bbb{R}^3$ son subespacios vectoriales de $\Bbb{R}^3$
\begin{enumerate}
\item Todos los $\alpha$, tales que $x_1 \geq 0$.
\item Todos los $\alpha$, tales que $x_1 + 3x_2 = x_3$.
\end{enumerate}
\end{enumerate}

\newpage

\setcounter{page}{1}
\subsection{Combinacion lineal de vectores, dependencia e independencia lineal}

\begin{definicion}
Un vector $\beta \in V$, se dice \textbf{combinaci\'on lineal} de los vectores $\alpha_1,...,\alpha_n \in
 V$,  si existen escalares $a_1,...,a_n \in K$, tales que:
\[
  \beta = \sum_{i=1}^{n} a_i \alpha_i.
\]
\end{definicion}

\begin{ejemplo}
El vector $ \left(
\begin{matrix}
6  \\
7
\end{matrix}
\right)$ en $\Bbb{R}^2$ es combinaci\'on lineal de los vectores
\[
\left(
\begin{matrix}
1  \\
0
\end{matrix}
\right) \quad \text{y} \quad \left(
\begin{matrix}
0  \\
1
\end{matrix}
\right)
\]
ya que:

\[ 6 \cdot
\left(
\begin{matrix}
1  \\
0
\end{matrix}
\right) + 7 \cdot  \left(
\begin{matrix}
0  \\
1
\end{matrix}
\right) = \left(
\begin{matrix}
6  \\
7
\end{matrix}
\right)
\]
\end{ejemplo}

\begin{definicion}
Sea $S$ es cualquier colecci\'on de vectores de $V$. \textbf{El sub\-es\-pa\-cio generado} por $S$ se define como
\[
  L(S) = \{ \sum_{i=1}^{k} a_i \alpha_i \mid a_i \in K, \alpha_i \in S \ \text{y}   \  k=1,2,3,... \}
\]
\end{definicion}

Cuando $L(S) = V$, decimos que $S$ genera a $V$


\begin{definicion}
Un subconjunto $S$ de $V$ se dice $\textbf{linealmente dependiente}$, si existen vectores distintos
$\alpha_1,...,\alpha_n$ de $S$ y escalares $a_1,...,a_n \in K$, no todos cero, tales que:
\[
     a_1 \alpha_1 + \cdots + a_n \alpha_n = 0.
\]
Un conjunto que no es linealmente dependiente se dice \textbf{linealmente independiente}. Si el conjunto $S$ solo tiene un n\'umero finito de vectores $\alpha_1,...,\alpha_n$, se dice a veces que los $\alpha_1,...,\alpha_n$ son dependientes (o independientes), en vez de decir que $S$ es dependiente (o independiente).
\end{definicion}

\begin{ejemplo}
Los siguientes vectores en $\Bbb{R}^2$
\[
\left(
\begin{matrix}
2  \\
3
\end{matrix}
\right) \quad \text{y} \quad \left(
\begin{matrix}
-1  \\
5
\end{matrix}
\right)
\]
son linealmente independientes.

\vspace{.2cm}

\textbf{Soluci\'on}: Sea
\[ a_1 \cdot
\left(
\begin{matrix}
2  \\
3
\end{matrix}
\right)  +  a_2 \cdot \left(
\begin{matrix}
-1  \\
5
\end{matrix}
\right)
=
\left(
\begin{matrix}
0  \\
0
\end{matrix}
\right)

de lo anterior obtenemos el sistema de ecuaciones:
\begin{align*}
 2a_1 - a_2 &= 0 \\
 3a_1 + 5a_2 &= 0
\end{align*}
\]
el cual tiene como soluci\'on: $a_1  = 0$ y $a_2 = 0$.
\end{ejemplo}


\begin{ejemplo}
Los vectores

\[
\left(
\begin{matrix}
2  \\
3
\end{matrix}
\right) \quad \text{y} \quad \left(
\begin{matrix}
4  \\
6
\end{matrix}
\right)
\]
son linealmente dependientes. Esto se sigue de
\[ -2 \cdot
\left(
\begin{matrix}
2  \\
3
\end{matrix}
\right) + \left(
\begin{matrix}
4  \\
6
\end{matrix}
\right) = \left(
\begin{matrix}
0  \\
0
\end{matrix}
\right)
\]
\end{ejemplo}

\begin{ejemplo}
Los vectores $(1,2,3)$ y $(1,1,0)$ son linealmente independientes en
$\Bbb{R}^3$.

\vspace{.2cm} Sea:
\[
a_1 \cdot (1,2,3) + a_2 \cdot  (1,1,0) = ( 0,0,0)
\]

Entonces
\begin{align*}
 a_1  + a_2  &= 0 \\
 2a_1 + a_2  &= 0 \\
 3a_1 &= 0
\end{align*}
Es f\'acil ver que el sistema de ecuaciones anterior tiene como
\'unica soluci\'on $a_1 = a_2 =  0$.
\end{ejemplo}

\begin{ejemplo} Demostrar
\medskip
\begin{enumerate}
\item[(a)] Sí
$\alpha_1 = \left( \begin{matrix} 3 \\  1 \end{matrix}
\right)$ y $\alpha_2 =  \left(\begin{matrix} 6 \\  2 \end{matrix}
\right) $ son linealmente dependientes.
\item[(b)] Sí
$\alpha_1 = \left( \begin{matrix} 3 \\  1 \end{matrix}
\right)$ y $\alpha_2 =  \left(\begin{matrix} 1 \\  2 \end{matrix}
\right) $ son linealmente independientes.
\end{enumerate}
\end{ejemplo}

\vspace{.2cm}

\textbf{Soluci\'on:}

\vspace{.2cm}

\begin{enumerate}
\item[(a)] Se ve que $\alpha_2 =2 \alpha_1$, luego $2\alpha_1 -
  \alpha_2 =0$. Tomando $a_1 = 2$ y $a_2 = -1$ se obtiene $a_1
  \alpha_1 + a_2 \alpha_2 = 0$, lo cual prueba que $a_1$ y $a_2$ son
  linealmente dependientes.
\item[(b)] La ecuaci\'on $a_1 \alpha_1 + a_2 \alpha_2 = 0$, da lugar
  al sistema
\begin{align*}
3a_1 + a_2 & = 0 \\
 a_1 + 2a_2 &= 0
\end{align*}
que tiene como soluci\'on \'unica $a_1 = a_2 = 0$. Por tanto
$\alpha_1$ y $\alpha_2$ son linealmente independientes.
\end{enumerate}


\subsection{Base y dimensi\'on}
\begin{definicion}
Una \textbf{base} de $\Bbb{R}^n$ es un conjunto de vectores linealmente independientes de $\Bbb{R}^n$ y que genera el
espacio $\Bbb{R}^n$.
\end{definicion}

\begin{teorema}
Sea $\{\alpha_1,...,\alpha_n\}$ un subconjunto de $\Bbb{R}^n$, entonces las siguientes condiciones son equivalentes:
\begin{enumerate}
  \item El conjunto $\{\alpha_1,...,\alpha_n\}$ es una base.
  \item El conjunto $\{\alpha_1,...,\alpha_n\}$ es linealmente independiente.
  \item El conjunto $\{\alpha_1,...,\alpha_n\}$ genera a $\Bbb{R}^n$.
\end{enumerate}
\end{teorema}


\begin{ejemplo}

Los vectores

\[
\left(
\begin{matrix}
1 \\
1
\end{matrix}
\right) \quad \text{y} \quad \left(
\begin{matrix}
-1  \\
1
\end{matrix}
\right)
\]
son una base de $\Bbb{R}^2$. Si


\[ a_1 \cdot
\left(
\begin{matrix}
1 \\
1
\end{matrix}
\right) +  a_2 \cdot \left(
\begin{matrix}
-1  \\
1
\end{matrix}
\right)
=
\left(
\begin{matrix}
0 \\
0
\end{matrix}
\right)
\]
Entonces de la combinaci\'on lineal anterior, obtenemos el sistema
de ecuaciones:
\begin{align*}
a_1  - a_2 &= 0 \\
a_1 + a_2 &= 0
\end{align*}
El cual tiene como \'unica soluci\'on: $a_1 = a_2  = 0$.  Ahora, sea
$(x,y) \in \Bbb{R}^2$, veamos que existen $a_1,a_2 \in \Bbb{R}$
tales que $a_1 \cdot (1,1) + a_2 \cdot (-1,1) = (x,y)$. Es f\'acil
ver que $a_1 = \frac{x + y}{2}$ y $a_2 = \frac{y - x}{2}$. De lo
anterior se sigue que los vectores $(1, 1)$ y $(-1, 1)$ son
linealmente independientes y que generan a $\Bbb{R}^2$, por lo tanto
son una base de $\Bbb{R}^2$.
\end{ejemplo}

\begin{definicion}
Dos bases cualesquiera de un espacio vectorial $V$  contiene el
mismo n\'umero de vectores. Este n\'umero que es compartido por
todas las bases y expresa el n\'umero de grados de libertad del
espacio, es la dimensi\'on de $V$.
\end{definicion}

\begin{ejemplo}
En $\Bbb{R}^n$, sean $e_i = (0,...,0,1,0,...,0)$ donde el 1 aparece
en el $i$-\'esimo lugar y todas las otras coordenadas son cero. El
conjunto $\{e_i\}_{i = 1}^{n}$ es una base de $\Bbb{R}^n$ llamada la
\textbf{base can\'onica}, por lo tanto la dimensi\'on del espacio
$\Bbb{R}^n $ es $n$.
\end{ejemplo}
\begin{ejemplo}
Si $A$ es una matriz  3 por 2 con rango $r$, entonces:
\begin{enumerate}
\item[a)] La dimensi\'on del espacio columna $C(A)$ es el rango $r$.
\item[b)] La dimensi\'on del espacio nulo de $A$ es $2-r$.
\item[c)] La dimensi\'on del espacio rengl\'on $C(A^T)$ es tambi\'en
$r$.
\item[d)] La dimensi\'on del espacio nulo izquierdo $N(A^T) =3- r.$
\end{enumerate}
\end{ejemplo}


\newpage
\setcounter{page}{1}
\begin{center}
\textbf{TAREA 2: BASES DE ESPACIOS VECTORIALES}
\end{center}

\vspace{.2cm}

Trabajo en equipo\\

\begin{enumerate}
\item Decida la dependencia o independencia en $\Bbb{R}^2$ y  $\Bbb{R}^3$ de
\begin{enumerate}
\item[a)] los vectores
    $(1,1)$ y $(1,-2)$.
\item[b)] los vectores $(1,-3,2),(2,1,-3)$ y $(-3,2,1)$.
\item[c)] los vectores
    $(1,3,2),(2,1,3)$ y $(3,2,1)$.
\end{enumerate}

\item Demuestre que el siguiente subconjunto de las matrices $2 \times
2$
\[
\left\{
 \left(
\begin{matrix}
0 & 1 \\
0 &1
\end{matrix}
\right),
\left(
\begin{matrix}
2 & 0 \\
1 & 0
\end{matrix}
\right) \right\}
\]

es linealmente independiente

\item Demostrar que los siguientes vectores forman una base para $\Bbb{R}^2$.
\begin{enumerate}
\item[a)]
\[
\alpha_1=(1,1), \quad \alpha_2=(1,-1)
\]
\item[b)]
\[
\alpha_1=(-1,1), \quad \alpha_2=(-1,0)
\]
\end{enumerate}
\item Demostrar que los siguientes vectores forman una base para $\Bbb{R}^3$.
\item[a)]
\[
\alpha_1=(1,0,1), \quad \alpha_2=(1,1,0), \quad \alpha_3=(0,1,1)
\]
\item[b)]
\[
\alpha_1=(1,0,-1), \quad \alpha_2=(1,2,1), \quad \alpha_3=(0,3,-2)
\]
\item[c)]
\[
\alpha_1=(1,0,-1), \quad \alpha_2=(1,1,1), \quad \alpha_3=(1,0,0)
\]

\item Encuentre una base para cada uno de los siguientes subespacios
de $\Bbb{R}^4$
\begin{enumerate}
\item[a)] Todos los vectores cuyas componentes son iguales.
\item[b)] Todos los vectores tales que la suma de sus componentes es
cero.
\end{enumerate}
\item Encuentre una base para cada uno de los siguientes subespacios
de matrices 3 por 3:
\begin{enumerate}
\item[a)] Todas las matrices diagonales
\item[b)] Todas las matrices sim\'etrica
\item[c)] Todas las matrices sesgadas sim\'etricas (A^T = -A)
\end{enumerate}
\item Encontrar la dimensión y una base para la siguiente matriz.\\
\[
\left(
\begin{matrix}
2& 1& 2\\
0& 3& -1\\
4& 1& 1
\end{matrix}
\right)
\]
\item Encontrar la dimensión y una base para la siguiente matriz.\\
\[
\left(
\begin{matrix}
1& 1& 0& 0& -1\\
2& 2& 0& 1& 0\\
-1& 0& -1& 4& 2
\end{matrix}
\right)
\]
\item Sea $V$ el espacio vectorial de las matrices $2 \times 2$
sobre el campo $\Bbb{R}$. Demuestre que $V$ tiene dimensi\'on 4
encontrando una base de $V$ que tenga cuatro elementos.
\end{enumerate}

\newpage

\setcounter{page}{1}
\subsection{Transformaci\'on lineal}

\begin{definicion}
Sean $V$ y $W$ dos espacios vectoriales. Una transformaci\'on lineal
es una funci\'on  $T: V \to W$ que satisface las siguientes
propiedades:
\begin{enumerate}
\item $ T(\alpha + \beta) = T(\alpha) + T (\beta)$, para todos
$\alpha, \beta \in V.$
\item $T(r \alpha) = r T(\alpha)$, para todo escalar $r \in \Bbb{R}$
 y para todo  $\alpha \in V .$
\end{enumerate}
Un operador lineal sobre $V$ es una transformaci\'on lineal de $V$
en si mismo.
\end{definicion}
\begin{ejemplo}
La funci\'on $0 : V \to W$ definida por $0(v) = 0$ que mapea todos
los elementos del espacio vectorial $V$ al elemento cero del espacio
$W,$ es claramente una funci\'on lineal, llamada la transformaci\'on
cero.
\end{ejemplo}
\begin{ejemplo}
La funci\'on $1V : V \to V$ dada por $1V (v) = v$ es un operador
lineal denominado operador identidad sobre $V$.
\end{ejemplo}



\begin{ejemplo}
Si $V = \Bbb{R}^n$ y $W  = \Bbb{R}^m$ las trasformaciones lineales
entre $V$ y $W$ corresponden a las matrices $A$ de $m \times n.$ En
particular, si
\[
A =
\left(
\begin{matrix}
1 & 1 & -1 \\
1 & -1 & 1
\end{matrix}
\right)
 entonces $T_A : \Bbb{R}^3  \to \Bbb{R}^2$ dada por $T_A (x) = Ax$ es
 lineal, dada por:
\[
 T_A
 \left(
\begin{matrix}
x \\
y \\
z
\end{matrix}
\right) =
\left(
\begin{matrix}
x+y-z \\
x-y+z
\end{matrix}
\right)
\end{ejemplo}



\begin{teorema}
Si $T : V \to W$ es una tranformaci\'on lineal, y si
$\alpha_1,...,\alpha_n$  son vectores de $V,$ entonces dados los
escalares $a_1,a_2,...,a_n,$
\[
   T(a_1 \alpha_1 + \cdots + a_n \alpha_n) = a_1 T(\alpha_1) + \cdots
   + a_n T(\alpha_n).
\]
\end{teorema}

\begin{teorema}
Sea $T : V \to W$ una tranformaci\'on lineal, si $\{\alpha_1,...,
\alpha_n \}$ es una base para $V,$  y si $T(\alpha_i) = \beta_i$, $i=
1, 2,...n$ entonces para cualquier vector $\alpha \in V,$ $T(\alpha)$
est\'a determinada y $T(\alpha) = a_1 \beta_1 + \cdots +  a_n
\beta_n$, donde $a_1, a_2,...,a_n$ son escalares tales que $\alpha =
a_1 \alpha_1 + \cdots + a_n \alpha_n$.
\end{teorema}

\begin{teorema}
\label{T}
  Sea $V$ un espacio vectorial de dimensi\'on finita $n$, sea
  $\alpha_1,...,\alpha_n$ una base ordenada de $V$. Sean $W$  un
  espacio vectorial y $\beta_1,...,\beta_n$ vectores cualesquiera en
  $W.$ Entonces existe una \'unica tranformaci\'on lineal $T : V \to
  W$ tal que
\[
  T(\alpha_j) = \beta_j. \quad  j=1,...,n.
\]
\end{teorema}

\begin{ejemplo}
Consideremos la base de $\Bbb{R}^2$ formada por lo vectores $\alpha_1 = (1,2), \alpha_2= (3,4)$. Por el Teorema \ref{T}
existe una transformaci\'on lineal $T$ de $\Bbb{R}^2$  en $\Bbb{R}^2$ tal que
\begin{align*}
T(\alpha_1) &= (3,2,1) \\
T(\alpha_2) &= (6,5,4)
\end{align*}
Encontremos $T(1,0)$.  Si $(1,0) = c_1(1,2) + c_2(3,4)$, con $c_1,c_2 \in \Bbb{R}$, entonces $c_1= -2$ y $c_2= 1$. Por lo tanto
\begin{align*}
T((1,0) ) &= T(c_1(1,2) + c_2(3,4)) \\ &= c_1 T(1,2) + c_2 T(3,4) \\ & =  -2(3,2,1) + (6,5,4) \\ & = (0,1,2).
\end{align*}
\end{ejemplo}


\subsection{Nucleo e imagen}

\begin{definicion}
Sea   $T : V  \to W$ una tranformaci\'on lineal. Definimos el
n\'ucleo de $T$ como el conjunto $N_T = \{\, \alpha \in V \mid T
(\alpha) = 0 \}$. La imagen de $T$, denotada $R_T$, se define como
$R_T = \{\beta \in W   \mid \text{existe un} \,  \alpha \in V
\text{y
  satisface} \,  T(\alpha) = \beta \}$.
\end{definicion}

\begin{ejemplo}
Sea $T: \Bbb{R}^3 \to \Bbb{R}^2$ dada por $T(x,y,z) = (-x + 3y + z, y + 2z)$. Entonces
$(x,y,z) \in N_T$ si y solo si
\begin{align*}
 -x + 3y + z &= 0 \\
 y + 2z &= 0
\end{align*}
La forma escalonada reducida de la matriz de los coeficientes de este sistema es
\[
\left(
\begin{matrix}
1 & 0 & 5 \\
0 & 1 & 2
\end{matrix}
\right).
\]
Por tanto el n\'ucleo de $T$, $N_T = \{(-5z,-2z, z) | z \in \Bbb{R}\}$.
\end{ejemplo}

El siguiente teorema  es uno de los m\'as importantes en la teor\'ia
de espacios vectoriales  de dimensi\'on finita.

\begin{teorema}
Sean $V$ y $W$ espacios vectoriales de dimensi\'on finita,
$T : V \to W$ una tranformaci\'on lineal, entonces la siguiente
ecuaci\'on se cumple:
\[
   dim(V) =dim (N_T) + dim(R_T)
\]
\end{teorema}

\subsection{Matriz de una tranformaci\'on lineal}
Sabemos que una tranformaci\'on lineal  queda completamente
determinada en una base. Si $T: V \to W$  es una tranformaci\'on
lineal, $\{ \alpha_1,..., \alpha_n\}$ y $\{ \beta_1,...,\beta_m \}$
son bases de $V$ y $W$ respectivamente, entonces para cada $j =
1,...,n$, $T(\alpha_j)$ se representa como combinaci\'on linel de
los elementos de la base $ \{ \beta_1,...,\beta_m \}$, es decir.
existen escalares $a_{1j},...,a_{mj}$, \'unicos, tales que:
\[
    T(\alpha_j) = \sum_{i = 1}^{m} a_{ij} \beta_i
\]

Los escalares $a_{ij}$ solamente dependen de la tranformaci\'on
lineal y de las bases elegidas, con ellos formamos la matriz:

\begin{equation*}
A  =
 \left[
  \begin{matrix}
     a_{11}   & a_{12}  & \cdots   & a_{1n} \\
     a_{21}   & a_{22}  & \cdots   & a_{2n} \\
    \vdots    & \vdots  & \cdots   & \vdots \\
      a_{m1}  & a_{m2}  & \cdots  & a_{mn}
  \end{matrix}
  \right]
\end{equation*}


\begin{ejemplo}
Sea $T: \Bbb{R}^2 \to \Bbb{R}^2$ dada por $T(x,y) = (x,0)$. Entonces la matriz asociada a
$T$ respecto de las bases can\'onicas es
\[ A =
\left[
  \begin{matrix}
   1    & 0     \\
   0  &  0
  \end{matrix}
  \right]
\]
\end{ejemplo}



\begin{ejemplo}
Sea $T: \Bbb{R}^2 \to \Bbb{R}^2$ dada por $T(x,y) = (2x + y, x - y)$. Entonces la matriz asociada a
$T$ respecto de las bases can\'onicas es
\[ A =
\left[
  \begin{matrix}
   2    & 1     \\
   1  &  -1
  \end{matrix}
  \right]
\]
\end{ejemplo}


\subsection{Cambio de base}

\begin{teorema}
Sean $V$ un espacio vectorial de dimensi\'on $n$ sobre el cuerpo $F$, y $W$ un espacio vectorial de dimensi\'on $n$ sobre
$F$. Sean $B$ una base ordenada de $V$ y $B'$ una base ordenada de $W$. Para cada transformaci\'on lineal $T$ de $V$ en $W$, existe una matriz $m \times n$, $A$, cuyos elementos pertenecen a $F$, tal que
\[
 [T \alpha]_{B'} = A [\alpha]_{B}
\]
Para todo vector $\alpha \in V.$
 \end{teorema}




\begin{definicion}
La matriz $A$ se llama \textbf{  la matriz asociada a la
trans\-for\-ma\-ci\'on $T$ respecto a las bases $\{ \alpha_1,...,\alpha_n \}$
y  $\{\beta_1,...,\beta_n \}$}.
\end{definicion}


\begin{ejemplo}
Sea $B$ la base de $\Bbb{R}^2$ formada por lo vectores $\alpha_1 = (1,1)$ y $\alpha_2 = (3,-2)$. Por el Teorema \ref{T}, existe
una \'unica transformaci\'on  lineal $T: \Bbb{R}^2 \to \Bbb{R}^2$ tal que $T(\alpha_1) = (4,5)$ y $T(\alpha_2) =(6, -1)$. Encontremos la matriz $A$ asociada a $T$ respecto a la base can\'onica de $\Bbb{R}^2$. Para determinar $A$, debemos determinar
$T(e_1) =(a,b)$ y $T(e_2) = (c,d)$. De las ecuaciones
\begin{align*}
T(1,1) &= T(e_1) + T(e_2) \ \text{y} \\
T(3,-2) &=  3 T(e_1) - 2T(e_2)
\end{align*}
se sigue que
\begin{align*}
(4,5) &= (a + c, b + d) \\
(6,-1) &= (3a- 2c, 3b - 2d)
\end{align*}
de donde se tiene el siguiente sistema de ecuaciones:
\begin{align*}
a+ c &=  4 \\
b+d &= 5 \\
3a -2c &= 6 \\
3b - 2d &= -1
\end{align*}
de cuya soluci\'on se sigue que  $T(e_1) = \left(\frac{14}{5}, \frac{9}{5} \right)$ y
$T(e_2) = \left(\frac{6}{5}, \frac{16}{5} \right)$, por lo tanto la matriz asociada a $T$ respecto a la
base can\'onica es:

\[ A =
\left[
  \begin{matrix}
   \frac{14}{5}    & \frac{6}{5}     \\
   \frac{9}{5}  &  \frac{16}{5}
  \end{matrix}
  \right]
\]

Por otro lado, la expresi\'on que define a $T(x,y)$ se obtiene del siguiente producto de matrices:
\[
AX = \left[
  \begin{matrix}
   \frac{14}{5}    & \frac{6}{5}     \\
   \frac{9}{5}  &  \frac{16}{5}
  \end{matrix}
  \right]
  \left[
  \begin{matrix}
   x\\
   y
  \end{matrix}
  \right]
  =
  \left[
  \begin{matrix}
   \frac{14}{5}x + \frac{6}{5}y     \\
   \frac{9}{5} x +  \frac{16}{5}y
  \end{matrix}
  \right]
\]
Por lo tanto $T(x,y) = (\frac{14}{5}x + \frac{6}{5}y, \frac{9}{5} x +  \frac{16}{5}y )$.
\end{ejemplo}

\begin{teorema}
(Cambio de base). Sea $T: V \to W$ una transformaci\'on lineal. Supongamos que $A$ es la matriz asociada a $T$ respecto a bases dadas $\{\alpha_1,...,\alpha_n \}$ en $V$ y $\{\beta_1,...,\beta_n \}$  en $W$. Si las bases anteriores se cambian a nuevas bases $\{ \alpha_1', \alpha_2',...,\alpha_n' \}$ y $\{\beta_1',...,\beta_n' \}$, con matrices de cambio de base $P$ y $Q$ respectivamente y $B$ es la matriz asociada a $T$ en estas nuevas bases, entonces se tiene:
\[
 B = Q^{-1} A P.
\]
\end{teorema}
\begin{corolario}

Si $T: V \to V$ es una transformaci\'on lineal, $\alpha_i = \beta_i$ y $\alpha_i' = \beta_i'$ para todo $i = 1,...,n.$ Entonces la matriz asociada a $T$ respecto a la nueva base es $P^{-1}A P$, $P$ la matriz de cambio de base.
\end{corolario}

\begin{ejemplo}
Sea $T: \Bbb{R}^3 \to \Bbb{R}^3$ dada por $T(x+ y - z, 2x - y + 3z, x- z)$. Para encontrar la matriz asociada a $T$ respecto a la base $\{(1,2,0), (1,-1,0),(1,1,1) \}$, primero encontramos la matriz asociada a $T$ respecto a la base can\'onica, la cual se obtiene evaluando a $T$ en los vectores can\'onicos. Tenemos que $T(1,0,0) =(1,2,1)$, $T(0,1,0) = (1,-1-0)$ y $T(0,0,1)=(-1,3,-1)$, por lo que la matriz asociada a $T$ respecto de la base can\'onica es:

\[
A=
\left(
\begin{matrix}
1 & 1 & -1 \\
2 &-1 & 3 \\
1 & 0 &-1
\end{matrix}
\right)
\]

La matriz de cambio de base es
\[
P=
\left(
\begin{matrix}
1 & 1 & 1 \\
2 &-1 & 1 \\
0 & 0 & 1
\end{matrix}
\right)
\]
con
\[
P^{-1}=\frac{1}{3}
\left(
\begin{matrix}
1 & 1 & -2 \\
2 &-1 & -1 \\
0 & 0 & 3
\end{matrix}
\right)
\]
Aplicando el Teorema anterior obtenemos que la matriz asociada a $T$ respecto de la base $\{(1,2,0), (1,-1,0),(1,1,1) \}$
es:
\[
B=\frac{1}{3}
\left(
\begin{matrix}
1 & 1 & -2 \\
2 &-1 & -1 \\
0 & 0 & 3
\end{matrix}
\right)
\left(
\begin{matrix}
1 & 1 & -1 \\
2 &-1 & 3 \\
1 & 0 &-1
\end{matrix}
\right)
\left(
\begin{matrix}
1 & 1 & 1 \\
2 &-1 & 1 \\
0 & 0 & 1
\end{matrix}
\right)
=
\frac{1}{3}
\left(
\begin{matrix}
1 & 1 & 5 \\
5 &-4 & -2 \\
3 & 3 & 0
\end{matrix}
\right).
\]

\end{ejemplo}

\newpage
\setcounter{page}{1}
\begin{center}
\textbf{TAREA 3: TRANSFORMACIONES LINEALES}
\end{center}
\vspace{.2cm}

Trabajo en equipo

\begin{enumerate}
\item ?`Cu\'ales de las siguientes funciones $T$ de $\Bbb{R}^2$ en $\Bbb{R}^2$ son tranformaciones lineales?
\begin{enumerate}
\item[(a)] $T(x,y)  = (1 + x, y)$
\item[(b)] $T(x,y)  = (y, x)$
\item[(c)] $T(x,y) = (x^2, y)$
\item[(d)] $T(x,y) =(x- y,0)$
\end{enumerate}
\item ?` Existe una tranformaci\'on lineal $T$ de $\Bbb{R}^3$ en $\Bbb{R}^2$ tal que $T(1,-1,1) =(1, 0)$ y $T(1,1,1) =(0,1)$?
\item Para cada una de las siguientes transformaciones lineales, encuentre su n\'ucleo y rango
\begin{enumerate}
\item[a)] Sea $T : \Bbb{R}^2 \to \Bbb{R}^2$ definida por  $T(x,y) = (x-y, 3x + 2y )$
\item[b)] Sea $T: \Bbb{R}^2 \to \Bbb{R}$ definida por $T(x,y) = x +  y$
\item[c)]  Sea $T_A : V \to V$, dada por $T_A(X) = AX$,  con $V$ el espacio vectorial de las matrices $2 \times 2$,
$ A =
\left[
  \begin{matrix}
   1    & 2     \\
   0  &  1
  \end{matrix}
  \right]
$
y
$ X =
\left[
  \begin{matrix}
   x    & y     \\
   z  &  w
  \end{matrix}
  \right]
  $
\end{enumerate}


\item Sea $T$ el operador lineal sobre $\Bbb{R}^2$ definido por
\[
 T(x,y) = (-y, x)
\]
\begin{enumerate}
\item[a)]?` Cu\'al es la matriz de $T$ en la base can\'onica de $\Bbb{R}^2.$
\item[b)] ?`Cu\'al es la matriz de $T$ respecto de la base ordenada en $\Bbb{R}^2$ formada por los vectores
$\alpha_1 =(1,2)$ y $\alpha_2 =(1,-1)$?
\end{enumerate}
\item Sea $T$ la transformaci\'on lineal de $\Bbb{R}^3$ en $\Bbb{R}^2$ definida por
\[
 T(x,y,z) = (x + y, 2z-x).
\]
Si $B$ es la base ordenada can\'onica de $\Bbb{R}^3$ y $B'$ es la base ordenada can\'onica de $\Bbb{R}^2$,
?` cu\'al es la matriz de $T$ respecto al par de bases $B, B'$.

\newpage


\item Sea $T$ el operador lineal en $\Bbb{R}^3$ definido por
\[
T(x,y,z) = (3x + z, - 2x + y, - x+ 2y + 4z)
\]
\begin{enumerate}
\item[a)]?` Cu\'al es la matriz de $T$ en la base can\'onica de $\Bbb{R}^3.$
\item[b)] ?`Cu\'al es la matriz de $T$ respecto de la base ordenada en $\Bbb{R}^3$ formada por los vectores
$\alpha_1 =(1,0,1)$, $\alpha_2 =(-1,2,1)$ y $\alpha_3 =(2,1,1)$?.
\end{enumerate}
\end{enumerate}

\newpage

\setcounter{page}{1}
\section{Diagonalizaci\'on de matrices}

La obtención  de valores y vectores propios  es fundamental para
resolver sistemas de ecuaciones diferenciales, que seran tema
principal en el curso de sistemas dinamicos. En el análisis de
series de tiempo la diagonalización de matrices juega un papel
fundamental en los vectores autorregresivos.

\subsection{Valores y vectores propios}
\subsubsection{Obtención  de los valores y vectores propios de una matriz y sus propiedades}

\begin{definicion}
Si $A$ es una matriz $n \times n$, un vector columna $X$, $n \times
1$, se llama \textbf{vector propio} de $A$ si y solo si $A X =
\lambda X$ para alg\'un escalar $\lambda$. $\lambda$ se llama
\textbf{valor propio} de $A$ que corresponde al vector $X$.
\end{definicion}

\begin{ejemplo}
\begin{enumerate}
\item[a)]  Los valores propios de la matriz
\[
\left(
\begin{matrix}
4 &  3 \\
0 & 1
\end{matrix}
\right)
\]
son $\lambda_1 = 1$ y $\lambda_2 = 4$.
\item[b)] Los valores propios de
la matriz
\[
\left(
\begin{matrix}
1 &  1 \\
0 & 1
\end{matrix}
\right)
\]
son $\lambda_1 = \lambda_2 = 1$.
\item[c)] Los valores propios de
la matriz
\[
\left(
\begin{matrix}
1 &  -1 \\
1 & 1
\end{matrix}
\right)
\]
son complejos.
\item[d)] Los valores propios de
la matriz
\[
\left(
\begin{matrix}
2 &  0 & 0  \\
-7 & 9 & 7 \\
0 & 0 & 2
\end{matrix}
\right)
\]
son $\lambda_1 = 9$, $\lambda_2 = \lambda_3 = 2$.
\end{enumerate}
\end{ejemplo}



\begin{teorema}
Sea $A$ una matriz $n \times n$ y sea $X$ un vector columna $n \times
1$ no nulo.
\begin{enumerate}
 \item $X$ es un vector propio de $A$ perteneciente a $\lambda_0$ si y
 solo si $(A - \lambda_0 I_n) =0$
 \item Un escalar $\lambda_0$ es un valor propio de $A$ si y solo si
$\lambda_0$ es una ra\'{\i}z real de la ecuaci\'on polin\'omica
   $\det(A- \lambda_0 I_n) =  0.$
\end{enumerate}
\end{teorema}

\begin{definicion}
Sea $A$ una matriz $n \times n$. El polinomio $\det(A-\lambda I_n) $
de grado $n$ se llama \textbf{polinomio caracter\'{\i}stico} de $A$
y se le denota por $p_A(\lambda )$. A la ecuaci\'on  $\det (A -
\lambda I_n) = 0 $ se llama la \textbf{ecuaci\'on
caracter\'{\i}stica} de $A.$ Las ra\'{\i}ces reales de la ecuaci\'on
caracter\'{\i}stia de $A$ son los valores propios reales o los
valores caracter\'{\i}sticos de $A$.
\end{definicion}

Un pregunta natural es si existe una manera simple de encontrar el
polinomio caracter\'{\i}stico de una matriz. Para el caso de una
matriz $2 \times 2$ la respuesta es afirmativa y el polinomio
caracter\'{\i}stico puede ser calculado con base en la traza y el
determinante.
\medskip

Si $A$ una matrix $2 \times 2$, entonces
\[
A- \lambda I  = \left( \begin{matrix} a_{11} & a_{12} \\
a_{21} & a_{22} \end{matrix} \right) - \lambda
\left(\begin{matrix}
1 &  0 \\
0 & 1
\end{matrix}
\right) =
\left(\begin{matrix}
a_{11} - \lambda &  a_{12} \\ a_{21} & a_{22} - \lambda
\end{matrix}\right)
\]


\begin{teorema}
Si $A$ es una matriz $2 \times 2$ Entonces
\[
  p_A(\lambda)= \det(A -\lambda I)  =  \lambda^2 - tr(A) \lambda + \det(A).
\]

adem\'as, si $\lambda_1$ y $\lambda_2$ son las ra\'{\i}ces del
polinomio caracter\'{\i}stico $p_A(\lambda) = \det (A - \lambda I) =
0$, entonces
\begin{align*}
   tr(A) &= \lambda_1 + \lambda_2 \\
 \det(A) &= \lambda_1 \lambda_2
\end{align*}

\end{teorema}

\begin{ejemplo}
Sea
\[
\left(\begin{matrix}
4 &  2 \\ 3 & 3
\end{matrix}\right)
\]

Resolvemos la ecuación $Ax=\lambda x$ aplicando los siguientes
pasos:

\begin{enumerate}
\item[1.] Calcular el determinante de $A - \lambda I$:
\[
det(A - \lambda I) =
 det \left|
 \begin{matrix}
   4 - \lambda & 2 \\
   3   & 3 - \lambda
  \end{matrix}
  \right|
\]
o sea, el polinomio característico de la matriz $A$ es:
\[
p(\lambda) = det(A- \lambda I) =(4- \lambda) (3 - \lambda)- 6
\]
Otra forma de calcularlo es usando el teorema anterior:
\begin{align*}
 tr(A) &=4 + 3 = 7 \\
\det (A) &= 12- 6 = 6
\end{align*}
\begin{align*}
  p_A(\lambda) &= \det(A -\lambda I)  =  \lambda^2 - tr(A) \lambda + \det(A) \\
    & = \lambda^2 - 7 \lambda + 6
\end{align*}

\item[2.] Encontrar las raíces del polinomio característico:
\begin{align*}
 p(\lambda) = det(A- \lambda I) &= 0 \\
             (4- \lambda) (3 - \lambda)- 6 &= 0 \\
             \lambda^2 - 7 \lambda + 6  &= 0 \\
             (\lambda-6) (\lambda -1) &= 0
\end{align*}

entonces las ra\'{\i}ces del polinomio caracter\'{\i}stico
$p_A(\lambda)$ son $\lambda_1 = 6$ y $\lambda_2 = 1$ las cuales
cumplen
\begin{align*}
\lambda_1 + \lambda_2 &= tr(A) \\
7 = 6 + 1 &= tr(A)  \\
\lambda_1 \lambda_2 &= \det (A) \\
   6  = 6 \cdot 1 &= \det(A)
\end{align*}

\item[3.] Para cada valor característico, resolvemos la ecuación $(A- \lambda I)x =
0$. Buscamos ahora los correspondientes vectores propios asociados a
los valores propios  $\lambda_1 = 1$ y $\lambda_2 = 6$
respectivamente.

Para $\lambda_1= 1$


\[
\left(\begin{matrix} 3 &  2 \\ 3 & 2
\end{matrix}\right)
\left(\begin{matrix} x_1 \\ x_2
\end{matrix}\right)=
\left(\begin{matrix} 0 \\ 0
\end{matrix}\right)
\]
\begin{align*}
 3x_1 + 2x_2 &= 0 \\
 3x_1 +  2x_2 &= 0
 \end{align*}

 cuyas soluciónes son de la forma $x_1= -2/3x_2$.

 Por lo tanto , para $\lambda_1 = 1$, los vectores propios son de la
 forma
$v_1 = \alpha \left(\begin{matrix} -2/3  \\ 1
\end{matrix}\right)$.

Para $\lambda_2= 6$
\[
\left(\begin{matrix} -2 &  2 \\ 3 & -3
\end{matrix}\right)
\left(\begin{matrix} x_1 \\ x_2
\end{matrix}\right)=
\left(\begin{matrix} 0 \\ 0
\end{matrix}\right)
\]
\begin{align*}
 -2x_1 + 2x_2 &= 0 \\
 x_1   &= x_2
 \end{align*}

 cuya solución es $x_1= x_2 =  1$.

 Por lo tanto , para $\lambda_2 = 6$, el vector propio es
 $v_2 =\left(\begin{matrix} 1 \\ 1
\end{matrix}\right)$

\end{enumerate}
\end{ejemplo}




\begin{teorema}
Si $A$ es una matriz $3 \times 3$, entonces su polinomio
caracter\'{\i}stico es de la forma
\[
  p_A(\lambda) = -\lambda^3 + tr(A) \lambda^2 + \frac{1}{2}
\left(tr(A^2)- tr(A)^2  \right) \lambda + det (A).
\]
\end{teorema}



Los vectores propios tambi\'en poseen una representaci\'on sencilla
en el caso de una matriz $A$ de $2 \times 2$ como la anterior. Para
encontrar el vector\vspace{.2cm} propio
$
\left(
 \begin{matrix}
   x_1  \\
   x_2
  \end{matrix}
  \right)
$
asociado al valor propio $\lambda$, se resuelve el siguiente sistema
de ecuaciones:
\begin{align*}
     ax_1 + bx_2 &= \lambda_1 x_1, \\
     ax_1 + dx_2 &= \lambda_1 x_2.
\end{align*}

Por construcci\'on, las ecuaciones  son dependientes, y el sistema no
es originalmente diagonal. Tenemos que alguno de los coeficientes $b$
o $c$ es diferente de cero. Supongamos que $b \ne 0$; suponiendo que
$x_1 = b$ en la primera ecuaci\'on, es f\'acil ver que $x_2 = \lambda -
a$, de manera que
$ \textbf{v} =
\left(
\begin{matrix}
   b  \\
   \lambda - a
\end{matrix}
\right)
$
es un vector propio con valor propio  $\lambda$. En el caso en que $b
= 0$ y $c \ne 0$, utilizamos \vspace{.2cm} la segunda ecuaci\'on y obtenemos que
$
\left(
\begin{matrix}
 \lambda - d  \\
  c
  \end{matrix}
  \right)
$
es el vector propio buscado.


\begin{ejemplo}
Sea
\[
 A = \left(
 \begin{matrix}
   1 & 1  \\
   2 & 2
  \end{matrix}
  \right)
\]
notemos que la matriz es singular y que por lo tanto $\lambda = 0 $ es una ra\'{\i}z del polinomio
caracter\'{\i}stico. El polinomio esta dado por
\[
p_A(\lambda) = \lambda (\lambda - 3),
\]
con ra\'{\i}ces $\lambda_1 = 3$ y $\lambda_2 = 0$. es f\'acil ver que
 $ v_1 = \left(
 \begin{matrix}
   1  \\
   2
  \end{matrix}
  \right)
$
es un vector propio asociado al valor propio $\lambda_1 = 3$ y que $ v_2 =
 \left(
 \begin{matrix}
   1 \\
   -1
  \end{matrix}
  \right)
$
es un vector no nulo que satisface la ecuaci\'on $A \textbf{v} = \textbf{0}$, o sea un vector propio con valor propio
$\lambda = 0$.
\end{ejemplo}

\begin{ejemplo}
Sea
\[
 A = \left(
 \begin{matrix}
   1 & -1 & 4 \\
   3 & 2 & -1 \\
   2 & 1 & -1
  \end{matrix}
  \right)
\]
Entonces el polinomio caracter\'{\i}stico es
\begin{align*}
 p_A (\lambda) &= det
 \left(
 \begin{matrix}
   1 - \lambda & -1 & 4 \\
   3 & 2 - \lambda & -1 \\
   2 & 1 & -1 - \lambda
  \end{matrix}
  \right) \\
  &= -(\lambda-1)(\lambda -3 )(\lambda + 2).
\end{align*}
Por lo tanto los valores propio de $A$ son $\lambda_1 = 1$, $\lambda_2 = 3$ y $\lambda_3 = -2.$ Ahora encontraremos los vectores propios  correspondientes a estos valores propios.
Si $\lambda_1 = 1$, resolvemos el sistema $(A - \lambda I)v = 0$. Estos es, si $\textbf{v} = (a,b,c)$ entonces
\[
\left(
 \begin{matrix}
   0 & -1 & 4 \\
   3 & 1 & -1 \\
   2 & 1 & -2
  \end{matrix}
  \right)
\left(
 \begin{matrix}
   a \\
   b \\
   c
  \end{matrix}
  \right)
 =
\left(
 \begin{matrix}
   0 \\
   0 \\
   0
  \end{matrix}
  \right)
 \]

Al resolver estas ecuaciones y escoger $a = -1$, obtenemos $b = 4$ y $c = 1$. En concluisi\'on,
\[
v_1= \left(
 \begin{matrix}
 -1 \\
  4 \\
  1
  \end{matrix}
  \right)
\]
es vector propio con valor propio $\lambda_1 = 1.$ Para verificarlo consideramos
\[
A v_1 = \left(
 \begin{matrix}
   1 & -1 & 4 \\
   3 & 2 & -1 \\
   2 & 1 & -1
  \end{matrix}
  \right)
\left(
 \begin{matrix}
   -1 \\
   4 \\
   1
  \end{matrix}
  \right)
 =
\left(
 \begin{matrix}
   -1 \\
   4 \\
   1
  \end{matrix}
  \right)
  = \lambda_1 v_1
 \]
De modo semejante se obtiene que el vector $v_2 = \left(
 \begin{matrix}
   1 \\
   2 \\
   1
  \end{matrix}
  \right)
$
es vector propio de $\lambda_2 = 3$ y $ v_3 = \left(
 \begin{matrix}
   -1 \\
   1 \\
   1
  \end{matrix}
  \right)
$
es un vector propio correspondiente a $\lambda_3 = -2.$

\end{ejemplo}


En el caso de ra\'{\i}ces repetidas,  es que no tiene una base de
vectores propios y por lo tanto la matriz no puede ser
diagonalizada. Sin embargo puede obtenerse una matriz triangular de
la forma
\begin{equation}
\label{T}
T =
\left(
 \begin{matrix}
   \lambda & 1   \\
   0   & \lambda
  \end{matrix}
  \right)
\end{equation}

Para obtener la matriz $T$, lo que se necesita es el vector propio $\textbf{v}$ co\-rres\-pon\-di\-en\-te al valor propio $\lamba$ y otro vector $\textbf{w}$ tal que la matriz
\[
  P = \left[ \textbf{ v \quad w } \right]
\]

cumpla $P^{-1}A P  = T$, donde $T$ es la matriz triangular dada en
\ref{T}. Para obtener el vector $\textbf{w}$ se procede como sigue.

\begin{definicion}
Sea $\textbf{v}$ un vector propio con valor propio $\lambda$. Se dice
que $\textbf{w}$ \textbf{ es un vector propio generalizado} si satisface
\[
    (A - \lambda I)\textbf{w} = \textbf{v}.
\]
\end{definicion}

Si la matriz $A$ est\'a dada por
\[
 A  =
\left(
 \begin{matrix}
  a & b  \\
  c & d
  \end{matrix}
  \right)
\]
y $b \ne 0$, entonces un vector propio asociado al valor propio
$\lambda$ est\'a dado por
\[
  \textbf{v} =
\left(
 \begin{matrix}
   b  \\
   \lambda - a
  \end{matrix}
  \right).
\]
El valor propio es una ra\'{\i}z del polinomio $\lambda^2 - \lambda
tr(A)  + det(A)$ y si es una ra\'iz doble debe ser de la forma
$\lambda = \frac{tr(A)}{2} = \frac{a + d}{2}$. Resolvamos ahora el
sistema  \vspace{.2cm} $(A - \lambda I) \textbf{w} = \textbf{v}$, con estos valores
espec\'{\i}ficos de $\textbf{v}$ y $\lambda.$ Si $ \textbf{w} =
\left(
\begin{matrix}
   x  \\
   y
  \end{matrix}
  \right)
$

se tiene que

\[
\left(
 \begin{matrix}
   \frac{a-d}{2} & b  \\
   c & \frac{d -a}{2}
  \end{matrix}
  \right)
\left(
 \begin{matrix}
   x  \\
   y
  \end{matrix}
  \right)
 =
\left(
 \begin{matrix}
   b  \\
 \frac{  d - a}{2}
  \end{matrix}
  \right)
\]

\vspace{.2cm}
y por lo tanto es f\'acil ver que $\textbf{w} =
\left(
\begin{matrix}
   0  \\
   1
  \end{matrix}
  \right)
$
siempre es soluci\'on. Si en la \vspace{.2cm} matriz $A$, $b = 0$ pero $c \ne 0$,
entonces se utiliza $\textbf{v} =
\left(
\begin{matrix}
   \lambda - d \\
   c
  \end{matrix}
  \right)
 $
como vector propio y procediendo de manera an\'aloga tenemos que $
\textbf{w} = \left(
 \begin{matrix}
   1  \\
   0
  \end{matrix}
  \right)
$

es un vector propio generalizado.

\begin{ejemplo}
Sea

\[
A  =
 \left(
  \begin{matrix}
     3   & -2  \\
     2   & -1
  \end{matrix}
  \right).
  \]

Como
\begin{align*}
det(A- \lambda I) &= det  \left(
  \begin{matrix}
     3-\lambda   & -2  \\
     2   & -1-\lambda
  \end{matrix}
  \right) = (3- \lambda)(-1-\lambda) + 2
\end{align*}

entonces:
\begin{align*}
det(A- \lambda I) &= (3- \lambda)(-1-\lambda) + 2 = 0 \\
                   &= -3-3\lambda + \lambda + \lambda^2 + 4 = 0 \\
                   &= \lambda^2 - 2\lambda + 1 = 0
\end{align*}


Por lo tanto la ecuación característica de la matriz $A$ es
$\lambda^2 - 2\lambda + 1 = 0$, cuya \'unica ra\'{\i}z es $\lambda =
1$. El \vspace{.2cm} los vectores propios correspondientes son
\[
 \left(
  \begin{matrix}
     2   & -2  \\
     2   & -2
  \end{matrix}
  \right)
 \left(
  \begin{matrix}
     x_1  \\
     x_2
  \end{matrix}
  \right)
= \left(
  \begin{matrix}
     0  \\
     0
  \end{matrix}
  \right)

de donde
\begin{align*}
2x_1 - 2x_2 &= 0 \\
  x_1 &= x_2.
\end{align*}

es decir, los vectores propios asociados al valor propio $\lambda_1
= 1$ son de la forma $\alpha \left(
  \begin{matrix}
     1  \\
     1
  \end{matrix}
  \right)
   $.
   Entonces escogemos al vector propio
$
   \left(
  \begin{matrix}
     -2  \\
     -2
  \end{matrix}
  \right)
$  y el vector propio generalizado, que se encuentra resolviendo

\[
\left(
 \begin{matrix}
   2 & -2  \\
   2 & -2
  \end{matrix}
  \right)
\left(
 \begin{matrix}
   a  \\
   b
  \end{matrix}
  \right)
 =
\left(
 \begin{matrix}
   -2  \\
 -2
  \end{matrix}
  \right),
\]

es simplemente
\[
\textbf{w} =
\left(
 \begin{matrix}
   0  \\
   1
  \end{matrix}
  \right)
\]

\end{ejemplo}


\begin{teorema}\label{VP}
Sea

\begin{equation*}
A  =
 \left(
  \begin{matrix}
     0   & 1  &  0 &    \cdots   & 0\\
     0   & 0  &  1  &    \cdots   & 0 \\
    \vdots    & \vdots  & \vdots  &  \ddots   & 1 \\
     - a_{0}  &- a_{1}  & -a_{2} &\cdots  & -a_{m-1}
  \end{matrix}
  \right)
\end{equation*}
Entonces la ecuaci\'on caracter\'{\i}stica de la matriz $A$ es:
\[
p(\lambda)_A = (-1)^m \left(\lambda^m + a_{m-1} \lambda^{m-1} + \cdots + a_1 \lambda + a_0 \right) = 0
\]
y para cada valor propio $\lambda_k$, el vector
\[
 v_k =
\left(
 \begin{matrix}
   1  \\
   \lambda_k \\
   (\lambda_k)^2 \\
   \vdots \\
   (\lambda_k)^{m-1}
  \end{matrix}
  \right)
\]
\end{teorema}

es un vector propio.


\begin{ejemplo}

Sea
\[
A  =
 \left(
  \begin{matrix}
     0   & 1  &  0 \\
     0   & 0  &  1  \\
    0 & 1 & 0
  \end{matrix}
  \right)
\]

Por el Teorema (\ref{VP}), la ecuaci\'on caracter\'{\i}stica es
$\lambda^3  - \lambda = 0$, los valores propios son $\lambda_1 = 0$,
$\lambda_2 = 1$ y $\lambda_3 = -1$ y para $\lambda_1 =  0$,
\[
 v_1 =
\left(
 \begin{matrix}
   1  \\
   \lambda_1 \\
   (\lambda_1)^2
  \end{matrix}
  \right)
= \left(
 \begin{matrix}
   1  \\
   0 \\
   0
  \end{matrix}
  \right)
 \]
es vector propio. Del mismo modo,

\[
 v_2 =
\left(
 \begin{matrix}
   1  \\
   \lambda_2 \\
   (\lambda_2)^2
  \end{matrix}
  \right)
= \left(
 \begin{matrix}
   1  \\
   1 \\
   1
  \end{matrix}
  \right)
  \]
es vector propio con valor propio $\lambda_2 = 1$. Finalmente,

\[
 v_3 =
\left(
 \begin{matrix}
   1  \\
   \lambda_3 \\
   (\lambda_3)^2
  \end{matrix}
  \right)
= \left(
 \begin{matrix}
   1  \\
   -1 \\
   1
  \end{matrix}
  \right)
\]
es vector propio con valor propio $\lambda_3 = -1$.
\end{ejemplo}


\begin{ejemplo}
Sea
\[
A  =
 \left(
  \begin{matrix}
     0   & 1  \\
     -2   & 2
  \end{matrix}
  \right).
\]
El polinomio caracter\'{\i}stico de la ecuaci\'on es $p_A(\lambda) =
\lambda^2 - 2\lambda + 2$, por lo que los valores propios son
\[
  \lambda_{1,2} = \frac{2 \pm \sqrt{4 - 8}}{2} = \frac{2 \pm
  \sqrt{-4}}{2} = 1 \pm i,
\]
Es decir,
\begin{align*}
\lambda_1 = \lambda = 1+i,
\lambda_2 = \bar{\lambda} = 1- i.
\end{align*}
Tomemos $\lambda = 1 + i$. Encontraremos vectores propios de la manera
usual; esto es, si

\[
v  =
 \left(
  \begin{matrix}
     a  \\
     b
  \end{matrix}
  \right),
\]

entonces,

\[
(A - \lambda I)v   =
 \left(
  \begin{matrix}
    -1 - i   & 1  \\
     -2   & 1 - i
  \end{matrix}
  \right)
 \left(
  \begin{matrix}
   a \\
   b
  \end{matrix}
  \right)
 =
 \left(
  \begin{matrix}
     0  \\
     0
  \end{matrix}
  \right).
\]
Si escogemos $a = 1$ obtenemos que $b = 1 + i$, y por lo tanto
\[
  v  =
 \left(
  \begin{matrix}
     1  \\
     1 + i
  \end{matrix}
  \right)
\]

es vector propio con valor propio $1 + i$.
\end{ejemplo}



\begin{ejemplo}
Sea
\[
A  =
 \left(
  \begin{matrix}
     0   & 1  \\
     -1   & 0
  \end{matrix}
  \right)
\]

Entonces el polinomio caracter\'{\i}stico  es
\[
p_A(\lambda) = \lambda^2 + 1.
\]
Las ra\'{\i}ces de $p_A$ son  $\lambda = i$ y $\bar{\lambda} =
-i$. Encontraremos un vector propio $v$ para el valor propio $\lambda
= i$ usando el teorema (\ref{VP}). As\'{\i}
\[
v  =
 \left(
  \begin{matrix}
     1 \\
     i
  \end{matrix}
  \right)
\]
es un vector propio  con valor propio $\lambda.$
\end{ejemplo}

\newpage
\setcounter{page}{1}
\begin{center}
\textbf{TAREA 1: VALORES Y VECTORES PROPIOS}
\end{center}

\vspace{.2cm}

Trabajo individual. \\

Obtener los valores y vectores propios de las siguientes matrices.
\begin{enumerate}
  \item
\[
 A =
 \left[
  \begin{matrix}
     -2   & 1   \\
     1   & -2
  \end{matrix}
  \right]
 \]
\item

\[
 B =
 \left[
  \begin{matrix}
     4   & -1   \\
     2   & 1
  \end{matrix}
  \right]
 \]
  \item
\[
 C =
 \left[
  \begin{matrix}
     1   & 1   \\
     -2   & 4
  \end{matrix}
  \right]
 \]
 \item
\[
 D =
 \left[
  \begin{matrix}
     1   & 2   \\
     2   & 1
  \end{matrix}
  \right]
 \]
\item
\[
 E =
 \left[
  \begin{matrix}
     3   & 1   \\
     5   & -1
  \end{matrix}
  \right]
 \]
 \item
\[
 F =
 \left[
  \begin{matrix}
     -3   & 4   \\
     -2   & 1
  \end{matrix}
  \right]
 \]
 \item
\[
 G =
 \left[
  \begin{matrix}
     1  & 4   \\
     -4  & 1
  \end{matrix}
  \right]
 \]
\item
\[
 H =
 \left[
  \begin{matrix}
     2   & 8   \\
     -1   & -2
  \end{matrix}
  \right]
 \]
\end{enumerate}

\newpage

\setcounter{page}{1}
\subsection{Diagonalización de matrices}

\begin{definicion}
Dos matrices cuadradas $A$ y $B$  de orden $n$  son equivalentes si
existe una matriz $P$ de orden $n$, no singular (det($P \ne 0$)) tal
que $ A = P^{-1} A P$.
\end{definicion}

\begin{ejemplo}
Las matrices $
 \left(
  \begin{matrix}
     3   & 0   \\
     1   & 1
  \end{matrix}
  \right)
$ y $
 \left(
  \begin{matrix}
     3   & 0   \\
     1   & 1
  \end{matrix}
  \right)
$ son equivalentes pues:

\[
\left(
  \begin{matrix}
     3   & 2   \\
     1   & 1
  \end{matrix}
  \right)^{-1}
  \left(
  \begin{matrix}
     3   & 0   \\
     1   & 1
  \end{matrix}
  \right)
  \left(
  \begin{matrix}
     3   & 2   \\
     1   & 1
  \end{matrix}
  \right)
  =
  \left(
  \begin{matrix}
     1   & 0   \\
     3   & 3
  \end{matrix}
  \right)
\]

\end{ejemplo}

\begin{definicion}
Una matriz cuadrada $A$ es diagonalizable si posee una matriz
equivalente $B$ que sea diagonal.
\end{definicion}

Suponga que  la matriz $A$ de orden $n$  tiene $n$ vectores
característicos linealmente independientes. Si estos vectores
característicos  son las columnas de una matriz $S$, entonces
$S^{-1} A S$ es una matriz diagonal $\Lambda$, es decir $A$ es
diagonalizable y los valores característicos de $A$ están sobre la
diagonal de $\Lambda$:

\[
S^{-1} A S = \Lambda = \left(
  \begin{matrix}
     \lambda_1   &  &   &  \\
                 &  \lambda_2 &    &   \\
  &  &   \ddots  &   \\
  &  &     & \lambda_n
  \end{matrix}
  \right).
\]

\vspace{.5cm}

\textbf{Diagonalización de matrices de orden 2}

\vspace{.5cm}

Consideremos la matriz $A= \left(
  \begin{matrix}
     a_{11}   & a_{12}   \\
     a_{21}   & a_{22}
  \end{matrix}
  \right)$ y calculemos sus valores propios, los cuales son las soluciones de:
\[
 \left|
  \begin{matrix}
     a_{11} - \lambda   & a_{12}   \\
     a_{21}   & a_{22} -\lambda
  \end{matrix}
  \right| = 0
\]

Entonces tenemos los siguientes casos:
\begin{enumerate}
\item \textbf{Dos raíces reales distintas} $\lambda_1$ y $\lambda_2$:
Entonces la matriz $A$ es equivalente a la matriz $A= \left(
  \begin{matrix}
     \lambda_1   & 0   \\
     0  & \lambda_2
  \end{matrix}
  \right)$ y por tanto es diagonalizable.

\begin{ejemplo}
Dada la matriz

\[
 A = \left[
  \begin{matrix}
   1  & 2  \\
   3  & 0
  \end{matrix}
  \right]
\]

Hallar
\begin{enumerate}
\item Los valores propios de $A$.
\item Los vectores propios $A$.
\item Diagonalizar la matriz $A$
\end{enumerate}

La ecuaci\'on caracter\'{\i}stica  es
\[
   \mid A - \lambda I  \mid =
\left|
  \begin{matrix}
   1 - \lambda  & 2  \\
   3   &   -\lambda
  \end{matrix}
  \right|  = \lambda^2 - \lambda - 6 = 0
\]

cuyas soluciones $\lambda_1 = -2$ y $\lambda_2 =  3$ son los valores
propios de $A$. Para $\lambda = \lambda_1 = -2$ da

\begin{align*}
3x_1 + 2x_2 &= 0 \\
3x_1 + 2x_2 &= 0
\end{align*}

Tomando $x_2 = t$ tenemos $x_1 = - \frac{2}{3} t $. Por lo tanto los
vectores propios a $\lambda_1 = -2$ son
\[
 x = t \left(
  \begin{matrix}
   - 2/3   \\
   1
  \end{matrix}
  \right)   \quad (t \in \Bbb{R})
\]
Para $\lambda_2 = 3$, $x_1 = x_2$. Luego los vectores propios son:
\[
 x = s \left(
  \begin{matrix}
   1   \\
   1
  \end{matrix}
  \right)   \quad (t \in \Bbb{R})
\]
Finalmente, como los lo valores propios de $A$ son $\lambda_1 = -1$
y $\lambda_2 = 3$, podemos tomar los vectores propios respectivos
\[
\left(
  \begin{matrix}
   2   \\
   -3
  \end{matrix}
\right) \quad  \text{y} \quad
  \left(
  \begin{matrix}
   1   \\
   1
  \end{matrix}
  \right)
\]

As\'{\i}

\[
P= \left(
  \begin{matrix}
   2   & 1  \\
   -3  & 1
  \end{matrix}
\right) \quad  \text{para la cual} \quad P^{-1}  = \left(
  \begin{matrix}
   1/5  & -1/5   \\
   3/5  & 2/5
  \end{matrix}
  \right)
\]

Multiplicando deducimos que $P^{-1}AP =  \left(
  \begin{matrix}
     -2  & 0   \\
     0  & 3
  \end{matrix}
  \right)$
\end{ejemplo}
\item \textbf{Una raíz doble} $\lambda$ y el rango de $A- \lambda I$ igual a
1; entonces la matriz $A$ es equivalente a la matriz: $\left(
  \begin{matrix}
     \lambda   & 0   \\
     1  & \lambda
  \end{matrix}
  \right)$ y no es diagonalizable. Observemos que si el rango de $A- \lambda
  I$ es 0, entonces $A= \left(
  \begin{matrix}
     \lambda   & 0   \\
     0  & \lambda
  \end{matrix}
  \right)$ que ya es diagonal.
\begin{ejemplo}
Sea $A= \left(
  \begin{matrix}
     0   & 1   \\
     0  & 0
  \end{matrix}
  \right)$.

La ecuaci\'on caracter\'{\i}stica  es
\[
   \mid A - \lambda I  \mid =
\left|
  \begin{matrix}
   - \lambda  & 1  \\
   0  &   -\lambda
  \end{matrix}
  \right|  = \lambda^2  = 0
\]

cuyas soluciones $\lambda =\lambda_1 = \lambda_2 = 0 $, es decir,
$\lambda = 0$ es un valor característico doble y el rango de la
matriz $A- \lambda I$ es 1, entonces la matriz $A$ es equivalente a
la matriz $\left(
  \begin{matrix}
  \lambda  & 0  \\
   1   &  \lambda
  \end{matrix}
  \right) =
  \left(
  \begin{matrix}
  0  & 0  \\
   1   &  0
  \end{matrix}
  \right)
$. la cual no es diagonal.
\end{ejemplo}
\item \textbf{Dos raíces complejas conjugadas}  $a + bi$ y $a- bi$:  entonces
la matriz $A$ es equivalente  a la matriz $ A = \left(
  \begin{matrix}
  a  & -b  \\
   b   & a
  \end{matrix}
  \right)
  $
y no es diagonalizable.
\begin{ejemplo}
Sea
\[
A  =
 \left(
  \begin{matrix}
     0  & 1  \\
     -1   & 0
  \end{matrix}
  \right)
\]


\[
   \mid A - \lambda I  \mid =
\left|
  \begin{matrix}
   - \lambda  & 1  \\
   -1  &   -\lambda
  \end{matrix}
  \right|  = \lambda^2  + 1 = 0
\]

cuyas ra\'{\i}ces son $\lambda_1= \lambda = i$ y $\lambda_2=
\bar{\lambda} = -i$. Entonces la matriz $A$ es equivalente a la
matriz
\[
 \left(
  \begin{matrix}
     0  & -1  \\
     1   & 0
  \end{matrix}
  \right)
\] y no es diagonalizable.


\end{ejemplo}
\end{enumerate}

\newpage

\setcounter{page}{1}
\begin{center}
\textbf{TAREA 2: DIAGONALIZACIÓN DE MATRICES}
\end{center}

\vspace{.2cm}

Tarea individual. \\

\begin{enumerate}
  \item Para la matriz:
\[
 A =
 \left[
  \begin{matrix}
     2   & 1   \\
     1   & 2
  \end{matrix}
  \right]
 \]
\begin{enumerate}
  \item Escribir la ecuaci\'on caracter\'{\i}stica y calcular los valores propios.
  \item Calcular los vectores propios correspondientes a la
  equaci\'on caracter\'{\i}stica.
  \item Diagonalize $A$.
\end{enumerate}
\vspace{.2cm}
\item Consteste las mismas preguntas del problema 1 para la matriz $A$
  dada por:
\[
 A =
 \left[
  \begin{matrix}
     1   & 0 & 1   \\
     0 & 1 & 1     \\
     1 & 1 & 2
  \end{matrix}
  \right]
 \]
\vspace{.2cm}
\item Obtener los valores propios de la matriz $P = X(X^T X)^{-1}X^T$,
  si:
\[
 X =
 \left[
  \begin{matrix}
     1   & 2   \\
     1   & 4   \\
     1   & 1   \\
     1 & 3
  \end{matrix}
  \right].
 \]
\end{enumerate}

\newpage

\setcounter{page}{1}
\subsection{Matrices simétricas y formas cuadráticas}


Sea $A$ una matriz cuadradada simetrica. En este caso, si
postmultiplicamos $A$ por un  vector $x$ y la premultiplicamos por
el transpuesto de ese mismo vector $x$, tenemos una \textbf{forma
cuadr\'atica}. Por ejemplo,

\[
 \left(
  \begin{matrix}
     x_1   & x_2
  \end{matrix}
  \right)
  \left(
  \begin{matrix}
     a_{11}   & a_{12}  \\
     a_{21}   & a_{22}
  \end{matrix}
  \right)
  \left(
  \begin{matrix}
     x_1 \\
     x_2
  \end{matrix}
  \right) = a_{11} x_1^2 + (a_{21} + a_{12})x_1x_2 + a_{22} x_2^2.
 \]

 Supongamos que $A$ es la matriz identidad. En este caso, no es
 dific\'{\i}l ver que cualesquiera que sean los valores de $x_1$ y
 $x_2$, la forma cuadr\'atica debe ser no negativa. De hecho, si $x_1$ y
 $x_2$ no son cero, $xAx$ ser\'a estrictamente positiva. La matriz
 identidad es un ejemplo de \textbf{  matriz definida positiva}.

\vspace{.2cm}


\textbf{Matrices definidas}. Una matriz cuadrada $A$ es:




\begin{enumerate}
\item[(a)] \textbf{definida positiva} si $x^t A x > 0$ cualquiera que sea $x
\ne 0$;
\item[(b)] \textbf{definida negativa} si $x^t A x < 0$ cualquiera
que sea $x$;
\item[(c)] \textbf{semidefinida positiva} si $x^t A x \geq 0$
cualquiera que sea $x$;
\item[(d)] \textbf{semidefinida negativa} si $x^t A x \leq 0$,
cuaquiera que sea $x$.
\end{enumerate}


\begin{ejemplo}
Considere el $n$-vector de variables aleatorias

\[
y = \left[
\begin{matrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{matrix}
\right]
\]

y sea

\[
\tilde{y} = \left[
\begin{matrix}
y_1 -E(y_1) \\
y_2 -E(y_2)\\
\vdots \\
y_n-E(y_n)
\end{matrix}
\right]
\]

la  matriz covarianza de $y$ es definida como


\[
V = E \left[
\begin{matrix}
\tilde{y_1}^2 & \tilde{y_1}\tilde{y_2} & \hdots & \tilde{y_1}\tilde{y_n}  \\
\tilde{y_2}\tilde{y_1} & \tilde{y_2}^2 & \hdots & \tilde{y_2}\tilde{y_n} \\
\vdots & \vdots &  \ddots &  \vdots \\
\tilde{y_n}\tilde{y_1} &  \tilde{y_n}\tilde{y_2} &  \hdots &
 \tilde{y_n}^2
\end{matrix}
\right]
\]

La matrix covarianza es simetrica y semidefinida positiva. Para
demostrar esta afirmaci\'on, primero notemos que $V$ se puede
escribir como
\[
 V= E(\tilde{y}\tilde{y}^T )
\]
As\'{\i}, para cualquier $x \ne 0$, tenemos

\begin{align*}
x^T V x &= x^T E(\tilde{y}\tilde{y}^T )x \\
       &= E x^T (\tilde{y}\tilde{y}^T) x \\
       &= E\left(\limits\sum_{j=1}^{n} x_j \tilde{y_j} \right)^2 \\
       &= E \left(\limits\sum_{j= 1}^{n}x_j ( y_j - E(y_j)) \right)^2
       \geq 0.
\end{align*}
\end{ejemplo}


En algunos casos no es necesario que $x^t A x$ tenga un signo
definido en el caso de todos los valores de $x$, si no s\'olo de un
conjunto restringido de ellos. Decimos que $A$ es definida positiva
sujeta a la restricci\'on $bx = 0$. Las otras definiciones se
ampl\'{\i}an de manera natural al caso con restricciones.


Las \textbf{matrices menores} de la matriz $A$  son las matrices que
se forman eliminando $k$-columnas y $k$-filas de la misma
numeraci\'on. Los menores principales naturalmente ordenados o
encadenados de la matriz $A$ vienen dados por

\[
a_{11} \qquad
 \left(
  \begin{matrix}
     a_{11}   & a_{12}  \\
     a_{21}   & a_{22}
  \end{matrix}
  \right)
\qquad
 \left(
  \begin{matrix}
     a_{11}   & a_{12} & a_{13}  \\
     a_{21}   & a_{22} & a_{23} \\
     a_{31}  & a_{32} & a_{33}
  \end{matrix}
  \right)
\]

etc. Los determinantes menores o menores de una matriz o menores
principales, son los determinantes de las matrices menores

\[
D_1= a_{11} \qquad D_2 =
 \left|
  \begin{matrix}
     a_{11}   & a_{12}  \\
     a_{21}   & a_{22}
  \end{matrix}
  \right|
\qquad D_3=
 \left|
  \begin{matrix}
     a_{11}   & a_{12} & a_{13}  \\
     a_{21}   & a_{22} & a_{23} \\
     a_{31}  & a_{32} & a_{33}
  \end{matrix}
  \right|
\]

etc.


Supongamos que se nos da una matriz cuadrada $A$ y un vector $b$.
Podemos \text{ orlar} A por medio de $b$ de la siguiente manera:

\[
 \left(
  \begin{matrix}
  0    & b_1  & \cdots   & b_n \\
     b_1   & a_{11}  & \cdots   & a_{1n} \\
    \vdots    & \vdots  & \vdots   & \vdots \\
      b_n  & a_{n1}  & \cdots  & a_{nn}
  \end{matrix}
  \right)
\]

Esta matriz  se denomina \textbf{matriz orlada}. La \'util
generalizaci\'on a las matrices menores genera los \textbf{menores
principales que conservan la orla}. Son las submatrices que se
forman eliminando las filas y las columnas adecuadas de $A$ y los
elementos de la orla que tienenla misma numeraci\'on, pero sin
eliminar la propia orla. Por lo tanto, las eliminaciones pueden
provenir de filas y columnas  de 1 al $n$, pero no de la fila o la
columna $n + 1$, que es donde se encuentra la orla. Dada esta
terminolog\'{\i}a, para que una matriz sea definida positiva o
negativa.


\begin{teorema}. Una matriz cuadrada $A$ es:

\begin{enumerate}
\item[(a)] definida positiva si y s\'olo si los menores principales
  son todos positivos.
\item[(b)] definida negativa si y s\'olo si los menores principales
  tienen el signo $(-1)^k$ siendo $k = 1,...,n.$
\item[(c)] definida positiva sujeta a la restricci\'on $bx = 0$ si y
s\'olo si los menores principales que conservan la orla son todos
ellos negativos;
\item[(d)] definida negativa sujeta a la restricci\'on $bx = 0 $ si y
  s\'olo si los menores principales que generan la orla tienen el
  signo $(-1)^k$ siendo $k= 2,...,n.$
\end{enumerate}
\end{teorema}

\newpage


\begin{definicion}
Una forma cuadratica en dos variables es un polinomio de la forma
\[
 q = au^2 + 2huv + bv^2
\]
\end{definicion}

\begin{definicion}
Una forma cuadr\'atica $q$ se dice

\begin{enumerate}
\item[(a)] positiva definida si $q > 0$.
\item[(b)] semidefinida positiva si $q \geq 0 $.
\item[(c)] semidefinida negativa si $q \leq 0 $
\item[(d)] definida negativa si $q <  0$.
\end{enumerate}
\end{definicion}

Una forma cuadr\'atica se puede expresar en t\'erminos de matrices.
Sea
\[
 q = au^2 + 2huv + bv^2
\]
entonces

\[
q = \left[
\begin{matrix}
u & v
\end{matrix}
 \right]
\left[
\begin{matrix}
a & h \\
h & b
\end{matrix}
 \right]
\left[
\begin{matrix}
u \\
v
\end{matrix}
\right]
\]


luego, si
\[
A= \left[
\begin{matrix}
a & h \\
h & b
\end{matrix}
 \right]
\]

la forma cuadr\'atica $q$ es
\begin{enumerate}
\item[(a)] positiva definida si y solo si la matriz $A$ es definida positiva.
\item[(b)] semi-definida positiva definida si y solo si la matriz $A$ es semi-definida positiva.
\item[(c)] definida negativa si y solo si la matriz $A$ es definida negativa.
\item[(d)] semi-definida negativa si y solo si la matriz $A$ es semi-definida negativa.
\end{enumerate}

\begin{ejemplo}
?`La forma cuadr\'atica $q = 5u^2 + 3uv + 2v^2$ es positiva definida
o negativa definida ?

En forma de matrices:
\[
q = \left[
\begin{matrix}
u & v
\end{matrix}
 \right]
\left[
\begin{matrix}
5 & 1.5 \\
1.5 & 2
\end{matrix}
 \right]
\left[
\begin{matrix}
u \\
v
\end{matrix}
\right]
\]

Sea
\[
A= \left[
\begin{matrix}
5 & 1.5 \\
1.5 & 2
\end{matrix}
 \right].
\]


Como


\[
D_1= 5 > 0 \qquad D_2 =
 \left|
  \begin{matrix}
     5   & 1.5  \\
     1.5   & 2
  \end{matrix}
  \right| = 10 -2.25 = 7.75> 0
\]

entonces la matriz $A$ es definida positiva, por tanto la forma
cuadr\'atica $q$ es definida positiva.

\end{ajemplo}


\begin{ejemplo}
Con el fin de conseguir una reducci\'on del d\'eficit p\'ublico, el
gobierno esta estudiando la posibilidad de introducir un nuevo
impuesto complementario del impuesto sobre la renta de las personas
f\'{\i}sicas y el impuesto sobre el patrimonio, pero de tal forma
que dependa de ellos, seg\'un:

\[
T = 2R^2 + 4P^2- 4 RP
\]

donde $R$ y $P$ son, respectivamente, las cantidades ingresadas por
el impuesto sobre la renta y el de patrimonio.

Justifique que ning\'un contibuyente conseguir\'a, con este nuevo
impuesto, que su declaraci\'on le salga devolver.


\textbf{Soluci\'on:}

El nuevo impuesto puede considerarse como una forma cuadr\'atica en
las variables $R$ y $P$:
\[
T(R,P) = 2R^2 + 4P^2- 4 RP
\]

que, por tanto tiene como matriz sim\'etrica asociada:

\[
A= \left(
\begin{matrix}
2 & -2 \\
-2 & 4
\end{matrix}
\right)
\]

El hecho de que el gobierno no quiera devolver dinero se traduce en
que la forma cuadr\'atica no debe tomar valores negativos para
ning\'un $R,P$, es decir, tiene que verificarse que:

\[
T(R,P)  \geq 0 \quad \text{para cualesquiera $R$ y $P$}
\]
Por tanto $T$ debe ser al menos semidefinida positiva. Veamos si
esto es as\'{\i}, calculando los menores principales de $A$

\begin{align*}
D_1 &= 2 > 0 \\
D_2 &= \det (A) = 4 > 0
\end{align*}

luego $T$ es definida positiva, por lo que se verifica lo pedido.
As\'{\i} pues , el impuesto re\'une las condiciones exigidas para su
aplicaci\'on.

\subsection{Matrices hermitianas}
\begin{definicion}
Una matriz A se le llama hermitiana si es igual a su traspuesta
conjugada, es decir $A = \bar{A^T} = A^{H}$.
\end{definicion}

\begin{ejemplo}
\[
A= \left(
\begin{matrix}
2 & 3 - 3i \\
3 + 3i & 5
\end{matrix}
\right) = A^{H}
\]
\end{ejemplo}

Las tres propiedades básicas de las matrices hermitianas son:

\begin{enumerate}
\item Si $A = A^{H}$, entonces para todos los vectores compelejos
$x$ , el n\'umero $x^{H} A x$ es real.
\begin{ejemplo}
Cada elemento de $A$ contibuye  a $x^{H}A x$. Si $x=(u,v)$, entonces

\begin{align*}
x^{H}A x &= x^{H} \left(
\begin{matrix}
2 & 3 - 3i \\
 3 + 3i & 5
\end{matrix}
\right) x = \left(
\begin{matrix}
\bar{u} & \bar{v}
\end{matrix}
\right)\left(
\begin{matrix}
2 & 3 - 3i \\
3 + 3i & 5
\end{matrix}
\right)
\left(
\begin{matrix}
\bar{u} \\
\bar{v}
\end{matrix}
\right) \\
&= 2\bar{u}u + 5 \bar{v}v + (3-3i)\bar{u}v + (3 + 3i)u \bar{v},
\end{align*}
el cual es un n\'umero real.
\end{ejemplo}
\item Si $A = A^{H}$, todo valor característico es real.

\begin{ejemplo}
Si $ A= \left(
\begin{matrix}
2 & 3 - 3i \\
3 + 3i & 5
\end{matrix}
\right) $, entonces:

\[
|A- \lambda I| = \left|
\begin{matrix}
2 - \lambda & 3 - 3i \\
3 + 3i & 5 -\lambda
\end{matrix}
\right| = \lambda^2 - 7\lambda -8 =(\lambda - 8) (\lambda + 1).
\]
de donde sus valores característicos son  los n\'umeros reales
$\lambda_1 = 8$ y $\lambda_2 = -1$.
\end{ejemplo}
\item Dos vectores característicos de una matriz hermitiana, si
provienen de valores característicos distintos, son ortogonales
entre sí:
\begin{ejemplo}
Para la matriz $ A= \left(
\begin{matrix}
2 & 3 - 3i \\
3 + 3i & 5
\end{matrix}
\right)$, obtenemos los valores característicos asociados a
$\lambda_1 = 8$ y $\lambda_2 = 1$. De las siguientes ecuaciones

\begin{align*}
(A- 8I) x &= \left(
\begin{matrix}
-6 & 3 - 3i \\
3 + 3i & -3
\end{matrix}
\right)= \left(
\begin{matrix}
x_1 \\
x_2
\end{matrix}
\right) = \left(
\begin{matrix}
0 \\
0
\end{matrix}
\right) \\
(A + I) y &= \left(
\begin{matrix}
3 & 3 - 3i \\
3 + 3i & 6
\end{matrix}
\right)= \left(
\begin{matrix}
y_1 \\
y_2
\end{matrix}
\right) = \left(
\begin{matrix}
0 \\
0
\end{matrix}
\right)
\end{align*}
se obtienen los vectores característicos asociados a $\lambda_1$ y
$\lambda_2$ respectivamente:

\begin{align*}
x &= \left(
\begin{matrix}
1 \\
1+i
\end{matrix}
\right) \\
y &= \left(
\begin{matrix}
1 -i\\
-1
\end{matrix}
\right)
\end{align*}
Estos vectores son ortogonales:
\[
 x^{H} y =
 \left(
\begin{matrix}
 1 & 1 -i
\end{matrix}
\right) \left(
\begin{matrix}
1 -i\\
-1
\end{matrix}
\right) = 0.

\]


\end{ejemplo}



\end{enumerate}

\subsection{Forma can\'onica de Jordan}

Dada una matriz cuadrada $A$, se quiere escoger $M$ de forma que
$M^{-1}A M$ sea lo más diagonalmente posible. En el caso más
sencillo, $A$ tiene un conjunto completo de vectores característicos
que se convierten en las columnas de $M$, la cual la denotamos por
$S$. La forma de Jordan es $J = M^{-1}A M = \Lambda;$ se construyo
completamente a partir de bloques $J_i = \lambda_i$ de 1 por 1, y el
objeto de una matriz diagonal se ha alcanzado por completo. En el
caso más general y difícil, faltan algunos vectores característicos
y una forma diagonal es imposible. Ese caso constituye ahora nuestro
principal interés.

\begin{teorema}
Si una matrizx $A$ tiene $s$ vectores característicos linealmente
independientes, entonces es semejante a una matriz $J$ que es la
\textbf{forma de Jordan}, con $s$ bloques cuadrados en la diagonal:
\[
J =M^{-1} A M = \Lambda = \left(
  \begin{matrix}
     J_1   &  &   &  \\
                 &  J_2 &    &   \\
  &  &   \ddots  &   \\
  &  &     & J_s
  \end{matrix}
  \right).
\]
Cada bloque tiene un vector característico, un valor característico
y unos justo arriba de la diagonal:

\[
J_i = \Lambda = \left(
  \begin{matrix}
     \lambda_i   & 1 &   & &  \\
                 &  \lambda_i   & \ddots   & & \\
  &  &   \ddots  &   & 1\\
  &  &     &   \lambda_i&
  \end{matrix}
  \right).
\]
\end{teorema}

\begin{ejemplo}
Un ejemplo de esta forma de Jordan es la matriz $J$, con
\[
J = \left[
  \begin{matrix}
     8   & 1 &  0 &   0 & 0  \\
     0   & 8  &  0 & 0 & 0 \\
     0   & 0  & 0 &  1 & 0  \\
    0  & 0  &  0&  0 & 0 \\
     0  & 0  &  0&  0 & 0
  \end{matrix}
  \right] =
\left(
  \begin{matrix}
     J_1   &  &   &  \\
                 &  J_2 &    &   \\
  &  &    &   \\
  &  &     & J_3
  \end{matrix}
  \right).
\]

donde $J_1 =\left(
\begin{matrix}
 8 & 1 \\
 0 & 8
\end{matrix}
\right)$, $J_2 =\left(
\begin{matrix}
 0 & 1 \\
 0 & 0
\end{matrix}
\right)$ y $J_3 = [0]$. El valor característico dobre $\lambda = 8$
sólo tiene un simple vector característico, en la primera dirección
de coordenadas $e_1=(1,0,0,0,0)$; como resultado $\lambda =8$ sólo
aparece  en un simple bloque $J_1$. El valor característico triple
$\lambda = 0$, tiene dos vectores característicos, $e_3$ y $e_5$ que
corresponden a los dos bloques de Jordan $J_2$ y $J_3$.
\end{ejemplo}

\textbf{En términos de operadores.} Sea $T$ un operador en
$\Bbb{R}^n$ y $m_T(x)= p_1^{e_1}(x) \cdots p_r^{er}(x)$ la
representaci\'on del polinomio m\'{\i}nimo de $T$ como productos de
irreducibles. Entonces
\[
    V = W_1 \oplus \cdots \oplus W_k, \, \text{ con} \, W_i = V_{pi^{e_i}}
\]

Tambi\'en sabemos que el polinomio m\'{\i}nimo de $T$ restringido a
$W_j$ es ${p_j}^{e_j} (x)$. Entonces:
\[
   W_j = W_{1j} \oplus \cdots \oplus W_{ij}
\]

donde cada $W_{ij}$ es T-c\'{\i}clico con anulador
${p_j}^{e_{ij}(x)}$, los exponentes satisfacen: $e_j = e_{1j} \geq
\cdots \geq e_{ij}$.

\begin{definicion}
Los polinomios ${p_j}^{e_j} (x)$ se llaman divisores elementales de
$T$.
\end{definicion}

Ahora, supongamos que alg\'un $p_j(x)$ es lineal y que el anulador y
que el anulador de $W_{ij}$ es $(x -c_j)^{e_{ij}}$. Si $v$ es un
vector c\'{\i}clico de $W_{ij}$ entonces:
\[
  \{v, (T-c_jI)v,..., (T-c_jI)^{e_{ij-1}}  \}
\]
es una base.

La matriz de $T$ restringida a $W_{ij}$ respecto a la base $\{v,
(T-c_jI)v,..., (T-c_jI)^{e_{ij-1}}  $ se obtiene aplicando $T$ a
cada elemento.
\begin{align*}
  T(v) &= c_jv + (T-c_jI)v \\
  T(T-c_jI)v &=  c_j (T-c_jI)v + (T-c_jI)^2 v \\
            & \ \vdots          \\
T((T-c_jI)^{e_{ij}-1} (v)) &=  c_j (T-c_jI)^{e_{ij} -1}(v)
\end{align*}

De estas ecuaciones se tiene que la matriz asociada a la
restricci\'on de $T$ en $W_{ij}$ es:
\begin{equation*}
 \left[
  \begin{matrix}
     c_j   & 0  & \cdots & 0 &   0  & 0 \\
     1   & c_j  & \cdots & 0 &   0 & 0 \\
     0   & 1  & \cdots & 0 &   0 & 0 \\
    \vdots    & \vdots  & \cdots &  \vdots & \vdots  & \vdots \\
     0   & 0  & \cdots & 1 &  c_j & 0 \\
    0  & 0  &  \cdots & 0 &   0& c_j
  \end{matrix}
  \right]
\end{equation*}

\vspace{.2cm}

Por tanto existe una base de $W_j$ respecto de la cual la matriz
asociada a $T$ restringida a $W_j$ es diagonal por bloques con cada
bloque de la forma , llamado bloque de Jordan. Si el polinomio
m\'{\i}nimo se expresa como  un producto de factores lineales,
entonces el anulador en cada $W_{ij}$ es de la forma $(x-
c_j)^{e_{ij}}$ y procediendo como en el caso anterior se tiene que
la restricci\'on de $T$ a cada $W_j$ es diagonal por bloques con
cada bloque de la forma. Resumiendo se tiene el siguiente resultado:

\begin{teorema}
\textbf{(Forma Can\'onica de Jordan)} Sobre $\Bbb{R}^n$, sea $T$ un
operador lineal. Supongamos que el polinomio m\'{\i}nimo
 de $T$ se expresa como $m_T(x) = (x- c_1)^{e_1} \cdots (x -c_k)^{e_k}$. Entonces existe una base $\Bbb{R}^n$ respecto de la cual $T$ se representa por una matriz de la forma $J = \text{diag} \{j_1,...,j_k  \}$, con cada $J_m$ a la vez diagonal por bloques:
 $J_m = \text{diag} \{j_{1},...,{j}_{i_mm}  \}$ y cada $J_{rm}$ un bloque de Jordan de orden $e_{rm}$, los cuales satisfacen
$e_m = e_{1m} \geq \cdots e_{r_mm}$.
\end{teorema}
\begin{ejemplo}
Sea
\[
A = \left[
  \begin{matrix}
     2   & 0 &  0 &   0   \\
     1   & 2  &  0 & 0 \\
     0   & 0  & 2 &  0  \\
    0  & 0  &  0& 2
  \end{matrix}
  \right]
\]
El polinomio característico de $A$ es $(x - 2)^4$. Como $A$ es suma
directa de dos matrices $2 \times 2$, es claro que el polinomio
minimal de $A$ es $(x - 2)^2$. Luego $A$ está en forma de Jordan.
\end{ejemplo}

\newpage
\setcounter{page}{1}
\begin{center}
\textbf{TAREA3: FORMAS CUADRATICAS, MATRICES HERMITIANAS Y FORMA CANONICA DE JORDAN}\\
\end{center}
\vspace{.2cm}
Trabajo en equipo
\vspace{.2cm}

\begin{enumerate}
\item Calcular la matriz Q (cuyas columnas son los vectores característicos ortonormales), y diagonaliza las siguientes matrices simétricas:\\

$
A=
\left(
\begin{matrix}
3& 2& 2\\
2& 2& 0\\
2& 0& 4
\end{matrix}
\right)
 \qquad \qquad
B=
\left(
\begin{matrix}
-1& 2& 2\\
2& -1& 2\\
2& 2& 1
\end{matrix}
\right)$
 \\

 \vspace{0.2cm}
$
C=
\left(
\begin{matrix}
3& -1\\
-1& 3
\end{matrix}
\right) \qquad \qquad
D=
\left(
\begin{matrix}
3& 4\\
4& -3
\end{matrix}
\right)
$
\item Encontrar y diagonalizar la matriz simétrica $ A $ que corresponde a la forma cuadrática.
\begin{enumerate}
\item $ x_1^2+2x_1x_2+x^2_2+4x_1x_3+6x_2x_3+3x^2_3+7x_1x_4-2x_2x_4+x^2_4 $
\item $ x_1^2-x^2_2+x_1x_3-x_2x_4+x^2_4 $
\item $ 4x^2+4xy+y^2=9 $
\item $ 3x^2-6xy+5y^2=36 $
\end{enumerate}

\item Diagonalizar las siguientes matrices hermitianas\\
$
A=
\left(
\begin{matrix}
2& i\\
-i& 5\\
\end{matrix}
\right) \qquad \qquad
B=\left(
\begin{matrix}
2& 1-i\\
1+i& 3
\end{matrix}
\right)
\qquad \qquad
\left(
\begin{matrix}
1& 2i& 3+4i\\
-2i& 4& 5\\
3-4i& 5& 0
\end{matrix}
\right)
$
\item Diagonalizar las siguientes matrices de Jordan:
\[
A=
\left(
\begin{matrix}
-2& 1& 0\\
-2& 1& -1\\
-1& 1& -2
\end{matrix}
\right)
 \qquad \qquad
B=
\left(
\begin{matrix}
-1& -2& -1\\
-1& -1& -1\\
2& 3& 2
\end{matrix}
\right)
\]
\[
C=
\left(
\begin{matrix}
-4& 4\\
-1& 0\\
\end{matrix}
\right) \qquad \qquad
D=
\left(
\begin{matrix}
-9& 4\\
-25& 11
\end{matrix}
\right)
\]
\end{enumerate}

\newpage

\begin{thebibliography}{10}
   \bibitem{T1}
    Gilbert Strang, 2007. Algebra Lineal y sus aplicaciones,
    Thomson. 4a edici\'on.
   \bibitem{T2}
    Darell A. Turkington, 2007. Mathematical Tools for Economics,
    Blackwell Publishing.
   \bibitem{T3}
    Mike Rosser, 2003. Basic Mathematics for Economicsts,
    Routledge. Routledge. 2da. edici\'on.
   \bibitem{T4}
   Nakos George, 2004. Algebra Lineal con aplicaciones. Internacional
   Thomson Editores. 2a Ed, M\'exico.
\end{thebibliography}

\end{document} 